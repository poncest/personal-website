[
  {
    "objectID": "data_visualizations.html",
    "href": "data_visualizations.html",
    "title": "Data Visualizations",
    "section": "",
    "text": "Data Visualization Portfolio\nWelcome to my data visualization gallery. Here youâ€™ll find a collection of visualizations created using R, primarily focusing on #TidyTuesday, #30DayChartChallenge, #SWDchallenege, and #MakeoverMonday challenges and personal projects.\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nAmericaâ€™s Most In-Demand Jobs: Beyond the Headlines\n\n\n\nJanuary 26, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nJust 25 Companies Hold Half of Brazilâ€™s Corporate Capital\n\n\n\nJanuary 26, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Accelerating Rise of Women+ Conductors on Broadway\n\n\n\nJanuary 19, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Far Does APOD Take Us?\n\n\n\nJanuary 18, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Global Housing Bubble is Losing Air\n\n\n\nJanuary 12, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfricaâ€™s Indigenous Language Families Span the Continentr\n\n\n\nJanuary 11, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Prescription Takeover\n\n\n\nJanuary 8, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\n60% started Geraltâ€™s journey. Only 22% finished it.\n\n\n\nJanuary 2, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstimated crime rates are ~134% higher in Londonâ€™s mostdeprived neighborhoods\n\n\n\nDecember 16, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nSmall Nations Lead in Roundabout Adoption\n\n\n\nDecember 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nGlobal language endangerment: scale and geographic concentration\n\n\n\nDecember 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI Model Performance: Accuracy vs.Â Hallucination\n\n\n\nDecember 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nQatar Cars: A Modern, Global Dataset Reveals Four Market Segments\n\n\n\nDecember 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nPet cats rest 70â€“80% of the day regardless of season\n\n\n\nDecember 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Race to 500 Home Runs\n\n\n\nDecember 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe BÃ¶Ã¶gg Cannot Predict Record Hot Summers\n\n\n\nNovember 29, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nKidsâ€™ June 2025 Streaming Top 10\n\n\n\nNovember 25, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Statistical Performance Gap: High vs.Â Low Income Countries\n\n\n\nNovember 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding the Rise in Domestic Terrorism: Context Matters\n\n\n\nNovember 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Sherlock Holmes Canon Thematic Word Networks\n\n\n\nNovember 16, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nLiving WWII Veterans by State (2025)\n\n\n\nNovember 11, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Changing Face of TB Mortality\n\n\n\nNovember 9, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nPokÃ©mon Speed by Type\n\n\n\nNovember 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nFlint Lead Contamination: Government vs.Â Citizen Testing (2015)\n\n\n\nNovember 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Partisan Divide: Who Agrees More?m\n\n\n\nOctober 29, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nGender Equity in British Literary Prizes: Progress with Persistent Disparities\n\n\n\nOctober 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nDrug Use Prevention Playbook: Whoâ€™s at Risk, How They Use, and What Protects Them\n\n\n\nOctober 21, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe UKâ€™s Climate Is Warming â€” and Extremes Are Increasing\n\n\n\nOctober 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nRecessions and Recovery: Not All Crises Are Equal\n\n\n\nOctober 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe World Started Tracking Severe Food Insecurity in 2016\n\n\n\nOctober 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nEuropean Basketball Success by Nation\n\n\n\nOctober 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nHealth Funding Surges While Education Slips\n\n\n\nOctober 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nLake HornborgasjÃ¶n cranes: seasonal peaks and long-term growth\n\n\n\nSeptember 29, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nUK Household Spending Inequality by Income Level in FYE 2024\n\n\n\nSeptember 24, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nChess Dreams and Breakthroughs: A Global Perspective\n\n\n\nSeptember 21, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Great Generational Divide in â€˜Childishâ€™ Perceptions\n\n\n\nSeptember 16, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nRecipe Complexity Correlates with Higher Ratings\n\n\n\nSeptember 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nAIâ€™s Job Market Impact: Transformation with Net Growth\n\n\n\nSeptember 9, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Global Passport Divide: Regional Inequality in Visa-Free Access\n\n\n\nSeptember 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Information Overload to Focused Insights: A Traffic Dashboard Redesign\n\n\n\nSeptember 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nRanking Drug Harms in the UK\n\n\n\nSeptember 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nAustralian Frogs Show Distinct Seasonal Calling Patterns\n\n\n\nAugust 31, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nGlobal Meat Production Analysis: Trends & Statistical Precision\n\n\n\nAugust 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Macarena to Bad Bunny: Latin Musicâ€™s Billboard Evolution\n\n\n\nAugust 25, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nUK Unemployment: Five Decades of Volatility and Range\n\n\n\nAugust 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nHeight Distribution: Scottish Munros vs.Â Munro Tops\n\n\n\nAugust 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegional evolution of extreme weather attribution science\n\n\n\nAugust 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nGlobal Convergence in Electricity Access, 2000-2023\n\n\n\nAugust 11, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe economics of corruption perceptions: structure vs change, 2012-2024\n\n\n\nAugust 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Geography of Inequality and the Redistribution Gap\n\n\n\nAugust 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nEuropean Minimum Wages Rose 23-87% Since 2020, With Eastern Europe Leading Growth\n\n\n\nJuly 29, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nNetflix Content Viewing Velocity Analysis (Jul to Dec 2023)\n\n\n\nJuly 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nLondon Underground Temperature Analysis (2013-2023)\n\n\n\nJuly 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvolution of MTA Art Materials (1980-2020)\n\n\n\nJuly 22, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nMass Deportations Would Devastate Employment Across Multiple States\n\n\n\nJuly 15, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe British Library Funding Crisis: A Three-Part Analysis\n\n\n\nJuly 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nGender Differences in Color Ranking Accuracy\n\n\n\nJuly 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nScience, Health, and History: The Big Three of Misconceptions\n\n\n\nJuly 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Evolution of Dieselâ€™s Premium Over Gasoline\n\n\n\nJune 30, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nGlobal Measles Surveillance: Quality vs Disease Burden\n\n\n\nJune 24, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPI Catalog Maintenance Patterns\n\n\n\nJune 17, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiversity in Federal Judicial Appointments Has Increased Over Time\n\n\n\nJune 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject Gutenberg: Language Patterns in Author Longevity\n\n\n\nJune 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Stakes for U.S. Truck Manufacturing Under Shifting Federal Policy\n\n\n\nJune 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom 17x Industry Benchmark to Optimized Efficiency: A Data-Driven Supplier Strategy\n\n\n\nJune 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nD&D Encounter Design: Celestials Dominate Skill-Based Challenges\n\n\n\nMay 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nClient Contact Program: Uneven Success Demands Strategic Response\n\n\n\nMay 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Enduring Legacy of PC Gaming Excellence\n\n\n\nMay 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nSydney Beaches: Water Quality Reliability\n\n\n\nMay 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nReligious Representation Gap: Migrants vs.Â General Population\n\n\n\nMay 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nVolatility and Change Patterns in Mount Vesuvius Seismic Activity (2011-2023)\n\n\n\nMay 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Uneven Landscape of Asian Restaurants in the U.S.\n\n\n\nMay 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of 1,041 Terminated NSF Grants Totaling $613.26M\n\n\n\nMay 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nDisaster Death Distributions: 1950-2020\n\n\n\nMay 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nTHE HIDDEN UNCERTAINTY\n\n\n\nApril 30, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeteorite Mass Distribution and Uncertainty\n\n\n\nApril 29, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nTopic-Speaker Bipartite Network for useR! 2025 Conference\n\n\n\nApril 29, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nGender Gap in Educational Exclusion by Region\n\n\n\nApril 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrump Approval Ratings Across Selected Demographic Groups\n\n\n\nApril 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nS&P 500 Price Uncertainty and Noise\n\n\n\nApril 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nUncertainty in Cardiovascular Disease Prevalence Across the U.S.\n\n\n\nApril 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nNBA Team Risk Matrix (2023-24 Season)\n\n\n\nApril 25, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nGender Differences in Diabetes Rates Vary Sharply by Region\n\n\n\nApril 24, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nPharmaceutical Giants Stock Performance (2018-2025)\n\n\n\nApril 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nStellar Observations by the Hubble Space Telescope\n\n\n\nApril 22, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nRise and Fall of Trilobites: Fossil Records Over Time\n\n\n\nApril 21, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Shifting Speeds of Urbanization (1960-2023)\n\n\n\nApril 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nApril 20th Fatal Crashes Compared to Yearly Average (1992-2016)\n\n\n\nApril 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nNBA 3-Point Shooting Efficiency: Top 4 Teams\n\n\n\nApril 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelationship Between Peak Hour and Daily Traffic\n\n\n\nApril 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nBirds of a Feather: How NBAâ€™s Bird Teams Show Identical Home Nest Advantage\n\n\n\nApril 17, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nNBA 2023-2024: High Usage Players with Below-Average Efficiency\n\n\n\nApril 16, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nMorphological Separation in Bill Dimensions Across Penguin Species\n\n\n\nApril 16, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Complicated Relationship Between Assists and Turnovers\n\n\n\nApril 15, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nWin Percentage by Player Combinations and Playstyle in 2023-2024 Season\n\n\n\nApril 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nNBA Player Archetypes: The Relationship Between Defense and 3-Point Shooting\n\n\n\nApril 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraffic Volume Distribution Analysis Across California Counties\n\n\n\nApril 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nNBA Teams: Distribution of Assist-to-Turnover Ratios\n\n\n\nApril 11, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistribution of Offensive Rebounding Specialization by Position (2024 NBA Season)\n\n\n\nApril 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nNBA 2023-24: Players with the Highest and Lowest Impact\n\n\n\nApril 9, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistribution of Points Per Game: Starters vs.Â Bench Players\n\n\n\nApril 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nShooting Performance Variability Across NBA Teams (2023-24)\n\n\n\nApril 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of NBA Starsâ€™ Shooting Efficiency (2023-2024)\n\n\n\nApril 6, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nChinaâ€™s Rise: GDP Ranking Changes (1960-2020)\n\n\n\nApril 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreserving Public Health Knowledge: CDC Dataset Categories at Risk\n\n\n\nApril 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nRadial Warmth: San Juanâ€™s Temperature Profile\n\n\n\nApril 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nDigital Divide Narrows: Internet Adoption Across Generations\n\n\n\nApril 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nCitrus: The Only Effective Treatment for Scurvy (1757)\n\n\n\nApril 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nFocus to Collaboration Ratio Across Industries\n\n\n\nMarch 24, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvolution of Business Priorities in Amazonâ€™s Annual Reports\n\n\n\nMarch 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpeed Distribution by PokÃ©mon Type\n\n\n\nMarch 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nRetail Department Performance Analysis: Growth and Volatility\n\n\n\nMarch 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl NiÃ±o Impact on Regional Precipitation\n\n\n\nMarch 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrowth Form Patterns Across Palm Subfamilies\n\n\n\nMarch 17, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Transformation of the Global Electric Vehicle Market (2013-2023)\n\n\n\nMarch 11, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Tale of Pixarâ€™s Evolution: Duration and Reception\n\n\n\nMarch 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Thames in Motion: How Flow Shapes Water Quality and Pollution at FRBC\n\n\n\nMarch 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nYouth Vaping Crisis: Policy Intervention Failure\n\n\n\nMarch 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrueNutâ€™s Market Dominance in Powdered Nut Butter\n\n\n\nFebruary 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nLong Beach Animal Shelter: Stay Duration and Outcomes\n\n\n\nFebruary 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nRacial and Ethnic Disparities in Reproductive Medicine Research (2010-2023)\n\n\n\nFebruary 24, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nPopulation Growth Patterns Across Regions\n\n\n\nFebruary 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Spectrum of Frequencies in Nature and Technology\n\n\n\nFebruary 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeographic Distribution of U.S. Law Enforcement Agencies\n\n\n\nFebruary 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nMost Popular Valentineâ€™s Candy Across U.S. States (2024)\n\n\n\nFebruary 9, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nCDC Dataset Purge: A Timeline of Public Health Data Removal\n\n\n\nFebruary 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nBritainâ€™s Power Mix: A Daily Energy Snapshot\n\n\n\nFebruary 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Simpsons: Character Dialogue Analysis (2010-2016)\n\n\n\nFebruary 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nFive Major U.S. Fresh Vegetable Crops (2000-2022)\n\n\n\nFebruary 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorld Happiness Report 2024\n\n\n\nJanuary 30, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nNearly Half of U.S. Counties Face Increased Water Insecurity\n\n\n\nJanuary 25, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Paradox of Himalayan Climbing Expeditions\n\n\n\nJanuary 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnergy Drink Brand Comparison: Activity Support Drives High Scores\n\n\n\nJanuary 15, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrack Connections at posit::conf (2023-2024)\n\n\n\nJanuary 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nAid Worker Security: A Global Analysis of Risks and Incidents\n\n\n\nJanuary 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Magic to Mixed Feelings: Analyzing â€˜One Hundred Years of Solitudeâ€™ Reviews\n\n\n\nJanuary 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nMore Holidays Associated with Lower Air Traffic Volatility in Larger Markets\n\n\n\nDecember 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Arcane Hierarchy: D&D Spellcasting Classes Compared\n\n\n\nDecember 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nTop 20 Perfume Brands Ranked by Average Rating and Portfolio Size\n\n\n\nDecember 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nProgress in Reducing Working Poverty Rates in Africa (2000-2019)\n\n\n\nDecember 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraffic Flow Analysis: A64 Road, May 2021\n\n\n\nNovember 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nBorder Encounters by Demographic and Authority Type\n\n\n\nNovember 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nBobâ€™s Burgers: Questioning Nature of Dialogue\n\n\n\nNovember 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Architecture of Global Country Codes\n\n\n\nNovember 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nRise and Fall of Democracies and Non-Democracies (1950-2020)\n\n\n\nNovember 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nEurovision: Sweden and Ireland Lead with the Most Wins\n\n\n\nNovember 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonster Movies by Decade and Title Type\n\n\n\nOctober 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Relationships Among CIA Factbook Variables\n\n\n\nOctober 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nOrca Encounter Observations: Leading Vessels\n\n\n\nOctober 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nWakeUp Coffee Sales Summary\n\n\n\nOctober 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nRadar Charts of Species Categories by National Park\n\n\n\nOctober 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nAstronaut Mission Trends and Career Paths: A Journey from Nationality to Occupation\n\n\n\nOctober 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhite and Black Chess Ratings: A Distribution Analysis\n\n\n\nSeptember 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nGender Representation in the International Mathematical Olympiad\n\n\n\nSeptember 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacter Interaction Networks in Shakespeareâ€™s Plays\n\n\n\nSeptember 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistribution of College Attendance Rates by Selectivity Tier\n\n\n\nSeptember 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nTop 20 Responses to Key Questions in the 2024 Stack Overflow Survey\n\n\n\nSeptember 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nHydrogen Projects by Country and Status\n\n\n\nSeptember 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Individual Word Trends Across 27 Seasons of Power Rangers\n\n\n\nAugust 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nAge at Marriage of Kings and Consorts\n\n\n\nAugust 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisitor Distribution by Start Month at Worldâ€™s Fairs\n\n\n\nAugust 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nJudoâ€™s Elite: Medal Achievements of the Top 10 Nations at the Summer Olympics Games, 1964 - 2016\n\n\n\nAugust 7, 2024\n\n\n\n\n\n\nNo matching items\n\n  \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualizations/MakeoverMonday/2025/mm_2025_46.html",
    "href": "data_visualizations/MakeoverMonday/2025/mm_2025_46.html",
    "title": "Kidsâ€™ June 2025 Streaming Top 10",
    "section": "",
    "text": "Original\nThe original visualization comes from Schoolâ€™s out and the TVâ€™s on: What kids in the U.S. watched in June\n\n\nOriginal visualization\n\nMakeover\n\n\n\n\n\nFigureÂ 1: Horizontal bar chart showing Kidsâ€™ June 2025 Streaming Top 10 programs by total minutes viewed. Netflix dominates with four programs (shown in red): Ginny & Georgia leads at 1.43 billion minutes, followed by Squid Game (837M), Stranger Things (617M), and Alvin! and the Chipmunks (466M). Other platforms in gray include Disney+ (Bluey - 895M, Phineas and Ferb - 748M), Paramount+ (SpongeBob - 801M), Hulu (Gumball - 626M), Max/Netflix (Young Sheldon - 533M), and Peacock (Love Island USA - 473M). Notable: Several Teen/Mature-rated shows rank highly despite a 6-17 age demographic.\n\n\nSteps to Create this Graphic \n1. Load Packages & Setup\n\nShow code```{r}\n#| label: load\n#| warning: false\n#| message: false\n#| results: \"hide\"\n\n## 1. LOAD PACKAGES & SETUP ----\nsuppressPackageStartupMessages({\n  if (!require(\"pacman\")) install.packages(\"pacman\")\n  pacman::p_load(\n  tidyverse,     # Easily Install and Load the 'Tidyverse'\n  janitor,       # Simple Tools for Examining and Cleaning Dirty Data\n  skimr,         # Compact and Flexible Summaries of Data\n  scales,        # Scale Functions for Visualization\n  ggtext,        # Improved Text Rendering Support for 'ggplot2'\n  showtext,      # Using Fonts More Easily in R Graphs\n  glue           # Interpreted String Literals\n)\n})\n\n### |- figure size ----\ncamcorder::gg_record(\n    dir    = here::here(\"temp_plots\"),\n    device = \"png\",\n    width  = 10,\n    height = 8,\n    units  = \"in\",\n    dpi    = 320\n)\n\n# Source utility functions\nsuppressMessages(source(here::here(\"R/utils/fonts.R\")))\nsource(here::here(\"R/utils/social_icons.R\"))\nsource(here::here(\"R/utils/image_utils.R\"))\nsource(here::here(\"R/themes/base_theme.R\"))\n```\n\n\n2. Read in the Data\n\nShow code```{r}\n#| label: read\n#| include: true\n#| eval: true\n#| warning: false\n#|\n\ntop_10 &lt;- readxl::read_excel(\n  here::here(\"data/MakeoverMonday/2025/Top 10 Streaming (Kids 6 17).xlsx\")) |&gt;\n  clean_names()\n```\n\n\n3. Examine the Data\n\nShow code```{r}\n#| label: examine\n#| include: true\n#| eval: true\n#| results: 'hide'\n#| warning: false\n\nglimpse(top_10)\n```\n\n\n4. Tidy Data\n\nShow code```{r}\n#| label: tidy\n#| warning: false\n\ntop_10_clean &lt;- top_10 |&gt;\n  mutate(\n    # Standardize program names\n    program_clean = case_when(\n      str_detect(program, \"Spongebob\") ~ \"SpongeBob SquarePants\",\n      TRUE ~ program\n    )\n  )\n\n# SOURCES:\n# - Content Ratings: IMDb (www.imdb.com) - displays TV Parental Guidelines ratings\n# - Show Type & Genre: IMDb and streaming service platforms (Netflix, Disney+, etc.)\n# - Additional verification: Common Sense Media (www.commonsensemedia.org)\n#\n# NOTE: These ratings reflect US TV Parental Guidelines:\n#   TV-Y   = All Children\n#   TV-Y7  = Directed to Older Children (7+)\n#   TV-G   = General Audience\n#   TV-PG  = Parental Guidance Suggested\n#   TV-14  = Parents Strongly Cautioned (14+)\n#   TV-MA  = Mature Audience Only (17+)\n\nshow_info &lt;- tribble(\n  ~program_clean,                ~type,         ~rating,   ~genre,          ~imdb_id,\n  \"Ginny & Georgia\",             \"Live-action\", \"TV-14\",   \"Drama\",         \"tt10624432\",\n  \"Bluey\",                       \"Animation\",   \"TV-Y\",    \"Comedy\",        \"tt7678620\",\n  \"Squid Game\",                  \"Live-action\", \"TV-MA\",   \"Thriller\",      \"tt10919420\",\n  \"SpongeBob SquarePants\",       \"Animation\",   \"TV-Y7\",   \"Comedy\",        \"tt0206512\",\n  \"Phineas and Ferb\",            \"Animation\",   \"TV-G\",    \"Comedy\",        \"tt0852863\",\n  \"The Amazing World of Gumball\",\"Animation\",   \"TV-PG\",   \"Comedy\",        \"tt1942683\",\n  \"Stranger Things\",             \"Live-action\", \"TV-14\",   \"Sci-Fi\",        \"tt4574334\",\n  \"Young Sheldon\",               \"Live-action\", \"TV-PG\",   \"Comedy\",        \"tt6226232\",\n  \"Love Island USA\",             \"Reality\",     \"TV-14\",   \"Reality\",       \"tt8230780\",\n  \"Alvin! and the Chipmunks\",    \"Animation\",   \"TV-Y7\",   \"Comedy\",        \"tt0084119\"\n)\n\n## |-  join and create analysis variables ----\ntop_10_analysis &lt;- top_10_clean |&gt;\n  left_join(show_info, by = \"program_clean\") |&gt;\n  mutate(\n    mins_millions = round(mins_viewed / 1e6, 0),\n    age_appropriate = case_when(\n      rating %in% c(\"TV-Y\", \"TV-Y7\", \"TV-G\") ~ \"Kids\",\n      rating == \"TV-PG\" ~ \"Family\",\n      rating == \"TV-14\" ~ \"Teen\",\n      rating == \"TV-MA\" ~ \"Mature\",\n      TRUE ~ \"Unknown\"\n    ),\n    age_appropriate = factor(age_appropriate,\n                             levels = c(\"Kids\", \"Family\", \"Teen\", \"Mature\")\n    ),\n    program_with_provider = glue(\"{program_clean}&lt;br&gt;&lt;span style='font-size:8pt;color:gray50'&gt;({svod_provider})&lt;/span&gt;\"),\n    program_ordered = fct_reorder(program_with_provider, -rank)\n  )\n```\n\n\n5. Visualization Parameters\n\nShow code```{r}\n#| label: params\n#| include: true\n#| warning: false\n\n### |-  plot aesthetics ----\n# Get base colors with custom palette\ncolors &lt;- get_theme_colors(\n  palette = list(\n    netflix       = \"#B20710\", \n    neutral_dark  = \"#9E9E9E\"          \n  )\n)\n\n### |-  Main titles ----\ntitle_text &lt;- \"Kids' June 2025 Streaming Top 10\"\nsubtitle_text &lt;- str_glue(\n  \"Netflix leads June with 4 of the top 10 programs, totaling 3.3B minutes viewed&lt;br&gt;\",\n  \"Nielsen measures household accounts with viewers 6â€“17; programming reflects actual viewing, not age-appropriateness.\"\n)\n\n### |-  Data source caption ----\ncaption_text &lt;- create_mm_caption(\n  mm_year = 2025,\n  mm_week = 46,\n  source_text = str_glue(\n    \"Nielsen National TV Panel&lt;br&gt;\",\n    \"**Note:** Kids 6-17, June 2025 (05/26/25 - 06/29/25). Metadata from IMDb.\"\n  )\n)\n\n### |-  fonts ----\nsetup_fonts()\nfonts &lt;- get_font_families()\n\n### |-  plot theme ----\n\n# Start with base theme\nbase_theme &lt;- create_base_theme(colors)\n\n# Add weekly-specific theme elements\nweekly_theme &lt;- extend_weekly_theme(\n  base_theme,\n  theme(\n    # # Text styling\n    plot.title = element_text(\n      size = rel(1.5), family = fonts$title, face = \"bold\",\n      color = colors$title, lineheight = 1.1, hjust = 0,\n      margin = margin(t = 5, b = 10)\n    ),\n    plot.subtitle = element_markdown(\n      size = rel(0.9), family = fonts$subtitle, face = \"italic\",\n      color = alpha(colors$subtitle, 0.9), lineheight = 1.1,\n      margin = margin(t = 0, b = 20)\n    ),\n\n    # Legend formatting\n    legend.position = \"plot\",\n    legend.justification = \"top\",\n    legend.margin = margin(l = 12, b = 5),\n    legend.key.size = unit(0.8, \"cm\"),\n    legend.box.margin = margin(b = 10),\n    # legend.title = element_text(face = \"bold\"),\n\n    # Axis formatting\n    axis.ticks.y = element_blank(),\n    axis.ticks.x = element_line(color = \"gray\", linewidth = 0.5),\n    axis.title.x = element_text(\n      face = \"bold\", size = rel(0.85),\n      margin = margin(t = 10)\n    ),\n    axis.title.y = element_text(\n      face = \"bold\", size = rel(0.85),\n      margin = margin(r = 10)\n    ),\n    axis.text.x = element_text(\n      size = rel(0.85), family = fonts$subtitle,\n      color = colors$text\n    ),\n    axis.text.y = element_markdown(\n      size = rel(0.85), family = fonts$subtitle,\n      color = colors$text\n    ),\n\n    # Grid lines\n    panel.grid.minor = element_line(color = \"#ecf0f1\", linewidth = 0.2),\n    panel.grid.major = element_line(color = \"#ecf0f1\", linewidth = 0.4),\n\n    # Margin\n    plot.margin = margin(20, 20, 20, 20)\n  )\n)\n\n# Set theme\ntheme_set(weekly_theme)\n```\n\n\n6. Plot\n\nShow code```{r}\n#| label: plot\n#| warning: false\n\n## |-  prepare data for plotting ----\nplot_data &lt;- top_10_analysis |&gt;\n  mutate(\n    # Netflix highlighting\n    is_netflix = svod_provider == \"Netflix\",\n    bar_color = ifelse(is_netflix, colors$palette$netflix, colors$palette$neutral_dark),\n    text_color = ifelse(is_netflix, \"white\", \"gray30\"),\n  ) |&gt;\n  mutate(\n    mins_billions = mins_millions / 1000,\n    mins_label_smart = ifelse(\n      mins_billions &gt;= 1,\n      paste0(round(mins_billions, 2), \"B\"),\n      paste0(mins_millions, \"M\")\n    )\n  )\n\n### |-  main plot ----\np &lt;- \n  plot_data |&gt;\n  ggplot(aes(x = mins_millions, y = program_ordered)) +\n  # Geoms\n  geom_col(aes(fill = bar_color), width = 0.65) +\n  geom_text(\n    aes(x = 25, label = paste0(genre, \" | \", type), color = text_color),\n    hjust = 0,\n    size = 2.5\n  ) +\n  geom_label(\n    aes(x = mins_millions - 40, label = rating),\n    hjust = 1,\n    size = 2.5,\n    fontface = \"bold\",\n    fill = \"white\",\n    label.size = 0,\n    label.padding = unit(0.15, \"lines\")\n  ) +\n  geom_text(\n    aes(label = mins_label_smart),\n    hjust = -0.1,\n    size = 3.5,\n    fontface = \"bold\"\n  ) +\n  # Annotate\n  annotate(\n    \"text\", x = 850, y = 3,\n    label = \"60% of the Top 10 are Kids/Family titles,\\nwhile several Teen/Mature shows still rank highly\\namong households with viewers 6â€“17.\",\n    hjust = 0, size = 3.2, lineheight = 1.1,\n    family = fonts$subtitle, color = \"gray30\"\n  ) +\n  # Scales\n  scale_x_continuous(\n    position = \"top\",\n    expand = expansion(mult = c(0.02, 0.1)),\n    labels = label_comma(suffix = \"M\")\n  ) +\n  scale_fill_identity() +\n  scale_color_identity() +\n  # Labs\n  labs(\n    title = title_text,\n    subtitle = subtitle_text,\n    x = \"Total Minutes Viewed (Millions)\",\n    y = NULL,\n    caption = caption_text\n  ) +\n  # Theme\n  theme(\n    plot.title = element_text(\n      size = rel(1.85),\n      family = fonts$title,\n      face = \"bold\",\n      color = colors$title,\n      lineheight = 1.1,\n      margin = margin(t = 5, b = 5)\n    ),\n    plot.subtitle = element_markdown(\n      size = rel(0.8),\n      family = fonts$subtitle,\n      color = alpha(colors$subtitle, 0.9),\n      lineheight = 1.5,\n      margin = margin(t = 5, b = 25)\n    ),\n    plot.caption = element_markdown(\n      size = rel(0.5),\n      family = fonts$caption,\n      color = colors$caption,\n      hjust = 0,\n      lineheight = 1.2,\n      margin = margin(t = 10)\n    ),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    axis.ticks = element_blank()\n  )\n```\n\n\n7. Save\n\nShow code```{r}\n#| label: save\n#| warning: false\n\n### |-  plot image ----  \nsave_plot(\n  plot = p, \n  type = \"makeovermonday\", \n  year = current_year,\n  week = current_week,\n  width = 10, \n  height = 8\n  )\n```\n\n\n8. Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] here_1.0.1      glue_1.8.0      showtext_0.9-7  showtextdb_3.0 \n [5] sysfonts_0.8.9  ggtext_0.1.2    scales_1.3.0    skimr_2.1.5    \n [9] janitor_2.2.0   lubridate_1.9.3 forcats_1.0.0   stringr_1.5.1  \n[13] dplyr_1.1.4     purrr_1.0.2     readr_2.1.5     tidyr_1.3.1    \n[17] tibble_3.2.1    ggplot2_3.5.1   tidyverse_2.0.0 pacman_0.5.1   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 tzdb_0.5.0       \n [5] vctrs_0.6.5       tools_4.4.0       generics_0.1.3    curl_6.0.0       \n [9] gifski_1.32.0-1   fansi_1.0.6       pkgconfig_2.0.3   readxl_1.4.3     \n[13] lifecycle_1.0.4   farver_2.1.2      compiler_4.4.0    textshaping_0.4.0\n[17] munsell_0.5.1     repr_1.1.7        codetools_0.2-20  snakecase_0.11.1 \n[21] htmltools_0.5.8.1 yaml_2.3.10       pillar_1.9.0      camcorder_0.1.0  \n[25] magick_2.8.5      commonmark_1.9.2  tidyselect_1.2.1  digest_0.6.37    \n[29] stringi_1.8.4     labeling_0.4.3    rsvg_2.6.1        rprojroot_2.0.4  \n[33] fastmap_1.2.0     grid_4.4.0        colorspace_2.1-1  cli_3.6.4        \n[37] magrittr_2.0.3    base64enc_0.1-3   utf8_1.2.4        withr_3.0.2      \n[41] timechange_0.3.0  rmarkdown_2.29    cellranger_1.1.0  ragg_1.3.3       \n[45] hms_1.1.3         evaluate_1.0.1    knitr_1.49        markdown_1.13    \n[49] rlang_1.1.6       gridtext_0.1.5    Rcpp_1.0.13-1     xml2_1.3.6       \n[53] renv_1.0.3        svglite_2.1.3     rstudioapi_0.17.1 jsonlite_1.8.9   \n[57] R6_2.5.1          systemfonts_1.1.0\n\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in mm_2025_46.qmd.\nFor the full repository, click here.\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\n\nData:\n\n\nMakeover Monday 2025 Week 46: Schoolâ€™s out and the TVâ€™s on: What kids in the U.S. watched in June\n\n\n\nArticle\n\n\nSchoolâ€™s out and the TVâ€™s on: What kids in the U.S. watched in June\n\n\nCitation:\n\nNielsen. (2025). Schoolâ€™s out and the TVâ€™s on: What kids in the U.S. watched in June. Nielsen Insights. Retrieved from https://www.nielsen.com/insights/2025/what-us-kids-watched-tv-streaming-summer-june/\n\n\n\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\n\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\n\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\n\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualizations/TidyTuesday/2025/tt_2025_48.html",
    "href": "data_visualizations/TidyTuesday/2025/tt_2025_48.html",
    "title": "The BÃ¶Ã¶gg Cannot Predict Record Hot Summers",
    "section": "",
    "text": "FigureÂ 1: Scatter plot testing Swiss folklore that a faster BÃ¶Ã¶gg explosion predicts a hotter summer. A dotted diagonal line shows the expected negative relationship, but the data contradicts it: record hot summers (large red points above 19Â°C threshold) are scattered across all burn durations from 4 to 60 minutes. The 2003 European heat wave had a fast 7-minute burn, while 2023â€™s record summer had a slow 57-minute burn. Correlation is +0.19, opposite to folkloreâ€™s prediction.\n\n\nSteps to Create this Graphic \n1. Load Packages & Setup\n\nShow code```{r}\n#| label: load\n#| warning: false\n#| message: false\n#| results: \"hide\"\n\n## 1. LOAD PACKAGES & SETUP ----\nsuppressPackageStartupMessages({\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n    tidyverse,     # Easily Install and Load the 'Tidyverse'\n    ggtext,        # Improved Text Rendering Support for 'ggplot2'\n    showtext,      # Using Fonts More Easily in R Graphs\n    janitor,       # Simple Tools for Examining and Cleaning Dirty Data\n    scales,        # Scale Functions for Visualization\n    glue,          # Interpreted String Literals\n    ggrepel        # Automatically Position Non-Overlapping Text Labels\n)\n})\n\n### |- figure size ----\ncamcorder::gg_record(\n  dir    = here::here(\"temp_plots\"),\n  device = \"png\",\n  width  = 10,\n  height = 10,\n  units  = \"in\",\n  dpi    = 320\n)\n\n# Source utility functions\nsuppressMessages(source(here::here(\"R/utils/fonts.R\")))\nsource(here::here(\"R/utils/social_icons.R\"))\nsource(here::here(\"R/utils/image_utils.R\"))\nsource(here::here(\"R/themes/base_theme.R\"))\n```\n\n\n2. Read in the Data\n\nShow code```{r}\n#| label: read\n#| include: true\n#| eval: true\n#| warning: false\n\ntt &lt;- tidytuesdayR::tt_load(2025, week = 48)\n\nsechselaeuten &lt;- tt$sechselaeuten |&gt; clean_names()\n\ntidytuesdayR::readme(tt)\nrm(tt)\n```\n\n\n3. Examine the Data\n\nShow code```{r}\n#| label: examine\n#| include: true\n#| eval: true\n#| results: 'hide'\n#| warning: false\n\nglimpse(sechselaeuten)\nskimr::skim(sechselaeuten) |&gt; summary()\n```\n\n\n4. Tidy Data\n\nShow code```{r}\n#| label: tidy-fixed\n#| warning: false\n\n### |- clean and prepare data ----\nsechselaeuten_clean &lt;- sechselaeuten |&gt;\n  mutate(\n    # Flag years with missing duration\n    duration_missing = is.na(duration),\n\n    # Categorize burn duration\n    burn_category = case_when(\n      is.na(duration) ~ \"No data\",\n      duration &lt;= 10 ~ \"Fast (â‰¤10 min)\",\n      duration &lt;= 20 ~ \"Medium (11â€“20 min)\",\n      TRUE ~ \"Slow (&gt;20 min)\"\n    ),\n    burn_category = factor(\n      burn_category,\n      levels = c(\"Fast (â‰¤10 min)\", \"Medium (11â€“20 min)\", \"Slow (&gt;20 min)\", \"No data\")\n    )\n  )\n\n### |- summary stats for reference ----\nduration_median &lt;- median(sechselaeuten_clean$duration, na.rm = TRUE)\ntemp_median &lt;- median(sechselaeuten_clean$tre200m0, na.rm = TRUE)\nrecord_threshold &lt;- 19\n\n# Correlation\ncor_duration_temp &lt;- cor(\n  sechselaeuten_clean$duration,\n  sechselaeuten_clean$tre200m0,\n  use = \"complete.obs\"\n)\n\n# Record summers count\nn_record &lt;- sum(sechselaeuten_clean$record, na.rm = TRUE)\nn_total &lt;- sum(!sechselaeuten_clean$duration_missing)\n\n### |- prepare data for plot ----\nplot_data &lt;- sechselaeuten_clean |&gt;\n  filter(!duration_missing)\n\n# Separate record years for labeling\nrecord_years &lt;- plot_data |&gt;\n  filter(record == TRUE)\n\n# Key stats for annotations\nmin_record_duration &lt;- min(record_years$duration)\nmax_record_duration &lt;- max(record_years$duration)\n```\n\n\n5. Visualization Parameters\n\nShow code```{r}\n#| label: params\n#| include: true\n#| warning: false\n\n### |-  plot aesthetics ----\ncolors &lt;- get_theme_colors(\n    palette = c(\n        \"record\"     = \"#C1292E\",  \n        \"normal\"     = \"#8B9DAE\",  \n        \"threshold\"  = \"#C1292E\",  \n        \"annotation\" = \"#5C6B7A\"   \n    )\n)\n\n### |- titles and caption ----\ntitle_text &lt;- \"The BÃ¶Ã¶gg Cannot Predict Record Hot Summers\"\n\nsubtitle_text &lt;- str_glue(\n    \"**The folklore:** A faster BÃ¶Ã¶gg explosion means a hotter summer.&lt;br&gt;\",\n    \"**The reality:** Record summers (&gt;{record_threshold}Â°C) occurred whether the BÃ¶Ã¶gg took \", \n    \"{min(plot_data$duration)} minutes or {max(plot_data$duration)}. Correlation: r = +0.19.\"\n)\n\ncaption_text &lt;- create_social_caption(\n    tt_year  = 2025,\n    tt_week  = 48,  \n    source_text = str_glue(\n        \"MeteoSwiss & Statistik Stadt ZÃ¼rich.&lt;br&gt;\",\n        \"Record summers: {n_record} of {n_total} years with burn data.\"\n    )\n)\n\n### |-  fonts ----\nsetup_fonts()\nfonts &lt;- get_font_families()\n\n### |-  plot theme ----\n# Start with base theme\nbase_theme &lt;- create_base_theme(colors)\n\n# Add weekly-specific theme elements\nweekly_theme &lt;- extend_weekly_theme(\n  base_theme,\n  theme(\n    # Text styling\n    plot.title = element_markdown(\n      face = \"bold\", family = fonts$title, size = rel(1.4),\n      color = colors$title, margin = margin(b = 10), hjust = 0\n    ),\n    plot.subtitle = element_text(\n      face = \"italic\", family = fonts$subtitle, lineheight = 1.2,\n      color = colors$subtitle, size = rel(0.9), margin = margin(b = 20), hjust = 0\n    ),\n\n    # Grid\n    panel.grid.minor = element_blank(),\n    # panel.grid.major.x = element_blank(),\n    panel.grid.major = element_line(color = \"gray90\", linewidth = 0.3),\n\n    # Axes\n    axis.title = element_text(size = rel(0.8), color = \"gray30\"),\n    axis.text = element_text(color = \"gray30\"),\n    axis.text.y = element_text(size = rel(0.85)),\n    axis.ticks = element_blank(),\n\n    # Facets\n    strip.background = element_rect(fill = \"gray95\", color = NA),\n    strip.text = element_text(\n      face = \"bold\",\n      color = \"gray20\",\n      size = rel(0.9),\n      margin = margin(t = 6, b = 4)\n    ),\n    panel.spacing = unit(1.5, \"lines\"),\n\n    # Legend elements\n    legend.position = \"plot\",\n    legend.title = element_text(\n      family = fonts$tsubtitle,\n      color = colors$text, size = rel(0.8), face = \"bold\"\n    ),\n    legend.text = element_text(\n      family = fonts$tsubtitle,\n      color = colors$text, size = rel(0.7)\n    ),\n    legend.margin = margin(t = 15),\n\n    # Plot margin\n    plot.margin = margin(20, 20, 20, 20)\n  )\n)\n\n# Set theme\ntheme_set(weekly_theme)\n```\n\n\n6. Plot\n\nShow code```{r}\n#| label: plot\n#| warning: false\n\n### |-  main plot ----\np &lt;- \n  plot_data |&gt;\n  ggplot(aes(x = duration, y = tre200m0)) +\n\n  # Geoms\n  geom_hline(\n    yintercept = record_threshold,\n    linetype = \"dashed\",\n    linewidth = 0.6,\n    color = colors$palette[\"threshold\"],\n    alpha = 0.6\n  ) +\n  geom_point(\n    data = filter(plot_data, record == FALSE),\n    size = 2.6,\n    alpha = 0.45,\n    color = colors$palette[\"normal\"]\n  ) +\n  geom_point(\n    data = record_years,\n    aes(size = tre200m0),\n    alpha = 0.85,\n    color = colors$palette[\"record\"]\n  ) +\n  # Labels for record years\n  geom_text_repel(\n    data = record_years,\n    aes(label = year),\n    size = 3.2,\n    fontface = \"bold\",\n    color = colors$palette[\"record\"],\n    nudge_y = 0.3,\n    direction = \"y\",\n    segment.size = 0.3,\n    segment.color = colors$palette[\"record\"],\n    segment.alpha = 0.5,\n    box.padding = 0.5,\n    point.padding = 0.4,\n    max.overlaps = 20,\n    seed = 42\n  ) +\n  # Annotate\n  annotate(\n    \"text\",\n    x = max(plot_data$duration) - 2,\n    y = record_threshold + 0.15,\n    label = (\"Record threshold ({record_threshold}Â°C)\"),\n    hjust = 1,\n    size = 3,\n    fontface = \"italic\",\n    color = colors$palette[\"threshold\"],\n    family = fonts$text\n  ) +\n  annotate(\n    \"segment\",\n    x = 8, xend = 50,\n    y = 20.5, yend = 17.5,\n    color = \"gray70\",\n    linewidth = 0.8,\n    linetype = \"dotted\",\n    arrow = arrow(length = unit(0.15, \"inches\"), type = \"closed\")\n  ) +\n  annotate(\n    \"text\",\n    x = 52, y = 17.3,\n    label = \"What folklore\\npredicts\",\n    size = 2.5,\n    color = \"gray50\",\n    hjust = 0,\n    lineheight = 0.9,\n    fontface = \"italic\"\n  ) +\n  # Scales\n  scale_x_continuous(\n    breaks = seq(0, 60, by = 10),\n    limits = c(0, 65),\n    expand = expansion(mult = c(0.02, 0.02))\n  ) +\n  scale_y_continuous(\n    breaks = seq(14, 22, by = 1),\n    limits = c(14, 22.5),\n    expand = expansion(mult = c(0.02, 0.02))\n  ) +\n  scale_size_continuous(range = c(4, 7), guide = \"none\") +\n  # Labs\n  labs(\n    title = title_text,\n    subtitle = subtitle_text,\n    caption = caption_text,\n    x = \"Burn Duration (minutes)\",\n    y = \"Avg Summer Temperature (Â°C)\"\n  ) +\n  # Theme\n  theme(\n    plot.title = element_markdown(\n      size = rel(2),\n      family = fonts$title,\n      face = \"bold\",\n      color = colors$title,\n      lineheight = 1.15,\n      margin = margin(t = 8, b = 5)\n    ),\n    plot.subtitle = element_markdown(\n      size = rel(0.8),\n      family = fonts$subtitle,\n      color = alpha(colors$subtitle, 0.88),\n      lineheight = 1.25,\n      margin = margin(t = 5, b = 20)\n    ),\n    plot.caption = element_markdown(\n      size = rel(0.55),\n      family = fonts$subtitle,\n      color = colors$caption,\n      hjust = 0,\n      lineheight = 1.4,\n      margin = margin(t = 20, b = 5)\n    )\n  )\n```\n\n\n7. Save\n\nShow code```{r}\n#| label: save\n#| warning: false\n\n### |-  plot image ----  \nsave_plot(\n  plot = p, \n  type = \"tidytuesday\", \n  year = 2025, \n  week = 48, \n  width  = 10,\n  height = 10,\n  )\n```\n\n\n8. Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] here_1.0.1      ggrepel_0.9.6   glue_1.8.0      scales_1.3.0   \n [5] janitor_2.2.0   showtext_0.9-7  showtextdb_3.0  sysfonts_0.8.9 \n [9] ggtext_0.1.2    lubridate_1.9.3 forcats_1.0.0   stringr_1.5.1  \n[13] dplyr_1.1.4     purrr_1.0.2     readr_2.1.5     tidyr_1.3.1    \n[17] tibble_3.2.1    ggplot2_3.5.1   tidyverse_2.0.0 pacman_0.5.1   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6       xfun_0.49          httr2_1.0.6        htmlwidgets_1.6.4 \n [5] gh_1.4.1           tzdb_0.5.0         vctrs_0.6.5        tools_4.4.0       \n [9] generics_0.1.3     parallel_4.4.0     curl_6.0.0         gifski_1.32.0-1   \n[13] fansi_1.0.6        pkgconfig_2.0.3    skimr_2.1.5        lifecycle_1.0.4   \n[17] farver_2.1.2       compiler_4.4.0     textshaping_0.4.0  munsell_0.5.1     \n[21] repr_1.1.7         codetools_0.2-20   snakecase_0.11.1   htmltools_0.5.8.1 \n[25] yaml_2.3.10        crayon_1.5.3       pillar_1.9.0       camcorder_0.1.0   \n[29] magick_2.8.5       commonmark_1.9.2   tidyselect_1.2.1   digest_0.6.37     \n[33] stringi_1.8.4      rsvg_2.6.1         rprojroot_2.0.4    fastmap_1.2.0     \n[37] grid_4.4.0         colorspace_2.1-1   cli_3.6.4          magrittr_2.0.3    \n[41] base64enc_0.1-3    utf8_1.2.4         withr_3.0.2        rappdirs_0.3.3    \n[45] bit64_4.5.2        timechange_0.3.0   rmarkdown_2.29     tidytuesdayR_1.1.2\n[49] gitcreds_0.1.2     bit_4.5.0          ragg_1.3.3         hms_1.1.3         \n[53] evaluate_1.0.1     knitr_1.49         markdown_1.13      rlang_1.1.6       \n[57] gridtext_0.1.5     Rcpp_1.0.13-1      xml2_1.3.6         renv_1.0.3        \n[61] vroom_1.6.5        svglite_2.1.3      rstudioapi_0.17.1  jsonlite_1.8.9    \n[65] R6_2.5.1           systemfonts_1.1.0 \n\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in tt_2025_48.qmd.\nFor the full repository, click here.\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\n\n\nData Source:\n\nTidyTuesday 2025 Week 48: Can an exploding snowman predict the summer season?\n\n\n\n\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\n\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\n\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\n\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualizations/SWD Challenge/2025/swd_2025_12.html",
    "href": "data_visualizations/SWD Challenge/2025/swd_2025_12.html",
    "title": "The Race to 500 Home Runs",
    "section": "",
    "text": "Challenge\nThis monthâ€™s challenge asks you to create a visual where lower values represent better performance or outcomes. Whether itâ€™s time, cost, risk, or something else, your goal is to make it immediately clear that less is the win.\nAdditional information can be found HERE\nVisualization\n\n\n\n\n\nFigureÂ 1: Line chart showing the cumulative home run trajectories for all 28 members of baseballâ€™s 500 Home Run Club. Three players are highlighted: Mark McGwire in red reached 500 HR fastest at 1,688 games but is linked to PED use; Babe Ruth in dark blue holds the fastest clean record at 1,790 games; Eddie Murray in teal took the longest at 2,971 games. The remaining 25 players appear as gray lines, illustrating a spread of roughly 1,300 games between the fastest and slowest paths to the milestone.\n\n\nSteps to Create this Graphic \n1. Load Packages & Setup\n\nShow code```{r}\n#| label: load\n\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  tidyverse,   # Easily Install and Load the 'Tidyverse'\n  ggtext,      # Improved Text Rendering Support for 'ggplot2'\n  showtext,    # Using Fonts More Easily in R Graphs\n  janitor,     # Simple Tools for Examining and Cleaning Dirty Data\n  scales,      # Scale Functions for Visualization\n  glue,        # Interpreted String Literals\n  Lahman       # Sean 'Lahman' Baseball Database\n) \n\n### |- figure size ---- \ncamcorder::gg_record(\n  dir    = here::here(\"temp_plots\"),\n  device = \"png\",\n  width  = 10,\n  height = 8,\n  units  = \"in\",\n  dpi    = 320\n)\n\n# Source utility functions\nsuppressMessages(source(here::here(\"R/utils/fonts.R\")))\nsource(here::here(\"R/utils/social_icons.R\"))\nsource(here::here(\"R/utils/image_utils.R\"))\nsource(here::here(\"R/themes/base_theme.R\"))\n```\n\n\n2. Read in the Data\n\nShow code```{r}\n#| label: read\n\nbatting_raw &lt;- Lahman::Batting\npeople_raw  &lt;- Lahman::People\n\n### |- PED-linked players (Source: ESPN - The Steroids Era) ----\n# https://www.espn.com/mlb/topics/_/page/the-steroids-era\n# \"Of the 10 players [who reached 500 HR between 1998-2009], six -- Barry Bonds, \n# Alex Rodriguez, Mark McGwire, Manny Ramirez, Rafael Palmeiro and Gary Sheffield \n# -- have been linked to PEDs.\"\n# Sammy Sosa added based on leaked 2003 test results\n\nped_players &lt;- c(\n  \"Mark McGwire\",\n  \"Barry Bonds\",\n  \"Alex Rodriguez\",\n  \"Sammy Sosa\",\n  \"Manny Ramirez\",\n  \"Rafael Palmeiro\",\n  \"Gary Sheffield\"\n)\n```\n\n\n3. Examine the Data\n\nShow code```{r}\n#| label: examine\n#| include: true\n#| eval: true\n#| results: 'hide'\n#| warning: false\n\nglimpse(batting_raw)\nglimpse(people_raw)\n```\n\n\n4. Tidy Data\n\nShow code```{r}\n#| label: tidy\n\ncareer_hr &lt;- batting_raw |&gt;\n  group_by(playerID) |&gt;\n  summarize(\n    career_HR = sum(HR, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt;\n  filter(career_HR &gt;= 500) |&gt;\n  left_join(\n    people_raw |&gt; select(playerID, nameFirst, nameLast),\n    by = \"playerID\"\n  ) |&gt;\n  mutate(player_name = paste(nameFirst, nameLast)) |&gt;\n  arrange(desc(career_HR))\n\ncumulative_stats &lt;- batting_raw |&gt;\n  filter(playerID %in% career_hr$playerID) |&gt;\n  group_by(playerID, yearID) |&gt;\n  summarize(\n    season_HR = sum(HR, na.rm = TRUE),\n    season_G  = sum(G, na.rm = TRUE),\n    .groups   = \"drop\"\n  ) |&gt;\n  arrange(playerID, yearID) |&gt;\n  group_by(playerID) |&gt;\n  mutate(\n    cumulative_HR = cumsum(season_HR),\n    cumulative_G  = cumsum(season_G)\n  ) |&gt;\n  ungroup()\n\nrace_data &lt;- cumulative_stats |&gt;\n  filter(cumulative_HR &lt;= 550) |&gt;\n  left_join(\n    people_raw |&gt; select(playerID, nameFirst, nameLast),\n    by = \"playerID\"\n  ) |&gt;\n  mutate(\n    player_name = paste(nameFirst, nameLast),\n    is_ped = player_name %in% ped_players,\n    player_category = case_when(\n      player_name == \"Mark McGwire\" ~ \"mcgwire\",\n      player_name == \"Babe Ruth\" ~ \"ruth\",\n      player_name == \"Eddie Murray\" ~ \"murray\",\n      TRUE ~ \"other\"\n    )\n  )\n```\n\n\n5. Visualization Parameters\n\nShow code```{r}\n#| label: params\n\n### |-  plot aesthetics ----\ncolors &lt;- get_theme_colors(\n  palette = list(\n    mcgwire = \"#BF092F\",  \n    ruth  = \"#132440\",  \n    murray = \"#3B9797\", \n    others = \"gray75\",\n    milestone = \"gray55\",\n    grid = \"gray90\"\n  )\n)\n\n### |-  titles and caption ----\ntitle_text &lt;- \"The Race to 500 Home Runs\"\n\nsubtitle_text &lt;- str_glue(\n  \"**McGwire** was fastest (1,688 games) but linked to PED use. **Babe Ruth** holds the fastest clean record at 1,790 games,&lt;br&gt;\",\n  \"while **Eddie Murray** needed 2,971 games.&lt;br&gt;&lt;br&gt;\",\n  \"&lt;span style='color:gray50; font-size:10pt;'&gt;7 of 28 club members have been linked to performance-enhancing drugs (1929â€“2021)&lt;/span&gt;\"\n)\n\n# Create caption\ncaption_text &lt;- create_swd_caption(\n  year = 2025,\n  month = \"Dec\",\n  source_text = \"500 HR Club trajectories: Lahman Baseball Database â€¢ PED links: ESPN â€œThe Steroids Eraâ€\"\n)\n\n### |-  fonts ----\nsetup_fonts()\nfonts &lt;- get_font_families()\n\n### |-  plot theme ----\n# Start with base theme\nbase_theme &lt;- create_base_theme(colors)\n\n# Add weekly-specific theme elements\nweekly_theme &lt;- extend_weekly_theme(\n  base_theme,\n  theme(\n    # Text styling\n    plot.title = element_text(\n      face = \"bold\", family = fonts$title, size = rel(1.4),\n      color = colors$palette$title, margin = margin(b = 10), hjust = 0\n    ),\n    plot.subtitle = element_text(\n      family = fonts$subtitle, lineheight = 1.2,\n      color = colors$palette$subtitle, size = rel(0.9), margin = margin(b = 20), hjust = 0\n    ),\n\n    ## Grid\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_line(color = \"gray90\", linewidth = 0.3),\n\n    # Axes\n    axis.title = element_text(size = rel(0.9), color = \"gray30\"),\n    axis.text = element_text(color = \"gray30\"),\n    axis.text.y = element_text(size = rel(0.95)),\n    axis.ticks = element_blank(),\n\n    # Facets\n    strip.background = element_rect(fill = \"gray95\", color = NA),\n    strip.text = element_text(\n      face = \"bold\",\n      color = \"gray20\",\n      size = rel(1),\n      margin = margin(t = 8, b = 8)\n    ),\n    panel.spacing = unit(2, \"lines\"),\n\n    # Legend elements\n    legend.position = \"plot\",\n    legend.title = element_text(\n      family = fonts$tsubtitle,\n      color = colors$palette$text, size = rel(0.8), face = \"bold\"\n    ),\n    legend.text = element_text(\n      family = fonts$tsubtitle,\n      color = colors$palette$text, size = rel(0.7)\n    ),\n    legend.margin = margin(t = 15),\n\n    # Plot margin\n    plot.margin = margin(10, 20, 10, 20)\n  )\n)\n\n# Set theme\ntheme_set(weekly_theme)\n```\n\n\n6. Plot\n\nShow code```{r}\n#| label: plot\n\np &lt;- ggplot(race_data, aes(x = cumulative_G, y = cumulative_HR, group = player_name)) +\n  # Geoms\n  geom_hline(\n    yintercept = 500,\n    linetype   = \"dashed\",\n    color      = colors$palette$milestone,\n    linewidth  = 0.5\n  ) +\n  geom_line(\n    data = race_data |&gt; filter(player_category == \"other\"),\n    color = colors$palette$others,\n    linewidth = 0.5,\n    alpha = 0.6\n  ) +\n  geom_line(\n    data = race_data |&gt; filter(player_category == \"murray\"),\n    color = colors$palette$murray,\n    linewidth = 1.1\n  ) +\n  geom_line(\n    data = race_data |&gt; filter(player_category == \"ruth\"),\n    color = colors$palette$ruth,\n    linewidth = 1.1\n  ) +\n  geom_line(\n    data = race_data |&gt; filter(player_category == \"mcgwire\"),\n    color = colors$palette$mcgwire,\n    linewidth = 1.4\n  ) +\n  # Annotations\n  annotate(\n    \"text\",\n    x = 1500, y = 545,\n    label = \"McGwire*\\n1,688 games\",\n    hjust = 0.5, vjust = 0,\n    size = 3.6,\n    color = colors$palette$mcgwire,\n    fontface = \"bold\"\n  ) +\n  annotate(\n    \"text\",\n    x = 1820, y = 585,\n    label = \"Ruth\\n1,790 games\\n(fastest clean)\",\n    hjust = 0, vjust = 0.5,\n    size = 3.3,\n    color = colors$palette$ruth,\n    fontface = \"bold\",\n    lineheight = 0.9\n  ) +\n  annotate(\n    \"text\",\n    x = 3200, y = 515,\n    label = \"Murray\\n2,971 games\\n(slowest)\",\n    hjust = 1, vjust = 0,\n    size = 3.3,\n    color = colors$palette$murray,\n    fontface = \"bold\",\n    lineheight = 0.9\n  ) +\n  annotate(\n    \"text\",\n    x = 80, y = 515,\n    label = \"500 HR milestone\",\n    hjust = 0, vjust = 0,\n    size = 3.1,\n    color = colors$palette$milestone\n  ) +\n  # Scales\n  scale_x_continuous(\n    labels = scales::comma,\n    limits = c(0, 3200),\n    breaks = seq(0, 3000, 500),\n    expand = c(0.02, 0)\n  ) +\n  scale_y_continuous(\n    limits = c(0, 600),\n    breaks = seq(0, 500, 100)\n  ) +\n  coord_cartesian(clip = \"off\") +\n  # Labs\n  labs(\n    title    = title_text,\n    subtitle = subtitle_text,\n    caption  = caption_text,\n    x        = \"Games played\",\n    y        = \"Cumulative home runs\"\n  ) +\n  # Theme\n  theme(\n    plot.title = element_markdown(\n      size = rel(2),\n      family = fonts$title,\n      face = \"bold\",\n      color = colors$title,\n      lineheight = 1.15,\n      margin = margin(t = 5, b = 5)\n    ),\n    plot.subtitle = element_markdown(\n      size = rel(0.8),\n      family = fonts$subtitle,\n      color = alpha(colors$subtitle, 0.88),\n      lineheight = 1.3,\n      margin = margin(t = 5, b = 20)\n    ),\n    plot.caption = element_markdown(\n      size = rel(0.55),\n      family = fonts$subtitle,\n      color = colors$caption,\n      hjust = 0,\n      lineheight = 1.4,\n      margin = margin(t = 20, b = 5)\n    ),\n    axis.title = element_text(size = 10, color = \"gray35\"),\n    axis.text = element_text(size = 9,  color = \"gray35\")\n  )\n```\n\n\n7. Save\n\nShow code```{r}\n#| label: save\n\n### |-  plot image ----  \nsave_plot(\n  p, \n  type = 'swd', \n  year = 2025, \n  month = 12, \n  width  = 10,\n  height = 8,\n  )\n```\n\n\n8. Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] here_1.0.1      Lahman_13.0-0   glue_1.8.0      scales_1.3.0   \n [5] janitor_2.2.0   showtext_0.9-7  showtextdb_3.0  sysfonts_0.8.9 \n [9] ggtext_0.1.2    lubridate_1.9.3 forcats_1.0.0   stringr_1.5.1  \n[13] dplyr_1.1.4     purrr_1.0.2     readr_2.1.5     tidyr_1.3.1    \n[17] tibble_3.2.1    ggplot2_3.5.1   tidyverse_2.0.0 pacman_0.5.1   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 tzdb_0.5.0       \n [5] vctrs_0.6.5       tools_4.4.0       generics_0.1.3    curl_6.0.0       \n [9] gifski_1.32.0-1   fansi_1.0.6       pkgconfig_2.0.3   lifecycle_1.0.4  \n[13] compiler_4.4.0    farver_2.1.2      textshaping_0.4.0 munsell_0.5.1    \n[17] codetools_0.2-20  snakecase_0.11.1  htmltools_0.5.8.1 yaml_2.3.10      \n[21] pillar_1.9.0      camcorder_0.1.0   magick_2.8.5      commonmark_1.9.2 \n[25] tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4     rsvg_2.6.1       \n[29] rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.0        colorspace_2.1-1 \n[33] cli_3.6.4         magrittr_2.0.3    utf8_1.2.4        withr_3.0.2      \n[37] timechange_0.3.0  rmarkdown_2.29    ragg_1.3.3        hms_1.1.3        \n[41] evaluate_1.0.1    knitr_1.49        markdown_1.13     rlang_1.1.6      \n[45] gridtext_0.1.5    Rcpp_1.0.13-1     xml2_1.3.6        renv_1.0.3       \n[49] svglite_2.1.3     rstudioapi_0.17.1 jsonlite_1.8.9    R6_2.5.1         \n[53] systemfonts_1.1.0\n\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in swd_2025_12.qmd. For the full repository, click here.\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\nData Sources:\n\nLahman Baseball Database: Sean Lahmanâ€™s Baseball Database via the {Lahman} R package\nPED Information: ESPN - The Steroids Era\n\n\nSWD Challenge: - Storytelling with Data: December 2025 - When Less is Better\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\n\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\n\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\n\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualizations/MakeoverMonday/2025/mm_2025_47.html",
    "href": "data_visualizations/MakeoverMonday/2025/mm_2025_47.html",
    "title": "Pet cats rest 70â€“80% of the day regardless of season",
    "section": "",
    "text": "Original\nThe original visualization comes from Do cats really loaf all day?\n\n\nOriginal visualization\n\nMakeover\n\n\n\n\n\nFigureÂ 1: Two-panel chart examining cat resting behavior. Left panel: Scatter plot comparing 28 catsâ€™ resting time in summer (x-axis) versus winter (y-axis), ranging from 55-90%. Points cluster along the diagonal â€˜no changeâ€™ line, mostly within 70-80%, indicating minimal seasonal variation. Blue points represent indoor cats, orange points represent indoor & outdoor cats. Right panel: Dot plots showing resting time by household environment. Cats in homes with children rest slightly less (~70%) than those without (~75%), while dog presence shows minimal difference. Individual cats are shown as points with mean Â± SE bars overlaid.\n\n\nSteps to Create this Graphic \n1. Load Packages & Setup\n\nShow code```{r}\n#| label: load\n#| warning: false\n#| message: false\n#| results: \"hide\"\n\n## 1. LOAD PACKAGES & SETUP ----\nsuppressPackageStartupMessages({\n  if (!require(\"pacman\")) install.packages(\"pacman\")\n  pacman::p_load(\n    tidyverse,     # Easily Install and Load the 'Tidyverse'\n    janitor,       # Simple Tools for Examining and Cleaning Dirty Data\n    skimr,         # Compact and Flexible Summaries of Data\n    scales,        # Scale Functions for Visualization\n    ggtext,        # Improved Text Rendering Support for 'ggplot2'\n    showtext,      # Using Fonts More Easily in R Graphs\n    glue,          # Interpreted String Literals\n    patchwork      # The Composer of Plots\n)\n})\n\n### |- figure size ----\ncamcorder::gg_record(\n    dir    = here::here(\"temp_plots\"),\n    device = \"png\",\n    width  = 10,\n    height = 8,\n    units  = \"in\",\n    dpi    = 320\n)\n\n# Source utility functions\nsuppressMessages(source(here::here(\"R/utils/fonts.R\")))\nsource(here::here(\"R/utils/social_icons.R\"))\nsource(here::here(\"R/utils/image_utils.R\"))\nsource(here::here(\"R/themes/base_theme.R\"))\n```\n\n\n2. Read in the Data\n\nShow code```{r}\n#| label: read\n#| include: true\n#| eval: true\n#| warning: false\n#|\n\ncats_data &lt;- read_csv(\n  here::here(\"data/MakeoverMonday/2025/cats_data.csv\")) |&gt;\n  clean_names()\n```\n\n\n3. Examine the Data\n\nShow code```{r}\n#| label: examine\n#| include: true\n#| eval: true\n#| results: 'hide'\n#| warning: false\n\nglimpse(cats_data)\nskim(cats_data) |&gt; summary()\n```\n\n\n4. Tidy Data\n\nShow code```{r}\n#| label: tidy\n#| warning: false\n\n### |- clean and factor variables ----\ncats_clean &lt;- cats_data |&gt;\n  mutate(\n    season = factor(season, levels = c(\"Summer\", \"Winter\")),\n    cat_age = factor(cat_age, levels = c(\"Junior\", \"Prime\", \"Mature\")),\n    bcs_ord = factor(bcs_ord, levels = c(\"Ideal\", \"Overweight\", \"Heavy\", \"Obese\")),\n    housing = factor(housing,\n      levels = c(\"Indoor\", \"Indoor Outdoor\"),\n      labels = c(\"Indoor\", \"Indoor & Outdoor\")\n    ),\n    area = factor(area, levels = c(\"Urban\", \"Rural\")),\n    cat2 = factor(cat2, levels = c(\"Single\", \"Multi\")),\n    children = factor(children,\n      levels = c(\"No\", \"Yes\"),\n      labels = c(\"No Children\", \"With Children\")\n    ),\n    dog = factor(dog,\n      levels = c(\"No\", \"Yes\"),\n      labels = c(\"No Dog\", \"With Dog\")\n    )\n  ) |&gt;\n  mutate(\n    resting_sec = lying + sitting,\n    prop_resting = prop_lying + prop_sitting,\n    pct_resting = prop_resting * 100,\n    pct_lying = prop_lying * 100,\n    pct_sitting = prop_sitting * 100,\n    pct_active = prop_active * 100,\n    pct_standing = prop_standing * 100,\n    pct_grooming = prop_grooming * 100,\n    pct_eating = prop_eating * 100,\n    pct_scratching = prop_scratching * 100,\n    pct_littering = prop_littering * 100\n  )\n\n### |- wide format for seasonal comparisons ----\ncats_seasonal &lt;- cats_clean |&gt;\n  select(\n    cat_id, season, pct_resting, pct_lying, pct_sitting, pct_active,\n    pct_standing, pct_grooming, pct_eating,\n    cat_age, cat_sex, bcs, bcs_ord, housing, area, diet, children, cat2, dog\n  ) |&gt;\n  pivot_wider(\n    names_from = season,\n    values_from = c(\n      pct_resting, pct_lying, pct_sitting, pct_active,\n      pct_standing, pct_grooming, pct_eating\n    ),\n    names_glue = \"{.value}_{season}\"\n  ) |&gt;\n  mutate(\n    resting_diff = pct_resting_Winter - pct_resting_Summer,\n    resting_avg = (pct_resting_Winter + pct_resting_Summer) / 2,\n    active_diff = pct_active_Winter - pct_active_Summer\n  ) |&gt;\n  # Keep only cats with complete data (n = 28)\n  filter(!is.na(pct_resting_Summer) & !is.na(pct_resting_Winter))\n\n### |- prepare environmental effects data ----\nenv_effects &lt;- cats_clean |&gt;\n  select(cat_id, season, pct_resting, children, dog, housing) |&gt;\n  pivot_longer(\n    cols = c(children, dog),\n    names_to = \"factor_type\",\n    values_to = \"factor_level\"\n  ) |&gt;\n  mutate(\n    factor_type = case_when(\n      factor_type == \"children\" ~ \"Children in household\",\n      factor_type == \"dog\" ~ \"Dog in household\"\n    ),\n    factor_type = factor(factor_type,\n      levels = c(\"Children in household\", \"Dog in household\")\n    )\n  )\n\n### |- calculate means ----\nenv_means &lt;- env_effects |&gt;\n  group_by(factor_type, factor_level, season) |&gt;\n  summarise(\n    mean_pct = mean(pct_resting, na.rm = TRUE),\n    se_pct = sd(pct_resting, na.rm = TRUE) / sqrt(n()),\n    n = n(),\n    .groups = \"drop\"\n  )\n\n### |- calculate medians ----\nmedian_summer &lt;- median(cats_seasonal$pct_resting_Summer, na.rm = TRUE)\nmedian_winter &lt;- median(cats_seasonal$pct_resting_Winter, na.rm = TRUE)\n\n# \"Lazy band\" (most cats spend 70â€“80% of the day resting)\nlazy_low  &lt;- 70\nlazy_high &lt;- 80\n\n# data frame for lazy band per facet\nlazy_band_df &lt;- tibble(\n  factor_type = factor(\n    levels(env_effects$factor_type),\n    levels = levels(env_effects$factor_type)\n  ),\n  xmin = -Inf, xmax = Inf,\n  ymin = lazy_low, ymax = lazy_high\n)\n```\n\n\n5. Visualization Parameters\n\nShow code```{r}\n#| label: params\n#| include: true\n#| warning: false\n\n### |-  plot aesthetics ----\n# Get base colors with custom palette\ncolors &lt;- get_theme_colors(\n  palette = list(\n    col_indoor  = \"#2C5F8D\",\n    col_outdoor = \"#E07B42\",\n    col_summer = \"#D4952A\",\n    col_winter = \"#6AADC4\",\n    col_gray = \"gray45\",\n    col_gray_light = \"gray70\",\n    col_grid = \"gray92\"        \n  )\n)\n\n### |-  Main titles ----\ntitle_text &lt;- \"Pet cats rest 70â€“80% of the day regardless of season\"\nsubtitle_text &lt;- str_glue(\n  \"Accelerometer data from 28 New Zealand cats shows most time is spent lying or sitting,&lt;br&gt;\",\n  \"with only small differences by season, housing, or household environment.\"\n)\n\n### |-  Data source caption ----\ncaption_text &lt;- create_mm_caption(\n  mm_year = 2025,\n  mm_week = 47,\n  source_text = str_glue(\n    \"Smit et al. (2024) Sensors&lt;br&gt;\",\n    \"**Note:** haded band = 70â€“80% of day resting | Dashed lines in panel A = medians | Points = individual cats, bars = mean Â± SE\"\n  )\n)\n\n### |-  fonts ----\nsetup_fonts()\nfonts &lt;- get_font_families()\n\n### |-  plot theme ----\n\n# Start with base theme\nbase_theme &lt;- create_base_theme(colors)\n\n# Add weekly-specific theme elements\nweekly_theme &lt;- extend_weekly_theme(\n  base_theme,\n  theme(\n    # # Text styling\n    plot.title = element_text(\n      size = rel(1.5), family = fonts$title, face = \"bold\",\n      color = colors$title, lineheight = 1.1, hjust = 0,\n      margin = margin(t = 5, b = 10)\n    ),\n    plot.subtitle = element_markdown(\n      size = rel(0.9), family = fonts$subtitle, face = \"italic\",\n      color = alpha(colors$subtitle, 0.9), lineheight = 1.1,\n      margin = margin(t = 0, b = 20)\n    ),\n\n    # Legend formatting\n    legend.position = \"plot\",\n    legend.justification = \"top\",\n    legend.margin = margin(l = 12, b = 5),\n    legend.key.size = unit(0.8, \"cm\"),\n    legend.box.margin = margin(b = 10),\n    # legend.title = element_text(face = \"bold\"),\n\n    # Axis formatting\n    axis.ticks.y = element_blank(),\n    axis.ticks.x = element_line(color = \"gray\", linewidth = 0.5),\n    \n    axis.title.x = element_text(\n      face = \"bold\", size = rel(0.85),\n      margin = margin(t = 10), family = fonts$subtitle,\n      color = \"gray40\" \n    ),\n    axis.title.y = element_text(\n      face = \"bold\", size = rel(0.85),\n      margin = margin(r = 10), family = fonts$subtitle,\n      color = \"gray40\" \n    ),\n    axis.text.x = element_text(\n      size = rel(0.85), family = fonts$subtitle,\n      color = \"gray40\"  \n    ),\n    axis.text.y = element_markdown(\n      size = rel(0.85), family = fonts$subtitle,\n      color = \"gray40\"\n    ),\n\n    # Grid lines\n    panel.grid.minor = element_line(color = \"#ecf0f1\", linewidth = 0.2),\n    panel.grid.major = element_line(color = \"#ecf0f1\", linewidth = 0.4),\n\n    # Margin\n    plot.margin = margin(20, 20, 20, 20)\n  )\n)\n\n# Set theme\ntheme_set(weekly_theme)\n```\n\n\n6. Plot\n\nShow code```{r}\n#| label: plot\n#| warning: false\n\n### |- SCATTER PLOT (Panel A) ----\np1 &lt;- ggplot(cats_seasonal, aes(x = pct_resting_Summer, y = pct_resting_Winter)) +\n  # Lazy band\n  annotate(\n    \"rect\",\n    xmin = lazy_low, xmax = lazy_high,\n    ymin = lazy_low, ymax = lazy_high,\n    fill = \"grey60\", alpha = 0.06\n  ) +\n  # Diagonal & medians\n  geom_abline(\n    slope = 1, intercept = 0,\n    linetype = \"dashed\", color = colors$palette$col_gray_light, linewidth = 0.7\n  ) +\n  geom_vline(\n    xintercept = median_summer,\n    linetype = \"dashed\", color = colors$palette$col_gray, linewidth = 0.5\n  ) +\n  geom_hline(\n    yintercept = median_winter,\n    linetype = \"dashed\", color = colors$palette$col_gray, linewidth = 0.5\n  ) +\n  geom_point(aes(color = housing), size = 3.5, alpha = 0.9) +\n  # Annotations\n  annotate(\"text\",\n           x = 57, y = 91,\n           label = \"More active in summer\\nLazier in winter\",\n           hjust = 0, vjust = 1, size = 2.8, color = colors$palette$col_gray\n  ) +\n  annotate(\"text\",\n           x = 91.5, y = 91.5,\n           label = \"Consistently lazy\",\n           hjust = 1, vjust = 1, size = 2.8, color = colors$palette$col_gray\n  ) +\n  annotate(\"text\",\n           x = 57, y = 56,\n           label = \"Consistently active\",\n           hjust = 0, vjust = 0, size = 2.8, color = colors$palette$col_gray\n  ) +\n  annotate(\"text\",\n           x = 91.5, y = 56,\n           label = \"Lazier in summer\\nMore active in winter\",\n           hjust = 1, vjust = 0, size = 2.8, color = colors$palette$col_gray\n  ) +\n  annotate(\"text\",\n           x = 88, y = 86,\n           label = \"No change\",\n           hjust = 1, size = 2.6, color = colors$palette$col_gray_light, angle = 45\n  ) +\n  # Scales\n  scale_color_manual(\n    values = c(\"Indoor\" = colors$palette$col_indoor, \"Indoor & Outdoor\" = colors$palette$col_outdoor),\n    name = \"Housing:\"\n  ) +\n  coord_fixed(xlim = c(55, 93), ylim = c(55, 93)) +\n  # Labs\n  labs(\n    x = \"Summer: % of day spent resting\",\n    y = \"Winter: % of day spent resting\"\n  ) +\n  guides(\n    color = guide_legend(override.aes = list(size = 3))\n  ) +\n  # Theme\n  theme(\n    legend.position = \"top\",\n    legend.justification = \"left\",\n    legend.title = element_text(face = \"bold\", size = 9),\n    legend.text = element_text(size = 9),\n    legend.margin = margin(b = 5),\n    legend.box.margin = margin(b = -5),\n    panel.grid.minor = element_blank(),\n    plot.margin = margin(5, 10, 5, 5)\n  )\n\n### |- DOT PLOT (Panel B) ----\np2 &lt;- env_effects |&gt;\n  ggplot(aes(x = factor_level, y = pct_resting, color = season)) +\n  # Lazy band\n  geom_rect(\n    data = lazy_band_df,\n    aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax),\n    inherit.aes = FALSE,\n    fill = \"grey60\",\n    alpha = 0.06\n  ) +\n  # Individual cats\n  geom_point(\n    position = position_jitterdodge(jitter.width = 0.12, dodge.width = 0.5, seed = 42),\n    alpha = 0.45,\n    size = 1.8\n  ) +\n  # Means with SE\n  geom_pointrange(\n    data = env_means,\n    aes(\n      x = factor_level, y = mean_pct,\n      ymin = mean_pct - se_pct, ymax = mean_pct + se_pct,\n      color = season\n    ),\n    position = position_dodge(width = 0.5),\n    size = 0.6,\n    linewidth = 0.7,\n    show.legend = FALSE\n  ) +\n  # Facet\n  facet_wrap(~factor_type, scales = \"free_x\") +\n  # Scales\n  scale_color_manual(\n    values = c(\"Summer\" = colors$palette$col_summer, \"Winter\" = colors$palette$col_winter),\n    name = \"Season:\"\n  ) +\n  scale_y_continuous(\n    limits = c(55, 93),\n    breaks = seq(60, 90, 10),\n    labels = label_percent(accuracy = 1, scale = 1)\n  ) +\n  # Labs\n  labs(\n    x = NULL,\n    y = \"% of day spent resting\"\n  ) +\n  guides(\n    color = guide_legend(override.aes = list(size = 3))\n  ) +\n  # Theme\n  theme(\n    legend.position = \"top\",\n    legend.justification = \"left\",\n    legend.title = element_text(face = \"bold\", size = 9),\n    legend.text = element_text(size = 9),\n    legend.margin = margin(b = 5),\n    legend.box.margin = margin(b = -5),\n    strip.text = element_text(face = \"bold\", size = 10),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank(),\n    plot.margin = margin(5, 5, 5, 10)\n  )\n\n### |- COMBINED PLOTS ----\ncombined_plots &lt;- p1 + p2 +\n  plot_layout(widths = c(1.2, 1)) +\n  plot_annotation(\n    title = title_text,\n    subtitle = subtitle_text,\n    caption = caption_text,\n    # tag_levels = \"A\",\n    theme = theme(\n      plot.title = element_text(\n        size = rel(1.95),\n        family = fonts$title,\n        face = \"bold\",\n        color = colors$title,\n        lineheight = 1.1,\n        margin = margin(t = 5, b = 5)\n      ),\n      plot.subtitle = element_markdown(\n        size = rel(0.95),\n        family = fonts$subtitle,\n        color = alpha(colors$subtitle, 0.9),\n        lineheight = 1.5,\n        margin = margin(t = 5, b = 25)\n      ),\n      plot.caption = element_markdown(\n        size = rel(0.55),\n        family = fonts$caption,\n        color = 'gray50',\n        hjust = 0,\n        lineheight = 1.2,\n        margin = margin(t = 10, b = 10)\n      ),\n      panel.grid.major = element_blank(),\n      panel.grid.minor = element_blank(),\n      axis.ticks = element_blank()\n    )\n  )\n```\n\n\n7. Save\n\nShow code```{r}\n#| label: save\n#| warning: false\n\n### |-  plot image ----  \nsave_plot_patchwork(\n  plot = combined_plots, \n  type = \"makeovermonday\", \n  year = current_year,\n  week = current_week,\n  width = 10, \n  height = 8\n  )\n```\n\n\n8. Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] here_1.0.1      patchwork_1.3.0 glue_1.8.0      showtext_0.9-7 \n [5] showtextdb_3.0  sysfonts_0.8.9  ggtext_0.1.2    scales_1.3.0   \n [9] skimr_2.1.5     janitor_2.2.0   lubridate_1.9.3 forcats_1.0.0  \n[13] stringr_1.5.1   dplyr_1.1.4     purrr_1.0.2     readr_2.1.5    \n[17] tidyr_1.3.1     tibble_3.2.1    ggplot2_3.5.1   tidyverse_2.0.0\n[21] pacman_0.5.1   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6       xfun_0.49          htmlwidgets_1.6.4  tzdb_0.5.0        \n [5] yulab.utils_0.1.8  vctrs_0.6.5        tools_4.4.0        generics_0.1.3    \n [9] curl_6.0.0         parallel_4.4.0     gifski_1.32.0-1    fansi_1.0.6       \n[13] pkgconfig_2.0.3    ggplotify_0.1.2    lifecycle_1.0.4    compiler_4.4.0    \n[17] farver_2.1.2       munsell_0.5.1      repr_1.1.7         codetools_0.2-20  \n[21] snakecase_0.11.1   htmltools_0.5.8.1  yaml_2.3.10        crayon_1.5.3      \n[25] pillar_1.9.0       camcorder_0.1.0    magick_2.8.5       commonmark_1.9.2  \n[29] tidyselect_1.2.1   digest_0.6.37      stringi_1.8.4      labeling_0.4.3    \n[33] rsvg_2.6.1         rprojroot_2.0.4    fastmap_1.2.0      grid_4.4.0        \n[37] colorspace_2.1-1   cli_3.6.4          magrittr_2.0.3     base64enc_0.1-3   \n[41] utf8_1.2.4         withr_3.0.2        bit64_4.5.2        timechange_0.3.0  \n[45] rmarkdown_2.29     bit_4.5.0          hms_1.1.3          evaluate_1.0.1    \n[49] knitr_1.49         markdown_1.13      gridGraphics_0.5-1 rlang_1.1.6       \n[53] gridtext_0.1.5     Rcpp_1.0.13-1      xml2_1.3.6         renv_1.0.3        \n[57] vroom_1.6.5        svglite_2.1.3      rstudioapi_0.17.1  jsonlite_1.8.9    \n[61] R6_2.5.1           fs_1.6.5           systemfonts_1.1.0 \n\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in mm_2025_47.qmd.\nFor the full repository, click here.\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\n\n\nData:\n\nMakeover Monday 2025 Week 47: Do cats really loaf all day?\n\n\n\n\nArticle\n\nDo cats really loaf all day?\n\n\n\nCitations:\n\nSmit, M., Corner-Thomas, R. A., Draganova, I., Andrews, C. J., & Thomas, D. G. (2024). How Lazy Are Pet Cats Really? Using Machine Learning and Accelerometry to Get a Glimpse into the Behaviour of Privately Owned Cats in Different Households. Sensors, 24(8), 2623. https://doi.org/10.3390/s24082623\nSmit, M. (2023). Weekly data cats for home trial. figshare. Dataset. https://doi.org/10.6084/m9.figshare.24848292.v2\n\n\n\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\n\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\n\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\n\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualizations/TidyTuesday/2025/tt_2025_49_______________________.html",
    "href": "data_visualizations/TidyTuesday/2025/tt_2025_49_______________________.html",
    "title": "The BÃ¶Ã¶gg Cannot Predict Record Hot Summers",
    "section": "",
    "text": "FigureÂ 1: Scatter plot testing Swiss folklore that a faster BÃ¶Ã¶gg explosion predicts a hotter summer. A dotted diagonal line shows the expected negative relationship, but the data contradicts it: record hot summers (large red points above 19Â°C threshold) are scattered across all burn durations from 4 to 60 minutes. The 2003 European heat wave had a fast 7-minute burn, while 2023â€™s record summer had a slow 57-minute burn. Correlation is +0.19, opposite to folkloreâ€™s prediction.\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in tt_2025_48.qmd.\nFor the full repository, click here.\n\n\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\n\nData Source:\n\nTidyTuesday 2025 Week 48: Can an exploding snowman predict the summer season?\n\n\n\n\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n\n\n Back to topCitationBibTeX citation:@online{ponce2025,\n  author = {Ponce, Steven},\n  title = {The {BÃ¶Ã¶gg} {Cannot} {Predict} {Record} {Hot} {Summers}},\n  date = {2025-11-29},\n  url = {https://stevenponce.netlify.app/data_visualizations/TidyTuesday/2025/tt_2025_49.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPonce, Steven. 2025. â€œThe BÃ¶Ã¶gg Cannot Predict Record Hot\nSummers.â€ November 29, 2025. https://stevenponce.netlify.app/data_visualizations/TidyTuesday/2025/tt_2025_49.html."
  },
  {
    "objectID": "data_visualizations/MakeoverMonday/2025/mm_2025_48.html",
    "href": "data_visualizations/MakeoverMonday/2025/mm_2025_48.html",
    "title": "AI Model Performance: Accuracy vs.Â Hallucination",
    "section": "",
    "text": "Original\nThe original visualization comes from Which AI Models Hallucinate the Most?\n\n\nOriginal visualization\n\nMakeover\n\n\n\n\n\nFigureÂ 1: Two-panel chart showing AI model performance. The top panel displays performance cards for the six best models (Claude 4.1 Opus, Claude 4.5 Sonnet, Grok 4, Magistral Medium 7.2, GPT-5 high, and Kimi K2 0905) with their accuracy, hallucination rates, and combined scores. The bottom panel shows a scatterplot of all 18 models, plotting accuracy versus hallucination rate, with the top 6 models labeled and highlighted. Proprietary models (blue) cluster in the high accuracy, low hallucination zone, while open-weight models (coral) show more varied performance.\n\n\nSteps to Create this Graphic \n1. Load Packages & Setup\n\nShow code```{r}\n#| label: load\n#| warning: false\n#| message: false\n#| results: \"hide\"\n\n## 1. LOAD PACKAGES & SETUP ----\nsuppressPackageStartupMessages({\n  if (!require(\"pacman\")) install.packages(\"pacman\")\n  pacman::p_load(\n    tidyverse,     # Easily Install and Load the 'Tidyverse'\n    janitor,       # Simple Tools for Examining and Cleaning Dirty Data\n    skimr,         # Compact and Flexible Summaries of Data\n    scales,        # Scale Functions for Visualization\n    ggtext,        # Improved Text Rendering Support for 'ggplot2'\n    showtext,      # Using Fonts More Easily in R Graphs\n    glue,          # Interpreted String Literals\n    patchwork,     # The Composer of Plots\n    ggrepel        # Automatically Position Non-Overlapping Text Labels with ggplot2\n)\n})\n\n### |- figure size ----\ncamcorder::gg_record(\n    dir    = here::here(\"temp_plots\"),\n    device = \"png\",\n    width  = 12,\n    height = 14,\n    units  = \"in\",\n    dpi    = 320\n)\n\n# Source utility functions\nsuppressMessages(source(here::here(\"R/utils/fonts.R\")))\nsource(here::here(\"R/utils/social_icons.R\"))\nsource(here::here(\"R/utils/image_utils.R\"))\nsource(here::here(\"R/themes/base_theme.R\"))\n```\n\n\n2. Read in the Data\n\nShow code```{r}\n#| label: read\n#| include: true\n#| eval: true\n#| warning: false\n#|\n\nai_models &lt;- readxl::read_excel(\n   here::here(\"data/MakeoverMonday/2025/AI Model Hallucination Scores.xlsx\")) |&gt;\n  clean_names()\n```\n\n\n3. Examine the Data\n\nShow code```{r}\n#| label: examine\n#| include: true\n#| eval: true\n#| results: 'hide'\n#| warning: false\n\nglimpse(ai_models)\nskim(ai_models) |&gt; summary()\n```\n\n\n4. Tidy Data\n\nShow code```{r}\n#| label: tidy\n#| warning: false\n\n### |-  data wrangling ----\nai_models_tidy &lt;- ai_models |&gt;\n  mutate(\n    model_type = case_when(\n      str_detect(model, \"Claude|GPT-5|Gemini|Grok\") ~ \"Proprietary\",\n      str_detect(model, \"DeepSeek|Llama|Qwen|GPT-OSS|Kimi|Magistral\") ~ \"Open Weights\",\n      TRUE ~ \"Unknown\"\n    ),\n    model_family = case_when(\n      str_detect(model, \"Claude\") ~ \"Claude\",\n      str_detect(model, \"GPT\") ~ \"GPT\",\n      str_detect(model, \"Gemini\") ~ \"Gemini\",\n      str_detect(model, \"Grok\") ~ \"Grok\",\n      str_detect(model, \"DeepSeek\") ~ \"DeepSeek\",\n      str_detect(model, \"Llama\") ~ \"Llama\",\n      str_detect(model, \"Qwen\") ~ \"Qwen\",\n      str_detect(model, \"Kimi\") ~ \"Kimi\",\n      str_detect(model, \"Magistral\") ~ \"Magistral\",\n      TRUE ~ \"Other\"\n    ),\n    model_short = str_remove(model, \" v\\\\d+\\\\.\\\\d+$\") |&gt;\n      str_remove(\" BA\\\\d+B \\\\d+$\"),\n    median_accuracy = median(accuracy_index_higher_is_better),\n    median_hallucination = median(hallucination_index_lower_is_better),\n    quadrant = case_when(\n      accuracy_index_higher_is_better &gt; median_accuracy &\n        hallucination_index_lower_is_better &lt; median_hallucination ~\n        \"High Accuracy, Low Hallucination\",\n      accuracy_index_higher_is_better &gt; median_accuracy &\n        hallucination_index_lower_is_better &gt;= median_hallucination ~\n        \"High Accuracy, High Hallucination\",\n      accuracy_index_higher_is_better &lt;= median_accuracy &\n        hallucination_index_lower_is_better &lt; median_hallucination ~\n        \"Low Accuracy, Low Hallucination\",\n      TRUE ~ \"Low Accuracy, High Hallucination\"\n    ),\n    combined_score = accuracy_index_higher_is_better - hallucination_index_lower_is_better,\n    rank_combined = rank(-combined_score, ties.method = \"min\"),\n    rank_label = glue(\"Rank {rank_combined} of {n()}\")\n  )\n\nmedian_acc &lt;- median(ai_models_tidy$accuracy_index_higher_is_better)\nmedian_hall &lt;- median(ai_models_tidy$hallucination_index_lower_is_better)\n\ntop_6_models &lt;- ai_models_tidy |&gt;\n  arrange(desc(combined_score)) |&gt;\n  slice_head(n = 6)\n```\n\n\n5. Visualization Parameters\n\nShow code```{r}\n#| label: params\n#| include: true\n#| warning: false\n\n### |-  plot aesthetics ----\n# Get base colors with custom palette\ncolors &lt;- get_theme_colors(\n  palette = list(\n   proprietary   = \"#0077B6\",\n    open_weights  = \"#E07A5F\",\n    neutral_light = \"#E8F4F8\",\n    neutral_mid   = \"#90C9E8\",\n    success       = \"#06A77D\"    \n  )\n)\n\n### |-  Main titles ----\ntitle_text    &lt;- \"AI Model Performance: Accuracy vs. Hallucination\"\nsubtitle_text &lt;- \"Top 6 models by combined accuracyâ€“hallucination score, shown in context of 18 leading AI models\"\n\n\n### |-  Data source caption ----\ncaption_text &lt;- create_mm_caption(\n  mm_year = 2025,\n  mm_week = 48,\n  source_text = str_glue(\n     \"artificialanalysis.ai (AA-Omniscience Index)\"\n  )\n)\n\n### |-  fonts ----\nsetup_fonts()\nfonts &lt;- get_font_families()\n\n### |-  plot theme ----\n\n# Start with base theme\nbase_theme &lt;- create_base_theme(colors)\n\n# Add weekly-specific theme elements\nweekly_theme &lt;- extend_weekly_theme(\n  base_theme,\n  theme(\n    # # Text styling\n    plot.title = element_text(\n      size = rel(1.5), family = fonts$title, face = \"bold\",\n      color = colors$title, lineheight = 1.1, hjust = 0,\n      margin = margin(t = 5, b = 10)\n    ),\n    plot.subtitle = element_markdown(\n      size = rel(0.9), family = fonts$subtitle, face = \"italic\",\n      color = alpha(colors$subtitle, 0.9), lineheight = 1.1,\n      margin = margin(t = 0, b = 20)\n    ),\n\n    # Legend formatting\n    legend.position = \"plot\",\n    legend.justification = \"right\",\n    legend.margin = margin(l = 12, b = 5),\n    legend.key.size = unit(0.8, \"cm\"),\n    legend.box.margin = margin(b = 10),\n    # legend.title = element_text(face = \"bold\"),\n\n    # Axis formatting\n    axis.ticks.y = element_blank(),\n    axis.ticks.x = element_line(color = \"gray\", linewidth = 0.5),\n    \n    axis.title.x = element_text(\n      face = \"bold\", size = rel(0.85),\n      margin = margin(t = 10), family = fonts$subtitle,\n      color = \"gray40\" \n    ),\n    axis.title.y = element_text(\n      face = \"bold\", size = rel(0.85),\n      margin = margin(r = 10), family = fonts$subtitle,\n      color = \"gray40\" \n    ),\n    axis.text.x = element_text(\n      size = rel(0.85), family = fonts$subtitle,\n      color = \"gray40\"  \n    ),\n    axis.text.y = element_markdown(\n      size = rel(0.85), family = fonts$subtitle,\n      color = \"gray40\"\n    ),\n\n    # Grid lines\n    panel.grid.minor = element_line(color = \"#ecf0f1\", linewidth = 0.2),\n    panel.grid.major = element_line(color = \"#ecf0f1\", linewidth = 0.4),\n\n    # Margin\n    plot.margin = margin(20, 20, 20, 20)\n  )\n)\n\n# Set theme\ntheme_set(weekly_theme)\n```\n\n\n6. Plot\n\nShow code```{r}\n#| label: plot\n#| warning: false\n\n### |- PANEL 1: SCORE CARDS ----\np1 &lt;- top_6_models |&gt;\n  ggplot(aes(x = 1, y = 1)) +\n  # Geoms\n  geom_tile(\n    aes(fill = model_type),\n    alpha = 0.18,\n    linewidth = 3\n  ) +\n  geom_text(\n    aes(label = glue(\n      \"{rank_label}\\n\\n\",\n      \"Accuracy: {percent(accuracy_index_higher_is_better, accuracy = 1)}\\n\",\n      \"Hallucination: {percent(hallucination_index_lower_is_better, accuracy = 1)}\\n\\n\",\n      \"Combined score: {sprintf('%.2f', combined_score)}\"\n    )),\n    size = 3.8,\n    lineheight = 1.1,\n    fontface = \"plain\",\n    color = \"gray20\"\n  ) +\n  # Facets\n  facet_wrap(\n    ~ reorder(model_short, -combined_score),\n    ncol   = 3,\n    scales = \"free\"\n  ) +\n  # Scales\n  scale_fill_manual(\n    values = c(\n      \"Proprietary\" = colors$palette$proprietary,\n      \"Open Weights\" = colors$palette$open_weights\n    ),\n    name = NULL\n  ) +\n  # Labs\n  labs(title = \"Top 6 Models by Combined Performance\") +\n  # Theme\n  theme(\n    legend.position = \"top\",\n    legend.direction = \"horizontal\",\n    legend.text = element_text(size = 9, face = \"bold\"),\n    strip.text = element_text(\n      size = rel(1),\n      face = \"bold\",\n      hjust = 0.5,\n      margin = margin(t = 4, b = 4)\n    ),\n    plot.margin = weekly_theme$plot.margin,\n    panel.spacing = unit(10, \"pt\"),\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank(),\n    axis.text.x = element_blank(),\n    axis.text.y = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.grid.major = element_blank()\n  )\n\n### |- PANEL 2: SCATTERPLOT ----\np2 &lt;- ai_models_tidy |&gt;\n  ggplot(aes(\n    x = hallucination_index_lower_is_better,\n    y = accuracy_index_higher_is_better\n  )) +\n  # Annotate\n  annotate(\n    \"rect\",\n    xmin = -Inf, xmax = median_hall,\n    ymin = median_acc, ymax = Inf,\n    fill = colors$palette$neutral_light, alpha = 0.5\n  ) +\n  annotate(\n    \"text\",\n    x = median_hall * 0.6,\n    y = Inf,\n    label = \"IDEAL ZONE\\nHigh accuracy\\nLow hallucination\",\n    vjust = 1.25,\n    size = 3,\n    color = \"gray40\",\n    fontface = \"bold\",\n    lineheight = 0.9\n  ) +\n  # Geoms\n  geom_vline(\n    xintercept = median_hall,\n    linetype   = \"dashed\",\n    color      = \"gray55\",\n    linewidth  = 0.5\n  ) +\n  geom_hline(\n    yintercept = median_acc,\n    linetype   = \"dashed\",\n    color      = \"gray55\",\n    linewidth  = 0.5\n  ) +\n  geom_point(\n    data = ai_models_tidy |&gt; filter(rank_combined &gt; 6),\n    aes(color = model_type),\n    size = 3.3,\n    alpha = 0.25\n  ) +\n  geom_point(\n    data = top_6_models,\n    aes(color = model_type),\n    size = 5,\n    alpha = 0.95\n  ) +\n  geom_text_repel(\n    data = top_6_models,\n    aes(label = model_short, color = model_type),\n    size = 3.2,\n    fontface = \"bold\",\n    box.padding = 0.4,\n    point.padding = 0.3,\n    segment.color = \"gray60\",\n    segment.size = 0.5,\n    min.segment.length = 0,\n    max.overlaps = 20,\n    show.legend = FALSE,\n    seed = 1234\n  ) +\n  # Scales\n  scale_color_manual(\n    values = c(\n      \"Proprietary\" = colors$palette$proprietary,\n      \"Open Weights\" = colors$palette$open_weights\n    ),\n    name = NULL\n  ) +\n  scale_x_continuous(\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = 0.05)\n  ) +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = 0.05)\n  ) +\n  # Labs\n  labs(\n    title = \"All 18 Models in Context\",\n    x = \"Hallucination rate (lower is better)\",\n    y = \"Accuracy (higher is better)\"\n  )\n\n### |- COMBINED PLOTS ----\ncombined_plots &lt;- p1 / p2 +\n  plot_layout(heights = c(1, 1.3)) +\n  plot_annotation(\n    title = title_text,\n    subtitle = subtitle_text,\n    caption = caption_text,\n    theme = theme(\n      plot.title = element_text(\n        size = rel(1.95),\n        family = fonts$title,\n        face = \"bold\",\n        color = colors$title,\n        lineheight = 1.1,\n        margin = margin(t = 5, b = 5)\n      ),\n      plot.subtitle = element_markdown(\n        size = rel(0.95),\n        family = fonts$subtitle,\n        color = alpha(colors$subtitle, 0.9),\n        lineheight = 1.5,\n        margin = margin(t = 5, b = 25)\n      ),\n      plot.caption = element_markdown(\n        size = rel(0.55),\n        family = fonts$caption,\n        color = \"gray50\",\n        hjust = 0,\n        lineheight = 1.2,\n        margin = margin(t = 10, b = 10)\n      ),\n      plot.margin = margin(10, 15, 10, 15)\n    )\n  )\n```\n\n\n7. Save\n\nShow code```{r}\n#| label: save\n#| warning: false\n\n### |-  plot image ----  \nsave_plot_patchwork(\n  plot = combined_plots, \n  type = \"makeovermonday\", \n  year = current_year,\n  week = current_week,\n  width = 12, \n  height = 14\n  )\n```\n\n\n8. Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] here_1.0.1      ggrepel_0.9.6   patchwork_1.3.0 glue_1.8.0     \n [5] showtext_0.9-7  showtextdb_3.0  sysfonts_0.8.9  ggtext_0.1.2   \n [9] scales_1.3.0    skimr_2.1.5     janitor_2.2.0   lubridate_1.9.3\n[13] forcats_1.0.0   stringr_1.5.1   dplyr_1.1.4     purrr_1.0.2    \n[17] readr_2.1.5     tidyr_1.3.1     tibble_3.2.1    ggplot2_3.5.1  \n[21] tidyverse_2.0.0 pacman_0.5.1   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6       xfun_0.49          htmlwidgets_1.6.4  tzdb_0.5.0        \n [5] yulab.utils_0.1.8  vctrs_0.6.5        tools_4.4.0        generics_0.1.3    \n [9] curl_6.0.0         gifski_1.32.0-1    fansi_1.0.6        pkgconfig_2.0.3   \n[13] ggplotify_0.1.2    readxl_1.4.3       lifecycle_1.0.4    compiler_4.4.0    \n[17] farver_2.1.2       munsell_0.5.1      repr_1.1.7         codetools_0.2-20  \n[21] snakecase_0.11.1   htmltools_0.5.8.1  yaml_2.3.10        pillar_1.9.0      \n[25] camcorder_0.1.0    magick_2.8.5       commonmark_1.9.2   tidyselect_1.2.1  \n[29] digest_0.6.37      stringi_1.8.4      labeling_0.4.3     rsvg_2.6.1        \n[33] rprojroot_2.0.4    fastmap_1.2.0      grid_4.4.0         colorspace_2.1-1  \n[37] cli_3.6.4          magrittr_2.0.3     base64enc_0.1-3    utf8_1.2.4        \n[41] withr_3.0.2        timechange_0.3.0   rmarkdown_2.29     cellranger_1.1.0  \n[45] hms_1.1.3          evaluate_1.0.1     knitr_1.49         markdown_1.13     \n[49] gridGraphics_0.5-1 rlang_1.1.6        gridtext_0.1.5     Rcpp_1.0.13-1     \n[53] xml2_1.3.6         renv_1.0.3         svglite_2.1.3      rstudioapi_0.17.1 \n[57] jsonlite_1.8.9     R6_2.5.1           fs_1.6.5           systemfonts_1.1.0 \n\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in mm_2025_48.qmd.\nFor the full repository, click here.\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\n\n\nData:\n\nMakeover Monday 2025 Week 48: Which AI Models Hallucinate the Most?\n\n\n\n\nArticle\n\nWhich AI Models Hallucinate the Most?\n\n\n\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\n\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\n\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\n\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n Back to topCitationBibTeX citation:@online{ponce2025,\n  author = {Ponce, Steven},\n  title = {AI {Model} {Performance:} {Accuracy} Vs. {Hallucination}},\n  date = {2025-12-08},\n  url = {https://stevenponce.netlify.app/data_visualizations/MakeoverMonday/2025/mm_2025_48.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPonce, Steven. 2025. â€œAI Model Performance: Accuracy Vs.\nHallucination.â€ December 8, 2025. https://stevenponce.netlify.app/data_visualizations/MakeoverMonday/2025/mm_2025_48.html."
  },
  {
    "objectID": "data_visualizations/TidyTuesday/2025/tt_2025_49.html",
    "href": "data_visualizations/TidyTuesday/2025/tt_2025_49.html",
    "title": "Qatar Cars: A Modern, Global Dataset Reveals Four Market Segments",
    "section": "",
    "text": "FigureÂ 1: A scatter plot of 105 vehicles, plotted by price (USD, log-scale x-axis) versus horsepower (y-axis). Density contours reveal four distinct market segments divided by vertical lines: Budget ($12k-25k), Mid-Range ($25k-75k), Premium ($75k-250k), and Ultra-Luxury ($250k+). Points are colored by engine type (teal for electric, orange for hybrid, dark gray for petrol). The majority of vehicles cluster in the budget and mid-range segments below 500 horsepower. Four ultra-luxury outliers are labeled in the upper right: Lotus Evija ($2.2M), Bugatti Centodieci ($9.1M), Bugatti Chiron ($3.6M), and McLaren Senna ($1.4M).\n\n\nSteps to Create this Graphic \n1. Load Packages & Setup\n\nShow code```{r}\n#| label: load\n#| warning: false\n#| message: false\n#| results: \"hide\"\n\n## 1. LOAD PACKAGES & SETUP ----\nsuppressPackageStartupMessages({\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n    tidyverse,     # Easily Install and Load the 'Tidyverse'\n    ggtext,        # Improved Text Rendering Support for 'ggplot2'\n    showtext,      # Using Fonts More Easily in R Graphs\n    janitor,       # Simple Tools for Examining and Cleaning Dirty Data\n    scales,        # Scale Functions for Visualization\n    glue,          # Interpreted String Literals\n    ggrepel        # Automatically Position Non-Overlapping Text Labels\n)\n})\n\n### |- figure size ----\ncamcorder::gg_record(\n  dir    = here::here(\"temp_plots\"),\n  device = \"png\",\n  width  = 10,\n  height = 10,\n  units  = \"in\",\n  dpi    = 320\n)\n\n# Source utility functions\nsuppressMessages(source(here::here(\"R/utils/fonts.R\")))\nsource(here::here(\"R/utils/social_icons.R\"))\nsource(here::here(\"R/utils/image_utils.R\"))\nsource(here::here(\"R/themes/base_theme.R\"))\n```\n\n\n2. Read in the Data\n\nShow code```{r}\n#| label: read\n#| include: true\n#| eval: true\n#| warning: false\n\ntt &lt;- tidytuesdayR::tt_load(2025, week = 49)\n\nqatarcars &lt;- tt$qatarcars |&gt; clean_names()\n\ntidytuesdayR::readme(tt)\nrm(tt)\n```\n\n\n3. Examine the Data\n\nShow code```{r}\n#| label: examine\n#| include: true\n#| eval: true\n#| results: 'hide'\n#| warning: false\n\nglimpse(qatarcars)\nskimr::skim(qatarcars) |&gt; summary()\n```\n\n\n4. Tidy Data\n\nShow code```{r}\n#| label: tidy-fixed\n#| warning: false\n\nqatarcars_tidy &lt;- qatarcars |&gt;\n  mutate(\n    price_usd = price / 3.64,\n    price_eur = price / 4.15\n  )\n\n# Identify top 4 most expensive cars\ntop4_cars &lt;- qatarcars_tidy |&gt;\n  arrange(desc(price_usd)) |&gt;\n  head(4) |&gt;\n  mutate(\n    label = paste0(make, \" \", model, \"\\n$\", label_comma(accuracy = 1)(price_usd))\n  )\n\n# Define market segments\nsegment_labels &lt;- tibble(\n  segment = c(\"Budget Segment\", \"Mid-Range\", \"Premium\", \"Ultra-Luxury\"),\n  price_usd = c(15000, 40000, 120000, 400000),\n  horsepower = c(1950, 1950, 1950, 1950),\n  price_range = c(\"$12k-25k\", \"$25k-75k\", \"$75k-250k\", \"$250k+\")\n)\n```\n\n\n5. Visualization Parameters\n\nShow code```{r}\n#| label: params\n#| include: true\n#| warning: false\n\n### |- plot aesthetics ----\ncolors &lt;- get_theme_colors(\n    palette = list(\n        \"Electric\" = \"#06AED5\",\n        \"Hybrid\" = \"#F77F00\", \n        \"Petrol\" = \"#2C3E50\",\n        col_gray = \"gray70\"\n    )\n)\n\n### |- titles and caption ----\ntitle_text &lt;- str_glue(\"Qatar Cars: A Modern, Global Dataset Reveals Four Market Segments\")\nsubtitle_text &lt;- str_glue(\n    \"Price-power positioning from 105 vehicles shows distinct clustering from&lt;br&gt;\",\n    \"**budget** ($12k-25k) through **mid-range** ($25k-75k) and **premium** ($75k-250k) to **ultra-luxury** ($250k+)\"\n)\n\ncaption_text &lt;- create_social_caption(\n    tt_year  = 2025,\n    tt_week  = 49,  \n    source_text = str_glue(\n        \"Qatar Cars Dataset\",\n    )\n)\n\n### |-  fonts ----\nsetup_fonts()\nfonts &lt;- get_font_families()\n\n### |-  plot theme ----\n# Start with base theme\nbase_theme &lt;- create_base_theme(colors)\n\n# Add weekly-specific theme elements\nweekly_theme &lt;- extend_weekly_theme(\n  base_theme,\n  theme(\n    # Text styling\n    plot.title = element_markdown(\n      face = \"bold\", family = fonts$title, size = rel(1.4),\n      color = colors$title, margin = margin(b = 10), hjust = 0\n    ),\n    plot.subtitle = element_markdown(\n      face = \"italic\", family = fonts$subtitle, lineheight = 1.2,\n      color = colors$subtitle, size = rel(0.9), margin = margin(b = 20), hjust = 0\n    ),\n\n    # Grid\n    panel.grid.minor = element_blank(),\n    # panel.grid.major.x = element_blank(),\n    panel.grid.major = element_line(color = \"gray90\", linewidth = 0.3),\n\n    # Axes\n    axis.title = element_text(size = rel(0.8), color = \"gray30\"),\n    axis.text = element_text(color = \"gray30\"),\n    axis.text.y = element_text(size = rel(0.85)),\n    axis.ticks = element_blank(),\n\n    # Facets\n    strip.background = element_rect(fill = \"gray95\", color = NA),\n    strip.text = element_text(\n      face = \"bold\",\n      color = \"gray20\",\n      size = rel(0.9),\n      margin = margin(t = 6, b = 4)\n    ),\n    panel.spacing = unit(1.5, \"lines\"),\n\n    # Legend elements\n    legend.position = \"plot\",\n    legend.title = element_text(\n      family = fonts$subtitle,\n      color = colors$text, size = rel(0.8), face = \"bold\"\n    ),\n    legend.text = element_text(\n      family = fonts$tsubtitle,\n      color = colors$text, size = rel(0.7)\n    ),\n    legend.margin = margin(t = 15),\n\n    # Plot margin\n    plot.margin = margin(20, 20, 20, 20)\n  )\n)\n\n# Set theme\ntheme_set(weekly_theme)\n```\n\n\n6. Plot\n\nShow code```{r}\n#| label: plot\n#| warning: false\n\n# labeling function for x-axis (k for thousands, M for millions)\ncustom_dollar_labels &lt;- function(x) {\n    case_when(\n        x &gt;= 1e6 ~ paste0(\"$\", x / 1e6, \"M\"),\n        x &gt;= 1e3 ~ paste0(\"$\", x / 1e3, \"k\"),\n        TRUE ~ paste0(\"$\", x)\n    )\n}\n\n### |-  main plot ----\np &lt;- qatarcars_tidy |&gt;\n  ggplot(aes(x = price_usd, y = horsepower)) +\n  # Geoms\n  geom_density2d(color = \"gray50\", alpha = 0.5, linewidth = 0.6) +\n  geom_vline(xintercept = 25000, linetype = \"dotted\", color = \"gray20\", alpha = 0.4) +\n  geom_vline(xintercept = 75000, linetype = \"dotted\", color = \"gray20\", alpha = 0.4) +\n  geom_vline(xintercept = 250000, linetype = \"dotted\", color = \"gray20\", alpha = 0.4) +\n  geom_text(\n    data = segment_labels,\n    aes(x = price_usd, y = horsepower, label = segment),\n    size = 3,\n    fontface = \"bold\",\n    color = \"gray30\",\n    alpha = 0.9,\n    family = fonts$text\n  ) +\n  geom_text(\n    data = segment_labels,\n    aes(x = price_usd, y = 1850, label = price_range),\n    size = 2.8,\n    color = \"gray40\",\n    alpha = 0.9,\n    family = fonts$text\n  ) +\n  geom_point(aes(color = enginetype), alpha = 0.7, size = 3) +\n  geom_text_repel(\n    data = top4_cars,\n    aes(label = label),\n    size = 3,\n    fontface = \"bold\",\n    box.padding = 0.5,\n    point.padding = 0.3,\n    segment.color = \"gray40\",\n    segment.size = 0.3,\n    min.segment.length = 0,\n    family = fonts$text,\n    seed = 1234\n  ) +\n  # Scales\n  scale_x_log10(\n    labels = custom_dollar_labels,\n    breaks = c(10000, 25000, 50000, 100000, 250000, 500000, 1e6, 3e6, 10e6)\n  ) +\n  scale_y_continuous(labels = label_comma(), limits = c(0, 2050)) +\n  scale_color_manual(\n    values = colors$palette,\n    name = \"Engine Type\"\n  ) +\n  # Labs\n  labs(\n    title = title_text,\n    subtitle = subtitle_text,\n    x = \"Price (USD, log scale)\",\n    y = \"Horsepower\",\n    caption = caption_text\n  ) +\n  # Theme\n  theme(\n    plot.title = element_markdown(\n      size = rel(1.6),\n      family = fonts$title,\n      face = \"bold\",\n      color = colors$title,\n      lineheight = 1.15,\n      margin = margin(t = 8, b = 5)\n    ),\n    plot.subtitle = element_markdown(\n      size = rel(0.9),\n      family = fonts$subtitle,\n      color = alpha(colors$subtitle, 0.88),\n      lineheight = 1.4,\n      margin = margin(t = 5, b = 20)\n    ),\n    plot.caption = element_markdown(\n      size = rel(0.65),\n      family = fonts$subtitle,\n      color = colors$caption,\n      hjust = 0,\n      lineheight = 1.4,\n      margin = margin(t = 20, b = 5)\n    ),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.major.x = element_blank(),\n  )\n```\n\n\n7. Save\n\nShow code```{r}\n#| label: save\n#| warning: false\n\n### |-  plot image ----  \nsave_plot(\n  plot = p, \n  type = \"tidytuesday\", \n  year = 2025, \n  week = 49, \n  width  = 10,\n  height = 10,\n  )\n```\n\n\n8. Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] here_1.0.1      ggrepel_0.9.6   glue_1.8.0      scales_1.3.0   \n [5] janitor_2.2.0   showtext_0.9-7  showtextdb_3.0  sysfonts_0.8.9 \n [9] ggtext_0.1.2    lubridate_1.9.3 forcats_1.0.0   stringr_1.5.1  \n[13] dplyr_1.1.4     purrr_1.0.2     readr_2.1.5     tidyr_1.3.1    \n[17] tibble_3.2.1    ggplot2_3.5.1   tidyverse_2.0.0 pacman_0.5.1   \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.2.1   farver_2.1.2       fastmap_1.2.0      gh_1.4.1          \n [5] digest_0.6.37      timechange_0.3.0   lifecycle_1.0.4    rsvg_2.6.1        \n [9] magrittr_2.0.3     compiler_4.4.0     rlang_1.1.6        tools_4.4.0       \n[13] utf8_1.2.4         yaml_2.3.10        knitr_1.49         skimr_2.1.5       \n[17] labeling_0.4.3     htmlwidgets_1.6.4  bit_4.5.0          curl_6.0.0        \n[21] xml2_1.3.6         camcorder_0.1.0    repr_1.1.7         tidytuesdayR_1.1.2\n[25] withr_3.0.2        grid_4.4.0         fansi_1.0.6        colorspace_2.1-1  \n[29] gitcreds_0.1.2     MASS_7.3-60.2      isoband_0.2.7      cli_3.6.4         \n[33] rmarkdown_2.29     crayon_1.5.3       ragg_1.3.3         generics_0.1.3    \n[37] rstudioapi_0.17.1  tzdb_0.5.0         commonmark_1.9.2   parallel_4.4.0    \n[41] base64enc_0.1-3    vctrs_0.6.5        jsonlite_1.8.9     hms_1.1.3         \n[45] bit64_4.5.2        systemfonts_1.1.0  magick_2.8.5       gifski_1.32.0-1   \n[49] codetools_0.2-20   stringi_1.8.4      gtable_0.3.6       munsell_0.5.1     \n[53] pillar_1.9.0       rappdirs_0.3.3     htmltools_0.5.8.1  R6_2.5.1          \n[57] httr2_1.0.6        textshaping_0.4.0  rprojroot_2.0.4    vroom_1.6.5       \n[61] evaluate_1.0.1     markdown_1.13      gridtext_0.1.5     snakecase_0.11.1  \n[65] renv_1.0.3         Rcpp_1.0.13-1      svglite_2.1.3      xfun_0.49         \n[69] pkgconfig_2.0.3   \n\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in tt_2025_49.qmd.\nFor the full repository, click here.\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\n\n\nData Source:\n\nTidyTuesday 2025 Week 49: CCars in Qatar\n\n\n\n\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\n\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\n\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\n\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n Back to topCitationBibTeX citation:@online{ponce2025,\n  author = {Ponce, Steven},\n  title = {Qatar {Cars:} {A} {Modern,} {Global} {Dataset} {Reveals}\n    {Four} {Market} {Segments}},\n  date = {2025-12-08},\n  url = {https://stevenponce.netlify.app/data_visualizations/TidyTuesday/2025/tt_2025_49.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPonce, Steven. 2025. â€œQatar Cars: A Modern, Global Dataset Reveals\nFour Market Segments.â€ December 8, 2025. https://stevenponce.netlify.app/data_visualizations/TidyTuesday/2025/tt_2025_49.html."
  },
  {
    "objectID": "data_visualizations/TidyTuesday/2025/tt_2025_50.html",
    "href": "data_visualizations/TidyTuesday/2025/tt_2025_50.html",
    "title": "Small Nations Lead in Roundabout Adoption",
    "section": "",
    "text": "FigureÂ 1: Scatter plot showing roundabouts per million people versus population (log scale) for 13 countries. New Zealand leads at ~165 per million, followed by Sweden (~147) and Australia (~137). Although the USA has the highest total number of roundabouts at 12,952 (represented by the largest bubble on the plot), it ranks near the median with only 39 roundabouts per million residents due to its large population. In contrast, smaller nations consistently demonstrate higher per capita adoption rates of roundabouts.\n\n\nSteps to Create this Graphic \n1. Load Packages & Setup\n\nShow code```{r}\n#| label: load\n#| warning: false\n#| message: false\n#| results: \"hide\"\n\n## 1. LOAD PACKAGES & SETUP ----\nsuppressPackageStartupMessages({\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n    tidyverse,     # Easily Install and Load the 'Tidyverse'\n    ggtext,        # Improved Text Rendering Support for 'ggplot2'\n    showtext,      # Using Fonts More Easily in R Graphs\n    janitor,       # Simple Tools for Examining and Cleaning Dirty Data\n    scales,        # Scale Functions for Visualization\n    glue,          # Interpreted String Literals\n    ggrepel        # Automatically Position Non-Overlapping Text Labels\n)\n})\n\n### |- figure size ----\ncamcorder::gg_record(\n  dir    = here::here(\"temp_plots\"),\n  device = \"png\",\n  width  = 12,\n  height = 10,\n  units  = \"in\",\n  dpi    = 320\n)\n\n# Source utility functions\nsuppressMessages(source(here::here(\"R/utils/fonts.R\")))\nsource(here::here(\"R/utils/social_icons.R\"))\nsource(here::here(\"R/utils/image_utils.R\"))\nsource(here::here(\"R/themes/base_theme.R\"))\n```\n\n\n2. Read in the Data\n\nShow code```{r}\n#| label: read\n#| include: true\n#| eval: true\n#| warning: false\n\ntt &lt;- tidytuesdayR::tt_load(2025, week = 50)\n\nroundabouts &lt;- tt$roundabouts_clean |&gt; clean_names()\n\ntidytuesdayR::readme(tt)\nrm(tt)\n```\n\n\n3. Examine the Data\n\nShow code```{r}\n#| label: examine\n#| include: true\n#| eval: true\n#| results: 'hide'\n#| warning: false\n\nglimpse(roundabouts)\nskimr::skim(roundabouts) |&gt; summary()\n```\n\n\n4. Tidy Data\n\nShow code```{r}\n#| label: tidy-fixed\n#| warning: false\n\n### |-  Clean roundabouts data ----\nroundabouts_clean &lt;- roundabouts |&gt;\n  clean_names() |&gt;\n  mutate(\n    # Standardize country names\n    country = case_when(\n      country == \"United States\" ~ \"USA\",\n      country == \"United Kingdom\" ~ \"UK\",\n      TRUE ~ country\n    )\n  )\n\n### |-  Population data for normalization ----\n# Source: World Bank Open Data (data.worldbank.org/indicator/SP.POP.TOTL)\n# 2024 estimates - Selected countries with 10+ roundabouts for meaningful comparison\ncountry_populations &lt;- tibble(\n  country = c(\n    \"USA\", \"Australia\", \"UK\", \"Sweden\", \"Canada\",\n    \"New Zealand\", \"Netherlands\", \"Norway\", \"France\",\n    \"Russia\", \"Japan\", \"Poland\", \"Croatia\"\n  ),\n  population_millions = c(\n    336.7, 27.0, 68.3, 10.6, 39.7,\n    5.3, 18.0, 5.6, 68.2,\n    143.5, 123.3, 36.6, 3.9\n  )\n)\n\n### |-  Calculate per capita rates ----\nper_capita_analysis &lt;- roundabouts_clean |&gt;\n  count(country, name = \"total_roundabouts\") |&gt;\n  inner_join(country_populations, by = \"country\") |&gt;\n  mutate(\n    per_million = total_roundabouts / population_millions,\n    # Categorize for emphasis\n    highlight = case_when(\n      per_million &gt; 100 ~ \"High adopters\",\n      per_million &gt; 30 ~ \"Moderate adopters\",\n      TRUE ~ \"Lower adopters\"\n    ),\n    highlight = factor(\n      highlight,\n      levels = c(\"High adopters\", \"Moderate adopters\", \"Lower adopters\")\n    )\n  ) |&gt;\n  arrange(desc(per_million))\n\n# Median reference\nmedian_per_million &lt;- median(per_capita_analysis$per_million)\n\nmedian_label &lt;- glue(\n  \"Median among\\nshown countries â‰ˆ {round(median_per_million, 1)}\\nroundabouts per million\"\n)\n```\n\n\n5. Visualization Parameters\n\nShow code```{r}\n#| label: params\n#| include: true\n#| warning: false\n\n### |-  plot aesthetics ----\ncolors &lt;- get_theme_colors(\n    palette = list(\n        high  = \"#004F6E\",\n        moderate = \"#2A7F9E\", \n        lower  = \"#C4CBD3\"\n    )\n)\n\n### |- titles and caption ----\ntitle_text &lt;- \"Small Nations Lead in Roundabout Adoption\"\n\nsubtitle_text &lt;- glue(\n    \"Per capita analysis of countries with 10+ roundabouts shows \",\n    \"**New Zealand** and **Sweden** clearly leading, and circle size represents&lt;br&gt;\",\n    \"the total number of roundabouts. Despite having 12,952 roundabouts, the **USA** sits near the median \",\n    \"of these countries once population&lt;br&gt;\",\n    \"is accounted for (39 per million people).\"\n)\n\ncaption_text &lt;- create_social_caption(\n    tt_year = 2025,\n    tt_week = 50,\n    source_text = paste(\n        \"Roundabout counts: Kittelson & Associates via { roundabouts } package.&lt;br&gt;\",\n        \"Population: World Bank Open Data (2024 estimates).\"\n    )\n)\n\n### |-  fonts ----\nsetup_fonts()\nfonts &lt;- get_font_families()\n\n### |-  plot theme ----\n# Start with base theme\nbase_theme &lt;- create_base_theme(colors)\n\n# Add weekly-specific theme elements\nweekly_theme &lt;- extend_weekly_theme(\n  base_theme,\n  theme(\n    # Text styling\n    plot.title = element_markdown(\n      face = \"bold\", family = fonts$title, size = rel(1.4),\n      color = colors$title, margin = margin(b = 10), hjust = 0\n    ),\n    plot.subtitle = element_markdown(\n      face = \"italic\", family = fonts$subtitle, lineheight = 1.2,\n      color = colors$subtitle, size = rel(0.9), margin = margin(b = 20), hjust = 0\n    ),\n\n    # Grid\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major = element_line(color = \"gray90\", linewidth = 0.25),\n\n    # Axes\n    axis.title = element_text(size = rel(0.8), color = \"gray30\"),\n    axis.text = element_text(color = \"gray30\"),\n    axis.text.y = element_text(size = rel(0.85)),\n    axis.ticks = element_blank(),\n\n    # Facets\n    strip.background = element_rect(fill = \"gray95\", color = NA),\n    strip.text = element_text(\n      face = \"bold\",\n      color = \"gray20\",\n      size = rel(0.9),\n      margin = margin(t = 6, b = 4)\n    ),\n    panel.spacing = unit(1.5, \"lines\"),\n\n    # Legend elements\n    legend.position = \"plot\",\n    legend.title = element_text(\n      family = fonts$subtitle,\n      color = colors$text, size = rel(0.8), face = \"bold\"\n    ),\n    legend.text = element_text(\n      family = fonts$tsubtitle,\n      color = colors$text, size = rel(0.7)\n    ),\n    legend.margin = margin(t = 15),\n\n    # Plot margin\n    plot.margin = margin(20, 20, 20, 20)\n  )\n)\n\n# Set theme\ntheme_set(weekly_theme)\n```\n\n\n6. Plot\n\nShow code```{r}\n#| label: plot\n#| warning: false\n\n### |-  main plot ----\np &lt;- ggplot() +\n  # Geoms\n  geom_hline(\n    yintercept = median_per_million,\n    linetype = \"dashed\",\n    color = \"gray55\",\n    linewidth = 0.4\n  ) +\n  geom_point(\n    data = per_capita_analysis |&gt; filter(highlight == \"Lower adopters\"),\n    aes(\n      x = population_millions, y = per_million,\n      size = total_roundabouts, fill = highlight\n    ),\n    shape = 21, color = \"white\", alpha = 0.75, stroke = 0.5\n  ) +\n  geom_point(\n    data = per_capita_analysis |&gt; filter(highlight == \"Moderate adopters\"),\n    aes(\n      x = population_millions, y = per_million,\n      size = total_roundabouts, fill = highlight\n    ),\n    shape = 21, color = \"white\", alpha = 0.9, stroke = 0.6\n  ) +\n  geom_point(\n    data = per_capita_analysis |&gt; filter(highlight == \"High adopters\"),\n    aes(\n      x = population_millions, y = per_million,\n      size = total_roundabouts, fill = highlight\n    ),\n    shape = 21, color = \"white\", alpha = 1, stroke = 0.7\n  ) +\n  geom_text_repel(\n    data = per_capita_analysis,\n    aes(\n      x = population_millions,\n      y = per_million,\n      label = country,\n      color = highlight\n    ),\n    size = 3.2,\n    family = fonts$text,\n    fontface = \"bold\",\n    max.overlaps = 20,\n    min.segment.length = 0,\n    box.padding = 0.5,\n    point.padding = 16.45,\n    nudge_x = 0.02,\n    force = 0.2,\n    seed = 123\n  ) +\n  # Annotate\n  annotate(\n    \"text\",\n    x = 6, y = median_per_million + 5,\n    label = median_label,\n    family = fonts$text,\n    size = 3,\n    hjust = 0,\n    vjust = 0,\n    color = \"gray40\"\n  ) +\n  # Scales\n  scale_fill_manual(\n    name = \"Adoption\\nlevel\",\n    values = c(\n      \"High adopters\" = colors$palette$high,\n      \"Moderate adopters\" = colors$palette$moderate,\n      \"Lower adopters\" = colors$palette$lower\n    )\n  ) +\n  scale_color_manual(\n    name = \"Adoption\\nlevel\",\n    values = c(\n      \"High adopters\" = colors$palette$high,\n      \"Moderate adopters\" = colors$palette$moderate,\n      \"Lower adopters\" = colors$palette$lower\n    )\n  ) +\n  scale_size_continuous(\n    name = \"Total\\nroundabouts\",\n    range = c(2.5, 14),\n    breaks = c(500, 2500, 5000, 10000),\n    labels = label_comma()\n  ) +\n  scale_x_log10(\n    labels = label_comma(),\n    breaks = c(5, 10, 25, 50, 100, 200, 300)\n  ) +\n  scale_y_continuous(\n    labels = label_number(accuracy = 1),\n    breaks = seq(0, 200, 50),\n    limits = c(0, 175),\n    expand = expansion(mult = c(0.05, 0.1))\n  ) +\n  # Labs\n  labs(\n    title = title_text,\n    subtitle = subtitle_text,\n    caption = caption_text,\n    x = \"Population (millions, log scale)\",\n    y = \"Roundabouts per million people\"\n  ) +\n  # Guides\n  guides(\n    fill = guide_legend(\n      order = 1,\n      nrow = 1,\n      title.vjust = 0.8,\n      override.aes = list(\n        shape = 21,\n        size = 5,\n        stroke = 0.7,\n        color = \"grey40\"\n      )\n    ),\n    size = guide_legend(\n      order = 2,\n      nrow = 1,\n      title.vjust = 0.8,\n      override.aes = list(\n        shape = 21,\n        color = \"grey40\",\n        fill  = \"white\",\n        alpha = 1\n      )\n    ),\n    color = \"none\"\n  ) +\n  # Theme\n  theme(\n    plot.title = element_markdown(\n      size = rel(2.3),\n      family = fonts$title,\n      face = \"bold\",\n      color = colors$title,\n      lineheight = 1.15,\n      margin = margin(t = 8, b = 5)\n    ),\n    plot.subtitle = element_markdown(\n      size = rel(0.9),\n      family = fonts$subtitle,\n      color = alpha(colors$subtitle, 0.88),\n      lineheight = 1.5,\n      margin = margin(t = 5, b = 20)\n    ),\n    plot.caption = element_markdown(\n      size = rel(0.65),\n      family = fonts$subtitle,\n      color = colors$caption,\n      hjust = 0,\n      lineheight = 1.4,\n      margin = margin(t = 20, b = 5)\n    ),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.major.x = element_blank(),\n    legend.position = \"bottom\",\n    legend.box = \"horizontal\",\n    legend.spacing.x = unit(3.5, \"lines\"),\n    legend.box.spacing = unit(0.5, \"lines\"),\n    legend.title = element_text(\n      family = fonts$text, size = 9, hjust = 0,\n      face = \"bold\", margin = margin(r = 8)\n    ),\n    legend.text = element_text(family = fonts$text, size = 9)\n  )\n```\n\n\n7. Save\n\nShow code```{r}\n#| label: save\n#| warning: false\n\n### |-  plot image ----  \nsave_plot(\n  plot = p, \n  type = \"tidytuesday\", \n  year = 2025, \n  week = 50, \n  width  = 12,\n  height = 10,\n  )\n```\n\n\n8. Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] here_1.0.1      ggrepel_0.9.6   glue_1.8.0      scales_1.3.0   \n [5] janitor_2.2.0   showtext_0.9-7  showtextdb_3.0  sysfonts_0.8.9 \n [9] ggtext_0.1.2    lubridate_1.9.3 forcats_1.0.0   stringr_1.5.1  \n[13] dplyr_1.1.4     purrr_1.0.2     readr_2.1.5     tidyr_1.3.1    \n[17] tibble_3.2.1    ggplot2_3.5.1   tidyverse_2.0.0 pacman_0.5.1   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6       xfun_0.49          httr2_1.0.6        htmlwidgets_1.6.4 \n [5] gh_1.4.1           tzdb_0.5.0         vctrs_0.6.5        tools_4.4.0       \n [9] generics_0.1.3     parallel_4.4.0     curl_6.0.0         gifski_1.32.0-1   \n[13] fansi_1.0.6        pkgconfig_2.0.3    skimr_2.1.5        lifecycle_1.0.4   \n[17] farver_2.1.2       compiler_4.4.0     textshaping_0.4.0  munsell_0.5.1     \n[21] repr_1.1.7         codetools_0.2-20   snakecase_0.11.1   htmltools_0.5.8.1 \n[25] yaml_2.3.10        crayon_1.5.3       pillar_1.9.0       camcorder_0.1.0   \n[29] magick_2.8.5       commonmark_1.9.2   tidyselect_1.2.1   digest_0.6.37     \n[33] stringi_1.8.4      rsvg_2.6.1         rprojroot_2.0.4    fastmap_1.2.0     \n[37] grid_4.4.0         colorspace_2.1-1   cli_3.6.4          magrittr_2.0.3    \n[41] base64enc_0.1-3    utf8_1.2.4         withr_3.0.2        rappdirs_0.3.3    \n[45] bit64_4.5.2        timechange_0.3.0   rmarkdown_2.29     tidytuesdayR_1.1.2\n[49] gitcreds_0.1.2     bit_4.5.0          ragg_1.3.3         hms_1.1.3         \n[53] evaluate_1.0.1     knitr_1.49         markdown_1.13      rlang_1.1.6       \n[57] gridtext_0.1.5     Rcpp_1.0.13-1      xml2_1.3.6         renv_1.0.3        \n[61] vroom_1.6.5        svglite_2.1.3      rstudioapi_0.17.1  jsonlite_1.8.9    \n[65] R6_2.5.1           systemfonts_1.1.0 \n\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in tt_2025_50.qmd.\nFor the full repository, click here.\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\n\n\nData Source:\n\nTidyTuesday 2025 Week 50: Roundabouts across the world\n\n\n\n\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\n\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\n\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\n\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n Back to topCitationBibTeX citation:@online{ponce2025,\n  author = {Ponce, Steven},\n  title = {Small {Nations} {Lead} in {Roundabout} {Adoption}},\n  date = {2025-12-14},\n  url = {https://stevenponce.netlify.app/data_visualizations/TidyTuesday/2025/tt_2025_50.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPonce, Steven. 2025. â€œSmall Nations Lead in Roundabout\nAdoption.â€ December 14, 2025. https://stevenponce.netlify.app/data_visualizations/TidyTuesday/2025/tt_2025_50.html."
  },
  {
    "objectID": "data_visualizations/TidyTuesday/2025/tt_2025_51.html",
    "href": "data_visualizations/TidyTuesday/2025/tt_2025_51.html",
    "title": "Global language endangerment: scale and geographic concentration",
    "section": "",
    "text": "FigureÂ 1: Two-panel visualization showing global language endangerment. Left panel: treemap displaying distribution of 8,612 languages by status - 2,704 not endangered (light blue-gray), 1,835 shifting (light gray), 1,629 threatened (medium gray), 1,225 extinct (dark gray), 434 moribund (red), and 311 nearly extinct (dark red). Right panel: map of the Pacific region showing 303 critically endangered languages (41% of the global total) concentrated in Papunesia, represented as red dots clustered across Indonesia, Papua New Guinea, the Philippines, and the Pacific islands.\n\n\nSteps to Create this Graphic \n1. Load Packages & Setup\n\nShow code```{r}\n#| label: load\n#| warning: false\n#| message: false\n#| results: \"hide\"\n\n## 1. LOAD PACKAGES & SETUP ----\nsuppressPackageStartupMessages({\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n    tidyverse,     # Easily Install and Load the 'Tidyverse'\n    ggtext,        # Improved Text Rendering Support for 'ggplot2'\n    showtext,      # Using Fonts More Easily in R Graphs\n    janitor,       # Simple Tools for Examining and Cleaning Dirty Data\n    skimr,         # Compact and Flexible Summaries of Data\n    scales,        # Scale Functions for Visualization\n    glue,          # Interpreted String Literals\n    treemapify,    # Create Treemap Visualizations\n    patchwork,     # The Composer of Plots\n    maps           # Draw Geographical Maps\n)\n})\n\n### |- figure size ----\ncamcorder::gg_record(\n  dir    = here::here(\"temp_plots\"),\n  device = \"png\",\n  width  = 14,\n  height = 12,\n  units  = \"in\",\n  dpi    = 320\n)\n\n# Source utility functions\nsuppressMessages(source(here::here(\"R/utils/fonts.R\")))\nsource(here::here(\"R/utils/social_icons.R\"))\nsource(here::here(\"R/utils/image_utils.R\"))\nsource(here::here(\"R/themes/base_theme.R\"))\n```\n\n\n2. Read in the Data\n\nShow code```{r}\n#| label: read\n#| include: true\n#| eval: true\n#| warning: false\n\ntt &lt;- tidytuesdayR::tt_load(2025, week = 51)\n\nendangered_status &lt;- tt$endangered_status |&gt; clean_names()\nfamilies &lt;- tt$families |&gt; clean_names()\nlanguages &lt;- tt$languages |&gt; clean_names()\n\n# tidytuesdayR::readme(tt)\nrm(tt)\n```\n\n\n3. Examine the Data\n\nShow code```{r}\n#| label: examine\n#| include: true\n#| eval: true\n#| results: 'hide'\n#| warning: false\n\nglimpse(endangered_status)\nglimpse(families)\nglimpse(languages)\n```\n\n\n4. Tidy Data\n\nShow code```{r}\n#| label: tidy-fixed\n#| warning: false\n\n### |- Join all datasets ----\nlanguages_combined &lt;- languages |&gt;\n  left_join(endangered_status, by = \"id\") |&gt;\n  left_join(families, by = c(\"family_id\" = \"id\")) |&gt;\n  mutate(\n    status_label = case_when(\n      status_code == 1 ~ \"Not Endangered\",\n      status_code == 2 ~ \"Threatened\",\n      status_code == 3 ~ \"Shifting\",\n      status_code == 4 ~ \"Moribund\",\n      status_code == 5 ~ \"Nearly Extinct\",\n      status_code == 6 ~ \"Extinct\",\n      TRUE ~ \"Unknown\"\n    ),\n    endangerment_broad = case_when(\n      status_code == 1 ~ \"Safe\",\n      status_code %in% 2:3 ~ \"Threatened/Shifting\",\n      status_code %in% 4:5 ~ \"Critical\",\n      status_code == 6 ~ \"Extinct\",\n      TRUE ~ \"Unknown\"\n    ),\n    is_endangered = status_code %in% 2:5,\n    n_countries = str_count(countries, \";\") + 1\n  )\n\n### |- Overall endangerment summary ----\nendangerment_summary &lt;- languages_combined |&gt;\n  count(status_label, endangerment_broad, sort = TRUE) |&gt;\n  mutate(pct = n / sum(n))\n\n### |- Pacific region critical languages ----\npacific_critical &lt;- languages_combined |&gt;\n  filter(\n    endangerment_broad == \"Critical\",\n    !is.na(latitude), !is.na(longitude),\n    longitude &gt;= 100, longitude &lt;= 180,\n    latitude &gt;= -50, latitude &lt;= 20\n  )\n\n# Calculate total critical languages globally \ntotal_critical &lt;- languages_combined |&gt;\n  filter(endangerment_broad == \"Critical\") |&gt;\n  nrow()\n\npacific_pct &lt;- round(nrow(pacific_critical) / total_critical * 100)\n\n### |- data for treemap labels  ----\nendangerment_summary2 &lt;- endangerment_summary |&gt;\n  filter(endangerment_broad != \"Unknown\") |&gt;\n  group_by(status_label) |&gt;\n  summarise(n = sum(n), .groups = \"drop\") |&gt;\n  mutate(\n    pct = n / sum(n),\n    status_label = fct_reorder(status_label, -n),\n    label_txt = glue(\"{status_label}\\n{comma(n)} ({scales::percent(pct, accuracy = 0.1)})\"),\n    text_color = if_else(status_label %in% c(\"Moribund\", \"Nearly Extinct\"), \"white\", \"gray10\")\n  )\n```\n\n\n5. Visualization Parameters\n\nShow code```{r}\n#| label: params\n#| include: true\n#| warning: false\n\n### |-  plot aesthetics ----\ncolors &lt;- get_theme_colors(\n    palette = list(\n      col_not_endangered = \"#E8EEF2\",\n      col_shifting = \"#D0D0D0\",\n      col_threatened = \"#A8A8A8\",\n      col_extinct = \"#8A8A8A\",\n      col_moribund = \"#E63946\",\n      col_nearly_extinct = \"#C41E3A\",\n      col_map_bg = \"gray96\",\n      col_map_border = \"gray65\",\n      col_ink = \"gray10\",\n      col_rule = \"gray85\"\n  )\n)\n\n### |- titles and caption ----\nmain_title &lt;- \"Global language endangerment: scale and geographic concentration\"\n\ntreemap_subtitle &lt;- \"Share of 8,612 documented languages by endangerment status (Glottolog 5.2.1)\"\n\nmap_title &lt;- \"Papunesia: a global hotspot for critical endangerment\"\nmap_subtitle &lt;- glue(\n    \"{comma(nrow(pacific_critical))} of {comma(total_critical)} critically endangered languages \",\n    \"({pacific_pct}%) fall within the Pacific focus region\"\n)\n\ncaption_text &lt;- create_social_caption(\n    tt_year = 2025,\n    tt_week = 51,\n    source_text = \"Glottolog 5.2.1 | Max Planck Institute for Evolutionary Anthropology\"\n)\n\nkey_takeaway &lt;- glue(\n    \"Nearly **half of the worldâ€™s critically endangered languages** \",\n    \"are concentrated in the **Pacific region**, making **Papunesia** the global epicenter of language loss risk.\"\n)\n\n### |-  fonts ----\nsetup_fonts()\nfonts &lt;- get_font_families()\n\n### |-  plot theme ----\n# Start with base theme\nbase_theme &lt;- create_base_theme(colors)\n\n# Add weekly-specific theme elements\nweekly_theme &lt;- extend_weekly_theme(\n  base_theme,\n  theme(\n    # Text styling\n    plot.title = element_text(\n      face = \"bold\", family = fonts$title, size = rel(1.4),\n      color = colors$title, margin = margin(b = 10), hjust = 0\n    ),\n    plot.subtitle = element_text(\n      face = \"italic\", family = fonts$subtitle, lineheight = 1.2,\n      color = colors$subtitle, size = rel(0.8), margin = margin(b = 20), hjust = 0\n    ),\n\n    # Grid\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major = element_line(color = \"gray90\", linewidth = 0.25),\n\n    # Axes\n    axis.title = element_text(size = rel(0.8), color = \"gray30\"),\n    axis.text = element_text(color = \"gray30\"),\n    axis.text.y = element_text(size = rel(0.85)),\n    axis.ticks = element_blank(),\n\n    # Facets\n    strip.background = element_rect(fill = \"gray95\", color = NA),\n    strip.text = element_text(\n      face = \"bold\",\n      color = \"gray20\",\n      size = rel(0.9),\n      margin = margin(t = 6, b = 4)\n    ),\n    panel.spacing = unit(1.5, \"lines\"),\n\n    # Legend elements\n    legend.position = \"plot\",\n    legend.title = element_text(\n      family = fonts$subtitle,\n      color = colors$text, size = rel(0.8), face = \"bold\"\n    ),\n    legend.text = element_text(\n      family = fonts$tsubtitle,\n      color = colors$text, size = rel(0.7)\n    ),\n    legend.margin = margin(t = 15),\n\n    # Plot margin\n    plot.margin = margin(20, 20, 20, 20),\n    \n    # Panel framing (subtle  containers) \n    panel.border     = element_rect(color = colors$palette$col_rule, fill = NA, linewidth = 0.8),\n  )\n)\n\n# Set theme\ntheme_set(weekly_theme)\n```\n\n\n6. Plot\n\nShow code```{r}\n#| label: plot\n#| warning: false\n\n### |- Plot 1: Treemap ----\np1 &lt;- ggplot(\n    endangerment_summary2,\n    aes(area = n, fill = status_label)\n) +\n    geom_treemap(color = \"white\", size = 2) +\n    geom_treemap_text(\n        aes(label = label_txt, color = text_color),\n        place = \"centre\",\n        fontface = \"bold\",\n        size = 12,\n        grow = FALSE,\n        family = fonts$text,\n        reflow = TRUE\n    ) +\n    scale_fill_manual(\n        values = c(\n            \"Not Endangered\"  = colors$palette$col_not_endangered,\n            \"Shifting\"        = colors$palette$col_shifting,\n            \"Threatened\"      = colors$palette$col_threatened,\n            \"Extinct\"         = colors$palette$col_extinct,\n            \"Moribund\"        = colors$palette$col_moribund,\n            \"Nearly Extinct\"  = colors$palette$col_nearly_extinct\n        )\n    ) +\n    scale_color_identity() +\n    labs(\n        # tag = \"A\",\n        title = \"Endangerment status distribution\",\n        subtitle = treemap_subtitle\n    ) +\n    theme(\n        legend.position = \"none\",\n        plot.margin = margin(t = 6, r = 10, b = 6, l = 6)\n    )\n\n### |- Plot 2: Map  ----\nworld_map &lt;- map_data(\"world\")\n\np2 &lt;- ggplot() +\n    geom_polygon(\n        data = world_map,\n        aes(x = long, y = lat, group = group),\n        fill = colors$palette$col_map_bg,\n        color = colors$palette$col_map_border,\n        linewidth = 0.28\n    ) +\n    geom_point(\n        data = pacific_critical,\n        aes(x = longitude, y = latitude),\n        shape = 21,\n        fill  = colors$palette$col_moribund,\n        color = \"white\",\n        stroke = 0.35,\n        alpha = 0.75,\n        size  = 1.9\n    ) +\n    coord_fixed(\n        xlim = c(100, 180),\n        ylim = c(-50, 20),\n        ratio = 1.3,\n        expand = FALSE\n    ) +\n    labs(\n        # tag = \"B\",\n        title = map_title,\n        subtitle = map_subtitle\n    ) +\n    theme_void() +\n    theme(\n        plot.title = element_text(\n            face = \"bold\", family = fonts$title, size = 19.6,\n            color = colors$title, margin = margin(b = 10), hjust = 0\n        ),\n        plot.subtitle = element_text(\n            face = \"italic\", family = fonts$subtitle, lineheight = 1.2,\n            color = colors$subtitle, size = 11.2, margin = margin(b = 20), hjust = 0\n        ),\n        panel.border = element_rect(color = colors$palette$col_rule, fill = NA, linewidth = 0.8),\n        plot.margin = margin(t = 6, r = 6, b = 6, l = 10)\n    )\n\n### |- Combine plots ----\ncombined_plots &lt;- p1 + p2 +\n    plot_annotation(\n        title    = main_title,\n        subtitle = key_takeaway,\n        caption  = caption_text,\n        theme =  theme(\n            plot.title = element_text(\n                size = rel(2.3),\n                family = fonts$title,\n                face = \"bold\",\n                color = colors$title,\n                lineheight = 1.15,\n                margin = margin(t = 8, b = 5)\n            ),\n            plot.subtitle = element_markdown(\n                size = rel(0.80),\n                family = fonts$subtitle,\n                color = alpha(colors$subtitle, 0.88),\n                lineheight = 1.5,\n                margin = margin(t = 5, b = 20)\n            ),\n            plot.caption = element_markdown(\n                size = rel(0.65),\n                family = fonts$subtitle,\n                color = colors$caption,\n                hjust = 0,\n                lineheight = 1.4,\n                margin = margin(t = 20, b = 5)\n            )\n        )\n    )\n```\n\n\n7. Save\n\nShow code```{r}\n#| label: save\n#| warning: false\n\n### |-  plot image ----  \nsave_plot_patchwork(\n  plot = combined_plots, \n  type = \"tidytuesday\", \n  year = 2025, \n  week = 51, \n  width  = 14,\n  height = 12,\n  )\n```\n\n\n8. Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] here_1.0.1       maps_3.4.2.1     patchwork_1.3.0  treemapify_2.5.6\n [5] glue_1.8.0       scales_1.3.0     skimr_2.1.5      janitor_2.2.0   \n [9] showtext_0.9-7   showtextdb_3.0   sysfonts_0.8.9   ggtext_0.1.2    \n[13] lubridate_1.9.3  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n[17] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n[21] ggplot2_3.5.1    tidyverse_2.0.0  pacman_0.5.1    \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.2.1   farver_2.1.2       fastmap_1.2.0      gh_1.4.1          \n [5] digest_0.6.37      timechange_0.3.0   lifecycle_1.0.4    rsvg_2.6.1        \n [9] magrittr_2.0.3     compiler_4.4.0     rlang_1.1.6        tools_4.4.0       \n[13] utf8_1.2.4         yaml_2.3.10        knitr_1.49         labeling_0.4.3    \n[17] htmlwidgets_1.6.4  bit_4.5.0          curl_6.0.0         xml2_1.3.6        \n[21] camcorder_0.1.0    repr_1.1.7         tidytuesdayR_1.1.2 withr_3.0.2       \n[25] grid_4.4.0         fansi_1.0.6        colorspace_2.1-1   gitcreds_0.1.2    \n[29] cli_3.6.4          rmarkdown_2.29     crayon_1.5.3       generics_0.1.3    \n[33] rstudioapi_0.17.1  tzdb_0.5.0         commonmark_1.9.2   parallel_4.4.0    \n[37] ggplotify_0.1.2    base64enc_0.1-3    vctrs_0.6.5        yulab.utils_0.1.8 \n[41] jsonlite_1.8.9     gridGraphics_0.5-1 hms_1.1.3          bit64_4.5.2       \n[45] systemfonts_1.1.0  magick_2.8.5       gifski_1.32.0-1    codetools_0.2-20  \n[49] stringi_1.8.4      gtable_0.3.6       munsell_0.5.1      pillar_1.9.0      \n[53] rappdirs_0.3.3     htmltools_0.5.8.1  ggfittext_0.10.2   R6_2.5.1          \n[57] httr2_1.0.6        rprojroot_2.0.4    vroom_1.6.5        evaluate_1.0.1    \n[61] markdown_1.13      gridtext_0.1.5     snakecase_0.11.1   renv_1.0.3        \n[65] Rcpp_1.0.13-1      svglite_2.1.3      xfun_0.49          fs_1.6.5          \n[69] pkgconfig_2.0.3   \n\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in tt_2025_51.qmd.\nFor the full repository, click here.\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\n\n\nData Source:\n\nTidyTuesday 2025 Week 50: The Languages of the World\n\n\n\n\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\n\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\n\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\n\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n Back to topCitationBibTeX citation:@online{ponce2025,\n  author = {Ponce, Steven},\n  title = {Global Language Endangerment: Scale and Geographic\n    Concentration},\n  date = {2025-12-14},\n  url = {https://stevenponce.netlify.app/data_visualizations/TidyTuesday/2025/tt_2025_51.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPonce, Steven. 2025. â€œGlobal Language Endangerment: Scale and\nGeographic Concentration.â€ December 14, 2025. https://stevenponce.netlify.app/data_visualizations/TidyTuesday/2025/tt_2025_51.html."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "My Featured Projects\nWelcome to the projects section! Here you can find details on the R package(s) Iâ€™ve created and standalone visualizations that are not tied to data challenges.\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n    \n  \n\n\n\n\n\n\n\n\n\n\nGovernance-First Launch Forecasting: A Decision Support Framework\n\n\n\nJanuary 28, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nOh My God, Bob!\n\n\n\nJanuary 23, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nBobâ€™s Burgers: The Fart Report\n\n\n\nJanuary 22, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Secret Sauce: Bobâ€™s Burgers Rating Trends?\n\n\n\nJanuary 21, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nbobsburgersR v0.2.0: Seasons 15-16 and TMDB Ratings\n\n\n\nJanuary 20, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nClinical Trial Duration Forecasting: A Validation-First Case Study\n\n\n\nJanuary 19, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nDesigning an Executive-Grade R&D Portfolio Simulator\n\n\n\nJanuary 7, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding a Hypothesis-Driven Financial Analysis Dashboard\n\n\n\nJanuary 3, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalyzing Appleâ€™s ESG Strategy Through a Risk-Based Lens\n\n\n\nDecember 21, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding an Executive-Grade Train Operations Dashboard\n\n\n\nDecember 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring a Century of Meteorite Discoveries\n\n\n\nDecember 15, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nRWFD Supply Chain Analytics Dashboard\n\n\n\nFebruary 16, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmotional Flow in Bobâ€™s Burgers\n\n\n\nNovember 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nBobâ€™s Burgers Episode Fingerprints by Season\n\n\n\nNovember 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nBobâ€™s Burgers Viewership from Seasons 1 to 14\n\n\n\nOctober 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Rise and Fall of Bobâ€™s Burgers Ratings Across Seasons\n\n\n\nOctober 27, 2024\n\n\n\n\n\n\n\n\n\n\n\nIntroducing the bobsburgersR Package\n\n\n\nOctober 26, 2024\n\n\n\n\n\n\nNo matching items\n\n  \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-15.html",
    "href": "projects/standalone_visualizations/sa_2025-12-15.html",
    "title": "Exploring a Century of Meteorite Discoveries",
    "section": "",
    "text": "Explore the project"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-15.html#the-opportunity",
    "href": "projects/standalone_visualizations/sa_2025-12-15.html#the-opportunity",
    "title": "Exploring a Century of Meteorite Discoveries",
    "section": "The Opportunity",
    "text": "The Opportunity\nNASAâ€™s meteorite landings dataset documents 45,716 meteorite discoveries from 860 CE to 2013â€”over 1,150 years of recorded encounters with material from space.\nThis project began with a simple goal: turn a large historical dataset into an intuitive, interactive experience that allows users to explore where meteorites were found, how discoveries changed over time, and what distinguishes rare observed falls from later recoveries."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-15.html#guiding-questions",
    "href": "projects/standalone_visualizations/sa_2025-12-15.html#guiding-questions",
    "title": "Exploring a Century of Meteorite Discoveries",
    "section": "Guiding Questions",
    "text": "Guiding Questions\nTo shape the dashboard, I focused on a small set of questions that naturally emerge from the data:\nGeography\n\nWhere are meteorite discoveries concentrated globally?\nWhy does Antarctica dominate modern records?\n\nTime\n\nHow have discoveries evolved over time?\nWhat explains the sharp rise in finds after 1970?\n\nPhysical Characteristics\n\nHow do observed falls differ from recovered meteorites?\nWhich meteorite types appear most frequently?"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-15.html#design-approach-progressive-disclosure",
    "href": "projects/standalone_visualizations/sa_2025-12-15.html#design-approach-progressive-disclosure",
    "title": "Exploring a Century of Meteorite Discoveries",
    "section": "Design Approach: Progressive Disclosure",
    "text": "Design Approach: Progressive Disclosure\nThe dashboard follows a progressive disclosure strategy: present the big picture first, then allow deeper exploration for users who want it.\nGlobal Overview\nThe opening view provides immediate context through four headline metrics:\n\n\nTotal meteorites: 45,716\n\nLargest find: Hoba (~60 tonnes)\n\nTime span: 860â€“2013\n\nObserved falls: 2.4%\n\n\n\n\n\n\nFigureÂ 1: Global Overview tab showing worldwide meteorite locations, discovery trends over time, and mass distributions for observed falls versus recovered finds.\n\n\nThese are paired with three core visualizations:\n\n\nInteractive world map showing all meteorite locations with clustering for performance\n\nDiscovery timeline highlighting the rapid increase in finds since the 19th century\n\nMass distribution comparing observed falls versus recovered meteorites\n\nA simple year-range filter allows users to focus on specific historical periods without overwhelming the interface.\nDeep Dive Analytics\nFor more detailed exploration, the analytics tab adds multidimensional filters:\n\nYear range\nMass range (log scale)\nMeteorite classification\nDiscovery status (Fell vs.Â Found)\n\nAll visualizations and summary statistics update reactively, allowing users to explore relationships across time, mass, and type.\n\n\n\n\n\nFigureÂ 2: Deep Dive Analytics tab with multidimensional filtering by year, mass, meteorite type, and discovery status, updating all charts and metrics in real time.\n\n\nData Explorer\nThe final tab exposes the underlying dataset through an interactive table, supporting:\n\nSearch and column-level filtering\nSorting\nCSV export for external analysis\n\n\n\n\n\n\nFigureÂ 3: Data Explorer tab providing a searchable, sortable table of all meteorite records with CSV export for further analysis."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-15.html#key-patterns-revealed-by-the-data",
    "href": "projects/standalone_visualizations/sa_2025-12-15.html#key-patterns-revealed-by-the-data",
    "title": "Exploring a Century of Meteorite Discoveries",
    "section": "Key Patterns Revealed by the Data",
    "text": "Key Patterns Revealed by the Data\nAntarcticaâ€™s Outsized Role\nModern meteorite discoveries are dominated by Antarctica. The ice sheet acts as a natural conveyor belt, concentrating meteorites in accessible regions. Dark stones contrast sharply against the ice, and cold, dry conditions preserve specimens exceptionally well.\nThe Post-1970 Discovery Surge\nThe dramatic rise in discoveries after 1970 reflects improved search efforts, not an increase in meteorite impacts. Antarctic expeditions, desert surveys, and systematic recovery programs fundamentally changed how meteorites are found.\nFell vs.Â Found\nOnly 1,097 meteorites (2.4%) were observed falling. These events are scientifically valuable because their arrival time is precisely known. Recovered meteorites, which make up the remaining 97.6%, are often larger and discovered long after impact."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-15.html#design-decisions-that-improved-clarity",
    "href": "projects/standalone_visualizations/sa_2025-12-15.html#design-decisions-that-improved-clarity",
    "title": "Exploring a Century of Meteorite Discoveries",
    "section": "Design Decisions That Improved Clarity",
    "text": "Design Decisions That Improved Clarity\nConsistency Over Color\nEarly versions of the dashboard used multiple accent colors for value boxes, creating visual noise. Switching to uniform white cards with subtle borders improved readability and gave the dashboard a more professional, consulting-style appearance.\nStandardized Layout\nBoth main tabs follow the same structure:\n\nKey metrics\nOptional filters\nDetailed charts\n\nThis consistency reduces cognitive load and helps users quickly understand how to navigate the dashboard.\nUnified Interactivity\nAll charts use ggiraph for hover-based interaction, ensuring a consistent interaction model across maps, timelines, and distributions."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-15.html#technical-overview",
    "href": "projects/standalone_visualizations/sa_2025-12-15.html#technical-overview",
    "title": "Exploring a Century of Meteorite Discoveries",
    "section": "Technical Overview",
    "text": "Technical Overview\n\n\n\n\n\n\nArchitecture & Stack\n\n\n\n\n\nThe app uses a modular Shiny architecture:\n\n\nUI: ui_main.R, ui_tabs.R\n\n\nServer: server.R, server_charts.R\n\n\nGlobal setup: global.R\n\n\nCore technologies:\n\nR Shiny + shinydashboard\nggiraph (interactive charts)\nleaflet (mapping)\nDT (data tables)\ndplyr / ggplot2 (data manipulation and visualization)"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-15.html#deployment-lessons",
    "href": "projects/standalone_visualizations/sa_2025-12-15.html#deployment-lessons",
    "title": "Exploring a Century of Meteorite Discoveries",
    "section": "Deployment Lessons",
    "text": "Deployment Lessons\n\n\n\n\n\n\nExpand for Deployment Notes\n\n\n\n\n\nDependency Management - Spatial packages (terra, raster) require explicit declaration in DESCRIPTION - Indirect dependencies must be captured in renv.lock with renv::snapshot()\nPerformance Optimization\n- Binary data formats (.rds) load ~10x faster than text formats (.csv) - Essential for meeting shinyapps.ioâ€™s 60-second startup limit\nReproducibility - Lock all dependencies early to avoid deployment surprises - Test with rsconnect::appDependencies() before deploying"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-15.html#closing-takeaway",
    "href": "projects/standalone_visualizations/sa_2025-12-15.html#closing-takeaway",
    "title": "Exploring a Century of Meteorite Discoveries",
    "section": "Closing Takeaway",
    "text": "Closing Takeaway\n\n\n\n\n\n\nNote\n\n\n\nThis project reinforced a simple but powerful lesson: effective dashboards are designed, not assembled. Clarity, consistency, and restraint mattered more than adding features â€” both in code and in communication."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-15.html#explore-the-dashboard",
    "href": "projects/standalone_visualizations/sa_2025-12-15.html#explore-the-dashboard",
    "title": "Exploring a Century of Meteorite Discoveries",
    "section": "Explore the Dashboard",
    "text": "Explore the Dashboard\nðŸ‘‰ Live app: https://0l6jpd-steven-ponce.shinyapps.io/Meteorite_Landings/"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-15.html#session-info",
    "href": "projects/standalone_visualizations/sa_2025-12-15.html#session-info",
    "title": "Exploring a Century of Meteorite Discoveries",
    "section": "Session Info",
    "text": "Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.0    fastmap_1.2.0     cli_3.6.4        \n [5] htmltools_0.5.8.1 tools_4.4.0       rstudioapi_0.17.1 yaml_2.3.10      \n [9] rmarkdown_2.29    knitr_1.49        jsonlite_1.8.9    xfun_0.49        \n[13] digest_0.6.37     rlang_1.1.6       renv_1.0.3        evaluate_1.0.1"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-15.html#github-repository",
    "href": "projects/standalone_visualizations/sa_2025-12-15.html#github-repository",
    "title": "Exploring a Century of Meteorite Discoveries",
    "section": "GitHub Repository",
    "text": "GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nAccess the GitHub repository here"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-15.html#references",
    "href": "projects/standalone_visualizations/sa_2025-12-15.html#references",
    "title": "Exploring a Century of Meteorite Discoveries",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\n\nNASA Meteorite Landings Dataset: https://catalog.data.gov/dataset/meteorite-landings\n\nShiny Documentation: https://shiny.posit.co/\n\nggiraph: https://davidgohel.github.io/ggiraph/\n\nLeaflet for R: https://rstudio.github.io/leaflet/"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-15.html#citation",
    "href": "projects/standalone_visualizations/sa_2025-12-15.html#citation",
    "title": "Exploring a Century of Meteorite Discoveries",
    "section": "Citation",
    "text": "Citation\n\n\n\n\n\n\nExpand for Citation\n\n\n\n\n\nTo cite this dashboard: Ponce, S. (2025). NASA Meteorite Explorer: Interactive Dashboard. Retrieved from https://0l6jpd-steven-ponce.shinyapps.io/Meteorite_Landings/"
  },
  {
    "objectID": "data_visualizations/MakeoverMonday/2025/mm_2025_49.html",
    "href": "data_visualizations/MakeoverMonday/2025/mm_2025_49.html",
    "title": "Estimated crime rates are ~134% higher in Londonâ€™s mostdeprived neighborhoods",
    "section": "",
    "text": "Original\nThe original visualization comes from London crimes by income deprivation decile\n\n\nOriginal visualization\n\nMakeover\n\n\n\n\n\nFigureÂ 1: Area chart showing estimated crime rates per 10,000 residents across Londonâ€™s income deprivation deciles, from most deprived (1) to least deprived (10). Crime rates are much higher in more deprived areas: the most deprived decile has about 1,656 crimes per 10,000 residents, which is roughly 134% higher than the least deprived decile at about 707. Rates peak around the second and third-most deprived deciles and then decline steadily toward the least deprived areas. Rates are based on equal-population estimates per decile and should be interpreted comparatively rather than as exact values.\n\n\nMethodology & Data Sources\nPopulation Estimates & Per Capita Calculations\nThis analysis uses per capita crime rates (crimes per 10,000 residents) rather than raw counts to enable fair comparison across income deprivation deciles. Since population data aggregated by income deprivation decile was not readily available, we estimated populations based on:\n\n\nLondon LSOA count: 4,835 Lower Layer Super Output Areas (London Datastore)\n\nAverage LSOA population: 1,722 residents\n\nEstimated population per decile: ~833,000 residents (assuming roughly equal distribution)\n\nTotal estimated: 8.33 million (vs.Â 8.9 million actual London population, 2021 Census)\n\nNote: Trust for London uses London-rebased income deprivation deciles, ranking only Londonâ€™s 4,835 LSOAs into deciles (not England-wide rankings).\nCritical Limitations & Assumptions\n\n\n\n\n\n\nKey Assumptions About Population Estimates\n\n\n\n\n\n1. Equal Distribution Assumption - We assume approximately equal population across all 10 income deprivation deciles - Each decile: ~483-484 LSOAs Ã— 1,722 residents = ~833,000 people - This is a simplification - actual populations likely vary by decile\n2. Why Estimates Were Necessary - IoD2025 File 7 (official population denominators) was not accessible - No readily available population data aggregated by income deprivation decile - Per capita analysis requires population denominators for meaningful comparison\n3. Validity of Findings - Under equal-population assumption: 134% difference persists (raw counts = per capita rates) - This suggests the crime disparity is real, not merely a population artifact - More deprived areas may have different population density than affluent areas\n4. Interpretation Guidance - Per capita rates shown are based on estimated, not actual, populations - True rates may vary if actual population distribution differs significantly - Treat values as comparative rather than exact - All visualizations note this limitation in titles/subtitles/captions\n\n\n\nData Preparation Pipeline\nThe CSV files used in this analysis were generated using a Python preprocessing script that calculated per capita crime rates with population estimates.\n\n\n\n\n\n\nReproducibility: Data Preparation Steps\n\n\n\n\n\nTo reproduce the analysis from raw data:\n\n\nRun the Python preprocessing script:\n\nScript: mm_2025_week49_prep.py\n\nInput: mom_week49_data.csv (raw crime counts from data.world)\nOutput: Two tidy CSV files with per capita rates\n\n\n\nRun the R visualization script (this document)\n\nUses the pre-calculated per capita rates\nCreates the final visualization\n\n\n\nThe Python script documents: - Population estimation methodology (4,835 LSOAs Ã— 1,722 avg residents) - Per capita rate calculations (crimes per 10,000 residents)\n- All assumptions and limitations (detailed above)\nRepository: MakeoverMonday/2025/Week_49\n\n\n\nData Sources\n\n\nCrime Data: Trust for London, DataPoliceUK (January-December 2024)\n\nDeprivation Rankings: Indices of Multiple Deprivation 2025 (IoD2025)\n\nPopulation Reference: London Datastore - LSOA Atlas\n\n\nChallenge Data: data.world - MakeoverMonday Week 49\n\nSteps to Create this Graphic \n1. Load Packages & Setup\n\nShow code```{r}\n#| label: load\n#| warning: false\n#| message: false\n#| results: \"hide\"\n\n## 1. LOAD PACKAGES & SETUP ----\nsuppressPackageStartupMessages({\n  if (!require(\"pacman\")) install.packages(\"pacman\")\n  pacman::p_load(\n  tidyverse,     # Easily Install and Load the 'Tidyverse'\n  janitor,       # Simple Tools for Examining and Cleaning Dirty Data\n  skimr,         # Compact and Flexible Summaries of Data\n  scales,        # Scale Functions for Visualization\n  ggtext,        # Improved Text Rendering Support for 'ggplot2'\n  showtext,      # Using Fonts More Easily in R Graphs\n  glue           # Interpreted String Literals\n)\n})\n\n### |- figure size ----\ncamcorder::gg_record(\n    dir    = here::here(\"temp_plots\"),\n    device = \"png\",\n    width  = 10,\n    height = 8,\n    units  = \"in\",\n    dpi    = 320\n)\n\n# Source utility functions\nsuppressMessages(source(here::here(\"R/utils/fonts.R\")))\nsource(here::here(\"R/utils/social_icons.R\"))\nsource(here::here(\"R/utils/image_utils.R\"))\nsource(here::here(\"R/themes/base_theme.R\"))\n```\n\n\n2. Read in the Data\n\nShow code```{r}\n#| label: read\n#| include: true\n#| eval: true\n#| warning: false\n#|\n\ntotal_crimes_by_decile &lt;- read_csv(\n   here::here(\"data/MakeoverMonday/2025/london_total_crimes_by_deprivation.csv\")) |&gt;\n  clean_names()\n```\n\n\n3. Examine the Data\n\nShow code```{r}\n#| label: examine\n#| include: true\n#| eval: true\n#| results: 'hide'\n#| warning: false\n\nglimpse(total_crimes_by_decile)\nskim(total_crimes_by_decile) |&gt; summary()\n```\n\n\n4. Tidy Data\n\nShow code```{r}\n#| label: tidy\n#| warning: false\n\n### |-  data wrangling ----\n# Baseline = least deprived (decile 10)\nbaseline_rate &lt;- total_crimes_by_decile |&gt;\n  filter(decile_num == 10) |&gt;\n  pull(total_crimes_per_10k)\n\ncrime_gradient &lt;- total_crimes_by_decile |&gt;\n  mutate(\n    baseline_rate = baseline_rate,\n    rate_ratio = total_crimes_per_10k / baseline_rate,\n    pct_difference = ((total_crimes_per_10k - baseline_rate) / baseline_rate) * 100\n  )\n\n# Values for annotations\nmost_deprived_rate &lt;- crime_gradient |&gt; filter(decile_num == 1)  |&gt; pull(total_crimes_per_10k)\nleast_deprived_rate &lt;- crime_gradient |&gt; filter(decile_num == 10) |&gt; pull(total_crimes_per_10k)\noverall_pct_diff &lt;- crime_gradient |&gt; filter(decile_num == 1) |&gt; pull(pct_difference)\n\n# Identify peak decile \npeak_decile &lt;- crime_gradient |&gt;\n  slice_max(total_crimes_per_10k, n = 1, with_ties = FALSE) |&gt;\n  pull(decile_num)\n\npeak_rate &lt;- crime_gradient |&gt;\n  filter(decile_num == peak_decile) |&gt;\n  pull(total_crimes_per_10k)\n```\n\n\n5. Visualization Parameters\n\nShow code```{r}\n#| label: params\n#| include: true\n#| warning: false\n\n### |-  plot aesthetics ----\n# Get base colors with custom palette\ncolors &lt;- get_theme_colors(\n  palette = list(\n    col_primary = \"#1E3A5F\",\n    col_danger  = \"#B5532F\"\n  )\n)\n\n### |-  Main titles ----\ntitle_text &lt;- \"Estimated crime rates are ~134% higher in Londonâ€™s most&lt;br&gt;deprived neighborhoods\"\n\nsubtitle_text &lt;- str_glue(\n  \"Per 10,000 residents by income deprivation decile (2024). \",\n  \"Rates use an equal-population estimate (~833k residents&lt;br&gt;per decile; interpret comparatively). \"\n)\n\ncaption_text &lt;- create_social_caption_02_mm(\n  mm_year = 2025, mm_week = 49,\n  source_text = str_glue(\n    \"**Crime Data:** Trust for London, DataPoliceUK (2024) | \",\n    \"**Deprivation Rankings:** Indices of Multiple Deprivation 2025&lt;br&gt;\"\n  ),\n  note_text = str_glue(\n    \"**Methodology:** Rates are normalized per 10,000 residents assuming equal population per decile (~833k). \",\n    \"Because true populations by decile may vary,&lt;br&gt;treat values as **comparative** rather than exact. \",\n    \"London-rebased deciles rank neighborhoods within London only.&lt;br&gt;\"\n  )\n)\n\n### |-  fonts ----\nsetup_fonts()\nfonts &lt;- get_font_families()\n\n### |-  plot theme ----\n\n# Start with base theme\nbase_theme &lt;- create_base_theme(colors)\n\n# Add weekly-specific theme elements\nweekly_theme &lt;- extend_weekly_theme(\n  base_theme,\n  theme(\n    # # Text styling\n    plot.title = element_text(\n      size = rel(1.5), family = fonts$title, face = \"bold\",\n      color = colors$title, lineheight = 1.1, hjust = 0,\n      margin = margin(t = 5, b = 10)\n    ),\n    plot.subtitle = element_markdown(\n      size = rel(0.9), family = fonts$subtitle, face = \"italic\",\n      color = alpha(colors$subtitle, 0.9), lineheight = 1.1,\n      margin = margin(t = 0, b = 20)\n    ),\n\n    # Legend formatting\n    legend.position = \"plot\",\n    legend.justification = \"right\",\n    legend.margin = margin(l = 12, b = 5),\n    legend.key.size = unit(0.8, \"cm\"),\n    legend.box.margin = margin(b = 10),\n\n    # Axis formatting\n    axis.ticks.y = element_blank(),\n    axis.ticks.x = element_line(color = \"gray\", linewidth = 0.5),\n    \n    axis.title.x = element_text(\n      face = \"bold\", size = rel(0.85),\n      margin = margin(t = 10), family = fonts$subtitle,\n      color = \"gray40\" \n    ),\n    axis.title.y = element_text(\n      face = \"bold\", size = rel(0.85),\n      margin = margin(r = 10), family = fonts$subtitle,\n      color = \"gray40\" \n    ),\n    axis.text.x = element_text(\n      size = rel(0.85), family = fonts$subtitle,\n      color = \"gray40\"  \n    ),\n    axis.text.y = element_markdown(\n      size = rel(0.85), family = fonts$subtitle,\n      color = \"gray40\"\n    ),\n\n    # Grid lines\n    panel.grid.minor = element_line(color = \"#ecf0f1\", linewidth = 0.2),\n    panel.grid.major = element_line(color = \"#ecf0f1\", linewidth = 0.4),\n\n    # Margin\n    plot.margin = margin(20, 20, 20, 20)\n  )\n)\n\n# Set theme\ntheme_set(weekly_theme)\n```\n\n\n6. Plot\n\nShow code```{r}\n#| label: plot\n#| warning: false\n\n### |-  main plot ----\np &lt;- \n  ggplot(crime_gradient, aes(x = decile_num, y = total_crimes_per_10k)) +\n  # Geoms\n  geom_area(fill = colors$palette$col_primary, alpha = 0.20) +\n  geom_line(color = colors$palette$col_primary, linewidth = 1.5) +\n  geom_point(color = colors$palette$col_primary, size = 3) +\n  geom_point(\n    data = crime_gradient |&gt; filter(decile_num %in% c(1, 10)),\n    size = 6, color = colors$palette$col_danger\n  ) +\n  # Annotations\n  annotate(\n    \"text\",\n    x = 1.1, y = 1350,\n    label = glue(\n      \"Most deprived areas (Decile 1):\\n\",\n      \"{comma(round(most_deprived_rate))} crimes per 10k\\n\",\n      \"({round(overall_pct_diff)}% higher than least deprived)\"\n    ),\n    size = 3.6, hjust = 0,\n    fontface = \"bold\", lineheight = 1.1,\n    color = colors$palette$col_danger\n  ) +\n  annotate(\n    \"text\",\n    x = 10.0, y = 1050,\n    label = glue(\n      \"Least deprived areas (Decile 10):\\n\",\n      \"{comma(round(least_deprived_rate))} crimes per 10k\\n\",\n      \"(Baseline for comparison)\"\n    ),\n    size = 3.6, hjust = 1,\n    fontface = \"bold\", lineheight = 1.1,\n    color = colors$palette$col_primary\n  ) +\n  annotate(\n    \"text\",\n    x = peak_decile, y = 2700,\n    label = \"Peak occurs around deciles 2â€“3\",\n    size = 3.2,\n    fontface = \"bold\",\n    color = colors$palette$col_primary,\n    vjust = -0.2\n  ) +\n  annotate(\n    \"text\",\n    x = 5.5, y = 200,\n    label = str_wrap(\n      \"Note: Income deprivation deciles rank London's neighborhoods from most (1) to least (10) deprived. Each decile represents ~10% of areas.\",\n      width = 86\n    ),\n    size = 3,\n    color = \"gray30\",\n    lineheight = 1.1,\n    hjust = 0.5\n  ) +\n  # Scales\n  scale_x_continuous(\n    breaks = 1:10,\n    labels = c(\n      \"1\\nMost\\nDeprived\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\",\n      \"10\\nLeast\\nDeprived\"\n    )\n  ) +\n  scale_y_continuous(\n    labels = comma,\n    limits = c(0, 2700),\n    breaks = seq(0, 2500, 500)\n  ) +\n  # Labs\n  labs(\n    title = title_text,\n    subtitle = subtitle_text,\n    caption = caption_text,\n    x = \"Income Deprivation Decile\",\n    y = \"Crimes per 10,000 Residents\"\n  ) +\n  # Theme\n  theme(\n    plot.title = element_markdown(\n      size = rel(1.9),\n      family = fonts$title,\n      face = \"bold\",\n      color = colors$title,\n      lineheight = 1.15,\n      margin = margin(t = 5, b = 10)\n    ),\n    plot.subtitle = element_markdown(\n      size = rel(0.88),\n      family = fonts$subtitle,\n      color = alpha(colors$subtitle, 0.88),\n      lineheight = 1.5,\n      margin = margin(t = 5, b = 20)\n    ),\n    plot.caption = element_markdown(\n      size = rel(0.65),\n      family = fonts$subtitle,\n      color = colors$caption,\n      hjust = 0,\n      lineheight = 1.4,\n      margin = margin(t = 20, b = 5)\n    ),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor.y = element_blank(),\n    panel.grid.major.y = element_line(color = \"gray90\", linewidth = 0.3),\n  )\n```\n\n\n7. Save\n\nShow code```{r}\n#| label: save\n#| warning: false\n\n### |-  plot image ----  \nsave_plot(\n  plot = p, \n  type = \"makeovermonday\", \n  year = current_year,\n  week = current_week,\n  width = 10, \n  height = 8\n  )\n```\n\n\n8. Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] here_1.0.1      glue_1.8.0      showtext_0.9-7  showtextdb_3.0 \n [5] sysfonts_0.8.9  ggtext_0.1.2    scales_1.3.0    skimr_2.1.5    \n [9] janitor_2.2.0   lubridate_1.9.3 forcats_1.0.0   stringr_1.5.1  \n[13] dplyr_1.1.4     purrr_1.0.2     readr_2.1.5     tidyr_1.3.1    \n[17] tibble_3.2.1    ggplot2_3.5.1   tidyverse_2.0.0 pacman_0.5.1   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 tzdb_0.5.0       \n [5] vctrs_0.6.5       tools_4.4.0       generics_0.1.3    curl_6.0.0       \n [9] parallel_4.4.0    gifski_1.32.0-1   fansi_1.0.6       pkgconfig_2.0.3  \n[13] lifecycle_1.0.4   farver_2.1.2      compiler_4.4.0    textshaping_0.4.0\n[17] munsell_0.5.1     repr_1.1.7        codetools_0.2-20  snakecase_0.11.1 \n[21] htmltools_0.5.8.1 yaml_2.3.10       crayon_1.5.3      pillar_1.9.0     \n[25] camcorder_0.1.0   magick_2.8.5      commonmark_1.9.2  tidyselect_1.2.1 \n[29] digest_0.6.37     stringi_1.8.4     rsvg_2.6.1        rprojroot_2.0.4  \n[33] fastmap_1.2.0     grid_4.4.0        colorspace_2.1-1  cli_3.6.4        \n[37] magrittr_2.0.3    base64enc_0.1-3   utf8_1.2.4        withr_3.0.2      \n[41] bit64_4.5.2       timechange_0.3.0  rmarkdown_2.29    bit_4.5.0        \n[45] ragg_1.3.3        hms_1.1.3         evaluate_1.0.1    knitr_1.49       \n[49] markdown_1.13     rlang_1.1.6       gridtext_0.1.5    Rcpp_1.0.13-1    \n[53] xml2_1.3.6        renv_1.0.3        vroom_1.6.5       svglite_2.1.3    \n[57] rstudioapi_0.17.1 jsonlite_1.8.9    R6_2.5.1          systemfonts_1.1.0\n\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in mm_2025_49.qmd.\nFor the full repository, click here.\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\n\n\nData:\n\nMakeover Monday 2025 Week 49: London crimes by income deprivation decile\n\n\n\n\nArticle\n\nLondon crimes by income deprivation decile\n\n\n\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\n\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\n\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\n\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n Back to topCitationBibTeX citation:@online{ponce2025,\n  author = {Ponce, Steven},\n  title = {Estimated Crime Rates Are \\textasciitilde134\\% Higher in\n    {Londonâ€™s} Most\\textless br\\textgreater deprived Neighborhoods},\n  date = {2025-12-16},\n  url = {https://stevenponce.netlify.app/data_visualizations/MakeoverMonday/2025/mm_2025_49.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPonce, Steven. 2025. â€œEstimated Crime Rates Are ~134% Higher in\nLondonâ€™s Most&lt;br&gt;deprived Neighborhoods.â€ December 16,\n2025. https://stevenponce.netlify.app/data_visualizations/MakeoverMonday/2025/mm_2025_49.html."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-19.html",
    "href": "projects/standalone_visualizations/sa_2025-12-19.html",
    "title": "Building an Executive-Grade Train Operations Dashboard",
    "section": "",
    "text": "ðŸš€ Live app: https://0l6jpd-steven-ponce.shinyapps.io/UK_train_operations/\nðŸ’» Source code: https://github.com/poncest/UK_train_operations"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-19.html#why-this-project",
    "href": "projects/standalone_visualizations/sa_2025-12-19.html#why-this-project",
    "title": "Building an Executive-Grade Train Operations Dashboard",
    "section": "Why this project",
    "text": "Why this project\nMost dashboards fail not because of poor data, but because they try to serve everyone at once. This project explores how to design a single Shiny application that supports executive, operations, and revenue decisionsâ€”without sacrificing clarity, performance, or trust.\nThis project explores how to design a single Shiny application that supports three distinct decision-makersâ€”without sacrificing usability, performance, or narrative focus. The goal was not to visualize everything, but to help the right people answer the right questions quickly.\n\nNote: All data, benchmarks, and financial impacts shown here are synthetic and illustrative, used solely to demonstrate analytical thinking and dashboard design."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-19.html#the-challenge",
    "href": "projects/standalone_visualizations/sa_2025-12-19.html#the-challenge",
    "title": "Building an Executive-Grade Train Operations Dashboard",
    "section": "The challenge",
    "text": "The challenge\nRail operations generate vast amounts of dataâ€”journeys, delays, ticket sales, booking patternsâ€”but these signals are often fragmented across systems. As a result:\n\nExecutives struggle to spot performance shifts quickly\nOperations teams lack a unified view of delay drivers\nRevenue analysts miss cross-route pricing and concentration risks\n\nThe challenge wasnâ€™t building a dashboard. It was building three dashboards in one, each tailored to a distinct stakeholderâ€”without creating a cluttered, one-size-fits-all interface that satisfies no one."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-19.html#designing-for-three-personas",
    "href": "projects/standalone_visualizations/sa_2025-12-19.html#designing-for-three-personas",
    "title": "Building an Executive-Grade Train Operations Dashboard",
    "section": "Designing for three personas",
    "text": "Designing for three personas\nRather than present everything at once, the dashboard is structured around three clear use cases.\nExecutive overview\nPurpose: Monitor performance at a glance, identify trends, and surface opportunities\nKey elements:\n\nFour headline KPIs with month-over-month trend indicators\nA one-sentence executive takeaway using consulting-style language\nDaily journey volume trends for context\nA concise insights panel summarizing what matters most\n\n\n\n\n\n\nFigureÂ 1: Executive Overview showing KPIs with trend indicators, executive summary, and daily performance trends.\n\n\nOperations analytics\nPurpose: Diagnose delay drivers and prioritize operational interventions\nKey elements:\n\nTime-period filtering (Morning Peak, Evening Peak, Off-Peak)\nRoute-level delay rate analysis\nDelay reason breakdown highlighting root causes\nSeverity distribution showing operational impact\n\n\n\n\n\n\nFigureÂ 2: Operations Analytics with time period filtering, delay diagnostics, and route performance metrics.\n\n\nRevenue intelligence\nPurpose: Analyze booking behavior, pricing patterns, and revenue concentration\nKey elements:\n\nBooking window analysis (same-day vs.Â advance)\nRevenue by time period\nTicket price distribution\nChannel performance (online vs.Â station)\nRoute-level revenue concentration metrics\n\n\n\n\n\n\nFigureÂ 3: Revenue Intelligence analyzing pricing strategies, booking patterns, and channel performance."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-19.html#key-insights-from-the-data",
    "href": "projects/standalone_visualizations/sa_2025-12-19.html#key-insights-from-the-data",
    "title": "Building an Executive-Grade Train Operations Dashboard",
    "section": "Key insights from the data",
    "text": "Key insights from the data\nNetwork performance (Janâ€“Apr 2024)\nTakeaway: Reliability is strong, but volume softness and delay duration still pose risk.\n\n31,653 journeys generated Â£742k in revenue (Â£23.44 average fare)\n92.8% on-time performance (above 89% industry benchmark)\n7.2% delay rate, with average delays of 42.5 minutes when they occur\nRoute concentration risk\nTakeaway: A small number of routes drive a disproportionate share of value.\n\nTop 5 routes account for 28% of total journey volume\nManchester Piccadilly â†’ Liverpool Lime Street leads with 5,128 journeys\nTop 10 routes represent 45% of total revenue, increasing concentration risk\nOperational patterns\nTakeaway: Delays cluster in predictable windows, enabling targeted intervention.\n\nMorning Peak has the highest delay rate (12.5%)\nWeather is the leading delay cause (42.8%), followed by Technical Issues (18.3%)\nDelay patterns are consistent by time period, not random\nDigital adoption gap\nTakeaway: Channel migration represents a clear near-term opportunity.\n\n58.5% digital adoption vs.Â 65% industry benchmark\nOnline channel generates 51.6% of revenue despite 58.5% of volume\nLower average online fares suggest pricing or product mix opportunity\nRevenue optimization potential\nTakeaway: Yield management levers remain underutilized.\n\nPeak fares are +40.3% higher than off-peak\nOnly 12.1% of tickets are purchased 8+ days in advance\n62% of tickets fall in the â€œBudgetâ€ category (&lt;Â£15)"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-19.html#design-decisions-that-elevated-the-dashboard",
    "href": "projects/standalone_visualizations/sa_2025-12-19.html#design-decisions-that-elevated-the-dashboard",
    "title": "Building an Executive-Grade Train Operations Dashboard",
    "section": "Design decisions that elevated the dashboard",
    "text": "Design decisions that elevated the dashboard\nFive specific choices that elevated usability and stakeholder engagement:\n1. Executive takeaway box\nA single, consulting-style summary at the top of the Executive tab reframed how users engage:\n\nCore service reliability remains strong (92.8% on-time), while recent softness in journey volume and sub-benchmark digital adoption indicate near-term opportunities in demand stimulation and channel migration.\n\nThis immediately answers: Whatâ€™s working? Whatâ€™s not? What should we do next?\n2. Trend indicators on KPIs\nMonth-over-month arrows provide context that raw numbers cannot. Executives care more about direction than magnitude.\n3. Info tooltips for clarity\nSubtle â„¹ï¸ icons explain metrics like â€œDigital Adoptionâ€ without cluttering the interface, reducing friction for new users.\n4. Unified visual language\nA restrained color palette replaced early rainbow gradients, resulting in a cohesive, consulting-grade aesthetic.\n5. Horizontal bar charts\nLong route and time-period labels remain readable, reducing cognitive load and improving scanability."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-19.html#technical-architecture",
    "href": "projects/standalone_visualizations/sa_2025-12-19.html#technical-architecture",
    "title": "Building an Executive-Grade Train Operations Dashboard",
    "section": "Technical architecture",
    "text": "Technical architecture\nThe application uses a modular Shiny architecture optimized for performance through aggressive reactive caching.\nCore structure\n\n\napp.R â€” Main application entry point\n\nR/mod_executive.R â€” Executive overview module\n\nR/mod_operations.R â€” Operations analytics module\n\nR/mod_revenue.R â€” Revenue intelligence module\nTechnology stack\n\n\nshiny.semantic â€” Modern Semantic UI framework\n\nggiraph â€” Interactive, hover-enabled charts\n\nreactable â€” Professional data tables\n\nggplot2 + dplyr + tidyr â€” Data manipulation and visualization\n\nbindCache() â€” Reactive caching for performance\nPerformance results\n\nInitial load time reduced from ~8â€“10 seconds to &lt;2 seconds\nExpensive computations cached\nSummary metrics pre-aggregated"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-19.html#making-the-dashboard-production-ready",
    "href": "projects/standalone_visualizations/sa_2025-12-19.html#making-the-dashboard-production-ready",
    "title": "Building an Executive-Grade Train Operations Dashboard",
    "section": "Making the dashboard production-ready",
    "text": "Making the dashboard production-ready\nDependency management\n\nRemoved all install.packages() calls from runtime code\nUsed explicit package imports\nExcluded development artifacts via .rscignore\n\nModal implementation\n\nUsed Semantic UI modals (create_modal()) instead of shiny::modalDialog()\n\nEnsured reliable triggering via JavaScript event handling\nDeployment\nrsconnect::deployApp(\n  appName = \"UK_train_operations\",\n  forceUpdate = TRUE\n)"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-19.html#strategic-recommendations",
    "href": "projects/standalone_visualizations/sa_2025-12-19.html#strategic-recommendations",
    "title": "Building an Executive-Grade Train Operations Dashboard",
    "section": "Strategic recommendations",
    "text": "Strategic recommendations\nThe following recommendations are illustrative examples of how this dashboard could support strategic decision-making.\n1. Channel migration initiative\nGoal: Increase digital adoption from 58.5% â†’ 65%\nTactics:\n\nIncentivize first-time online booking\nImprove mobile UX\nExpand digital partnerships\n\nExpected impact: +Â£45k annual revenue (illustrative)\n2. Peak period capacity management\nGoal: Reduce Morning Peak delay rate from 12.5% â†’ 9.0%\nTactics:\n\nAdd rolling stock on high-impact routes\nDynamic crew scheduling\n\nExpected impact: +3.5pp on-time performance\n3. Revenue optimization\nGoal: Increase advance booking rate from 12.1% â†’ 18%\nTactics:\n\nAdvance-purchase discounts\nFare bundling experiments\n\nExpected impact: +Â£28k annual revenue (illustrative)"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-19.html#five-lessons-from-building-executive-grade-dashboards",
    "href": "projects/standalone_visualizations/sa_2025-12-19.html#five-lessons-from-building-executive-grade-dashboards",
    "title": "Building an Executive-Grade Train Operations Dashboard",
    "section": "Five lessons from building executive-grade dashboards",
    "text": "Five lessons from building executive-grade dashboards\n\n\nClarity beats completeness â€” Fewer metrics, better decisions\n\nPerformance matters â€” Slow dashboards donâ€™t get used\n\nLanguage matters â€” Consulting-style framing builds credibility\n\nDesign is strategic â€” UX decisions shape adoption\n\nDocumentation is part of the product â€” Explaining why matters as much as how"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-19.html#potential-extensions",
    "href": "projects/standalone_visualizations/sa_2025-12-19.html#potential-extensions",
    "title": "Building an Executive-Grade Train Operations Dashboard",
    "section": "Potential extensions",
    "text": "Potential extensions\nIf this were a production deployment, next priorities would include:\n\nPredictive delay forecasting using historical patterns\nAutomated alert system for performance anomalies\nIntegration with real-time operations data\nMobile-optimized responsive design\nMulti-language support for international routes"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-19.html#closing-takeaway",
    "href": "projects/standalone_visualizations/sa_2025-12-19.html#closing-takeaway",
    "title": "Building an Executive-Grade Train Operations Dashboard",
    "section": "Closing takeaway",
    "text": "Closing takeaway\nEffective business intelligence isnâ€™t about showing all available dataâ€”itâ€™s about answering the right questions for the right people. In dashboard design and stakeholder communication alike, clarity consistently beats complexity."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-19.html#session-info",
    "href": "projects/standalone_visualizations/sa_2025-12-19.html#session-info",
    "title": "Building an Executive-Grade Train Operations Dashboard",
    "section": "Session Info",
    "text": "Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/La_Paz\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.0    fastmap_1.2.0     cli_3.6.4        \n [5] htmltools_0.5.8.1 tools_4.4.0       rstudioapi_0.17.1 yaml_2.3.10      \n [9] rmarkdown_2.29    knitr_1.49        jsonlite_1.8.9    xfun_0.49        \n[13] digest_0.6.37     rlang_1.1.6       renv_1.0.3        evaluate_1.0.1"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-19.html#github-repository",
    "href": "projects/standalone_visualizations/sa_2025-12-19.html#github-repository",
    "title": "Building an Executive-Grade Train Operations Dashboard",
    "section": "GitHub Repository",
    "text": "GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nAccess the GitHub repository here"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-19.html#references",
    "href": "projects/standalone_visualizations/sa_2025-12-19.html#references",
    "title": "Building an Executive-Grade Train Operations Dashboard",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\n\nMaven Analytics â€” UK Train Operations (Synthetic Dataset)\nShiny Documentation: https://shiny.posit.co/\n\nAppsilon shiny.semantic: https://appsilon.github.io/shiny.semantic/\n\nggiraph: https://davidgohel.github.io/ggiraph/\n\nreactable: https://glin.github.io/reactable/"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-21.html",
    "href": "projects/standalone_visualizations/sa_2025-12-21.html",
    "title": "Analyzing Appleâ€™s ESG Strategy Through a Risk-Based Lens",
    "section": "",
    "text": "ðŸš€ Live app: [Apple ESG Strategy Dashboard]https://0l6jpd-steven-ponce.shinyapps.io/Apple_ESG/\nðŸ’» Source code: https://github.com/poncest/Apple_ESG"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-21.html#why-this-project",
    "href": "projects/standalone_visualizations/sa_2025-12-21.html#why-this-project",
    "title": "Analyzing Appleâ€™s ESG Strategy Through a Risk-Based Lens",
    "section": "Why this project",
    "text": "Why this project\nESG dashboards often show what happened without explaining what it means strategically. This project explores how to transform publicly available emissions data into a strategic decision-support tool using consulting frameworksâ€”risk matrices, controllability analysis, and scenario planning.\nThe goal wasnâ€™t to visualize every data point, but to answer the questions executives and analysts actually ask: Where has real progress occurred? What constraints do we face? What tradeoffs must leadership consider?\n\nNote: This is an independent portfolio project using publicly available Apple Environmental Progress Reports. It demonstrates analytical frameworks and strategic thinkingâ€”not internal Apple strategy or confidential information.\n\n\nAppleâ€™s 2030 carbon neutrality pledge is one of the technology sectorâ€™s most ambitious climate commitments. However, understanding progress requires more than tracking gross emissions:\n\n\n99.7% of emissions are Scope 3 (supply chain and product use), outside direct operational control\nReported metrics often conflate real reductions with carbon use of carbon removals\nStrategic dependencies on supplier cooperation and customer behavior create controllability constraints\nLeadership faces tradeoffs between breakthrough investment, timeline adjustment, and stakeholder expectations\n\nThe challenge wasnâ€™t building a dashboard that shows all the data. It was building a framework that helps decision-makers understand where they have leverage, what they can control, and what strategic choices they face.\n\nRather than organize by data tables, the dashboard is structured around five strategic questions.\nExecutive brief: Whatâ€™s the big picture?\nPurpose: Assess progress quickly, understand strategic dependencies, identify key risks\nKey elements:\n\nThree strategic insights synthesized from the data\nHigh-level KPIs with appropriate context\nRisk callout highlighting Scope 3 dependency\nGross vs.Â Net emissions trend showing minimal offset usage\n\n\n\n\n\n\nFigureÂ 1: Executive Brief showing strategic insights, KPIs, and risk callout\n\n\nEmissions reality: How real is the progress?\nPurpose: Distinguish genuine reductions from accounting adjustments or use of carbon removals\nKey elements:\n\nConsulting-style takeaway box summarizing key findings\nBaseline vs.Â current emissions with offset dependency metric\nEmissions by scope visualization (showing Scope 3 dominance)\nEmissions intensity improvement alongside revenue growth\nYear-over-year change analysis\n\n\n\n\n\n\nFigureÂ 2: Emissions Reality Check with scope breakdown and intensity trends\n\n\nWhere progress lives: What can Apple actually control?\nPurpose: Understand which emission sources Apple can influence vs.Â those requiring external cooperation\nKey elements:\n\nCorporate vs.Â Product Life Cycle emissions split\nTop Scope 3 contributors (manufacturing, product use, transportation)\niPhone carbon footprint improvement trend (29% reduction)\nControllability framework classifying sources as High/Medium/Low control\n\n\n\n\n\n\nFigureÂ 3: Where Progress Lives showing controllability analysis grid\n\n\nRisk lens: What strategic choices does leadership face?\nPurpose: Analyze dependencies, constraints, and strategic tradeoffs using risk-based frameworks\nKey elements:\n\nRisk matrix plotting Controllability Ã— Impact\nInteractive scenario analysis (â€œWhat if Scope 3 stalls?â€)\nPrimary risks vs.Â Strategic options comparison\nLeadership tradeoffs table with benefit/cost/time horizon\nRecommended portfolio approach\n\n\n\n\n\n\nFigureÂ 4: Where Progress Lives showing controllability analysis grid\n\n\nData explorer: Whatâ€™s in the underlying data?\nPurpose: Provide full transparency and enable analyst deep-dives\nKey elements:\n\nInteractive filters (year range, category, scope)\nSummary statistics with professional card layout\nSearchable, sortable data table\nCSV download for external analysis"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-21.html#key-insights-from-the-analysis",
    "href": "projects/standalone_visualizations/sa_2025-12-21.html#key-insights-from-the-analysis",
    "title": "Analyzing Appleâ€™s ESG Strategy Through a Risk-Based Lens",
    "section": "Key insights from the analysis",
    "text": "Key insights from the analysis\nReal progress, real constraints (2015â€“2022)\nTakeaway: Appleâ€™s 40% emissions reduction is operational, not cosmetic.\n\nGross emissions reduced 40% despite 69% revenue growth\nEmissions intensity improved 68% (177 â†’ 56 tCOâ‚‚e/$M revenue)\nOffset usage minimal (1.6%), signaling commitment to real reductions vs.Â purchased credits\nHowever, 99.7% Scope 3 dependency means future progress increasingly relies on suppliers\nThe controllability paradox\nTakeaway: Apple has largely addressed what it can directly control.\n\nCorporate facilities (Scope 1/2) essentially carbon-neutral through renewable energy\nHigh-control sources (packaging, business travel, product design) substantially improved\nRemaining emissions concentrated in low-control categories:\n\nCustomer electricity use (product operation)\nSupplier manufacturing energy\nUpstream raw material extraction\n\n\nDiminishing returns on incremental efficiency\nTakeaway: The next 29% reduction will be harder than the last.\n\niPhone carbon footprint: 79kg (2017) â†’ 56kg (2023) = 29% improvement\nRequired years of R&D in materials science and chip efficiency\nFurther gains likely require breakthrough innovations:\n\nRecycled aluminum and carbon fiber alternatives\nCircular design (modular components, repair programs)\nRenewable manufacturing at scale\n\n\nScenario analysis: What if Scope 3 stalls?\nKey finding: 2030 net zero would require mathematically impossible reduction rates.\n\nAt 0% Scope 3 reduction: 2030 emissions = 20.6M tCOâ‚‚e (current level)\nGap to net zero: 20.6M tCOâ‚‚e (100% of current emissions)\nRequired annual reduction: Mathematically impossible (would need to eliminate 100% of remaining emissions each year)\n\nImplication: Breakthrough innovation or timeline adjustment required"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-21.html#design-decisions-that-elevated-the-analysis",
    "href": "projects/standalone_visualizations/sa_2025-12-21.html#design-decisions-that-elevated-the-analysis",
    "title": "Analyzing Appleâ€™s ESG Strategy Through a Risk-Based Lens",
    "section": "Design decisions that elevated the analysis",
    "text": "Design decisions that elevated the analysis\nFive specific choices that transformed this from a data visualization into a strategic tool:\n1. Controllability framework over scope categories\nInstead of just showing Scope 1/2/3 (the standard ESG view), the dashboard classifies sources by Appleâ€™s actual influence:\n\n\nHigh Control: Corporate facilities, product design, packaging\n\nMedium Control: Supplier contracts, component specs, transportation\n\nLow Control: Customer behavior, grid electricity mix, end-of-life\n\nThis reframes the conversation from â€œwhat are the emissions?â€ to â€œwhat can we actually do about them?â€\n2. Risk matrix for strategic prioritization\nThe scatter plot of Controllability Ã— Impact immediately reveals:\n\n\nTop-right quadrant (High Impact, High Control): Strategic opportunitiesâ€”go here first\n\nTop-left quadrant (High Impact, Low Control): Strategic risksâ€”requires partnerships, policy, or innovation\nBottom quadrants: Lower priority\n\nThis gives executives a clear framework for resource allocation.\n3. Scenario planning over historical reporting\nThe â€œWhat if Scope 3 stalls?â€ slider lets users see the implications of different reduction trajectories:\n\nAt 5% annual reduction â†’ Still 65% of current emissions in 2030\nAt 10% annual reduction â†’ Net zero achievable but requires sustained execution\nAt 0% reduction â†’ 2030 target becomes unrealistic\n\nThis shifts the conversation from â€œare we on track?â€ to â€œwhat would it take to get there?â€\n4. Strategic options table instead of recommendations\nRather than prescribe a single path, the dashboard presents four strategic options with explicit tradeoffs:\n\nAggressive supplier contracts (near-term, addressable now, relationship risk)\nBreakthrough R&D investment (long-term, high potential, uncertain timeline)\nCircular economy pivot (transformative, revenue model risk, 10+ year horizon)\nTransparent timeline revision (credible, PR risk, avoids missed target)\n\nThis acknowledges complexity and respects that leadership must balance competing priorities.\n5. Consulting language throughout\nExamples of language refinements:\n\nâ€œLikely requiresâ€ instead of â€œdemandsâ€ (acknowledges uncertainty)\nâ€œShould prioritizeâ€ instead of â€œmust prioritizeâ€ (advisory not prescriptive)\nâ€œMathematically impossibleâ€ instead of â€œimpossibleâ€ (clarifies itâ€™s calculation, not hyperbole)\nâ€œBased on current trendsâ€ instead of absolute claims (appropriate hedging)\n\nThis tone signals professional judgment and strategic thinking."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-21.html#technical-architecture",
    "href": "projects/standalone_visualizations/sa_2025-12-21.html#technical-architecture",
    "title": "Analyzing Appleâ€™s ESG Strategy Through a Risk-Based Lens",
    "section": "Technical architecture",
    "text": "Technical architecture\nThe application uses a modular Shiny architecture with consulting-grade visual design.\nCore structure\n\n\napp.R â€” Main application with shinydashboard framework\n\nglobal.R â€” Data loading and configuration\n\ndata_preparation.R â€” Complete data pipeline with validation\n\nmodules/mod_executive_brief.R â€” Strategic insights and KPIs\n\nmodules/mod_emissions_reality.R â€” Detailed emissions analysis\n\nmodules/mod_progress_sources.R â€” Controllability framework\n\nmodules/mod_risk_lens.R â€” Risk matrix and scenario planning\n\nmodules/mod_data_explorer.R â€” Interactive data table\nTechnology stack\n\n\nshiny.semantic + shinydashboard â€” Modern UI with enterprise patterns\n\nggiraph â€” Interactive charts with consistent hover tooltips\n\nreactable â€” Professional data tables with search and download\n\nggplot2 + scales â€” Custom visualizations and formatting\n\ndplyr + tidyr â€” Data transformation and aggregation\n\nbindCache() â€” Performance optimization through reactive caching\nDesign system\n\n\nColor palette: Forest green (#2C5530), Charcoal (#2C2C2C), Warm amber (#D97C3A)\n\nTypography: System fonts, 600 weight headers, appropriate hierarchy\n\nLayout: Card-based, generous white space, progressive disclosure\n\nInteractivity: Hover tooltips, interactive filters, scenario sliders\nPerformance optimizations\n\nPre-aggregated summary statistics\nCached reactive computations with bindCache()\n\nModular architecture for maintainability\nLightweight data files (all &lt;50KB)"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-21.html#making-it-consulting-grade",
    "href": "projects/standalone_visualizations/sa_2025-12-21.html#making-it-consulting-grade",
    "title": "Analyzing Appleâ€™s ESG Strategy Through a Risk-Based Lens",
    "section": "Making it consulting-grade",
    "text": "Making it consulting-grade\nLanguage refinements\nFour key changes that elevated the professional tone:\n\n\nâ€œdemandâ€ â†’ â€œlikely requireâ€ â€” Acknowledges uncertainty appropriately\n\nâ€œmustâ€ â†’ â€œshouldâ€ â€” Advisory stance, not prescriptive\n\nâ€œimpossibleâ€ â†’ â€œmathematically impossibleâ€ â€” Clarifies itâ€™s calculation\n\nâ€œis not achievableâ€ â†’ â€œwould requireâ€ â€” More measured phrasing\nFramework thinking\nApplied standard consulting methodologies:\n\n\n2Ã—2 Risk Matrix â€” Controllability Ã— Impact\n\nScenario Planning â€” Multiple futures with slider input\n\nOptions Analysis â€” Pros/cons/tradeoffs for each path\n\nPortfolio Strategy â€” Balanced approach across time horizons\nVisual professionalism\n\nNo rainbow gradients or default color schemes\nNo dual-axis charts (replaced with side-by-side)\nConsistent card layout across all tabs\nProfessional typography and spacing"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-21.html#strategic-implications-illustrative",
    "href": "projects/standalone_visualizations/sa_2025-12-21.html#strategic-implications-illustrative",
    "title": "Analyzing Appleâ€™s ESG Strategy Through a Risk-Based Lens",
    "section": "Strategic implications (illustrative)",
    "text": "Strategic implications (illustrative)\nThe following represent the type of strategic thinking this framework enablesâ€”not actual recommendations for Apple.\nPortfolio approach: Hedge across time horizons\nNear-term (3-5 years): - Lock in top 5 suppliers with renewable energy contracts - Accelerate iPhone recycling programs - Expected impact: 15-20% Scope 3 reduction (illustrative)\nMedium-term (5-10 years): - Invest $500M annually in breakthrough materials R&D - Partner with research institutions on carbon fiber alternatives - Expected impact: Enable next 30% product footprint reduction\nLong-term (10+ years): - Circular economy transformation (modular design, repair-first) - Grid decarbonization advocacy and investment - Expected impact: Systemic emissions reduction\nRisk mitigation priorities\n\n\nSupplier concentration risk â€” No single supplier &gt;10% of manufacturing emissions\n\nInnovation timeline risk â€” Parallel R&D bets, quarterly go/no-go reviews\n\nCredibility risk â€” Transparent progress reporting, acknowledge constraints openly\n\nCompetitive risk â€” Patent protection on breakthrough materials"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-21.html#five-lessons-from-building-strategic-esg-analytics",
    "href": "projects/standalone_visualizations/sa_2025-12-21.html#five-lessons-from-building-strategic-esg-analytics",
    "title": "Analyzing Appleâ€™s ESG Strategy Through a Risk-Based Lens",
    "section": "Five lessons from building strategic ESG analytics",
    "text": "Five lessons from building strategic ESG analytics\n\n\nFrameworks elevate data â€” Risk matrices and scenario planning transform charts into strategy tools\n\nControllability matters more than scope categories â€” What you can influence &gt; accounting classifications\n\nHedging demonstrates judgment â€” â€œLikely requiresâ€ sounds more professional than â€œdemandsâ€\n\nTradeoffs beat prescriptions â€” Present options with costs/benefits, respect that leaders balance priorities\n\nDocumentation is strategic communication â€” README and blog post showcase thinking as much as code"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-21.html#potential-extensions",
    "href": "projects/standalone_visualizations/sa_2025-12-21.html#potential-extensions",
    "title": "Analyzing Appleâ€™s ESG Strategy Through a Risk-Based Lens",
    "section": "Potential extensions",
    "text": "Potential extensions\nIf this were a production deployment supporting actual strategy teams:\n\n\nReal-time supplier emissions tracking via API integration\n\nMonte Carlo simulation for scenario probability distributions\n\nCompetitive benchmarking vs.Â Microsoft, Google, Amazon climate commitments"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-21.html#closing-takeaway",
    "href": "projects/standalone_visualizations/sa_2025-12-21.html#closing-takeaway",
    "title": "Analyzing Appleâ€™s ESG Strategy Through a Risk-Based Lens",
    "section": "Closing takeaway",
    "text": "Closing takeaway\nThis project illustrates how sustainability data can be analyzed with the same rigor applied to financial or operational metrics: separating signal from presentation, assessing controllability rather than magnitude alone, and framing uncertainty explicitly.\nThe objective is not to judge performance, but to demonstrate a structured, defensible way to translate ESG disclosures into executive-relevant insights under real-world constraints."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2025-12-21.html#appendix",
    "href": "projects/standalone_visualizations/sa_2025-12-21.html#appendix",
    "title": "Analyzing Appleâ€™s ESG Strategy Through a Risk-Based Lens",
    "section": "Appendix",
    "text": "Appendix\nSession info\n\nBuilt with R, Shiny, ggplot2, reactable, and ggiraph\nModular architecture for clarity and extensibility\nData sourced from publicly available Apple Environmental Progress Reports (FY2015â€“FY2022)\nGitHub repository\nhttps://github.com/poncest/Apple_ESG\nReferences\n\nApple Inc.Â Environmental Progress Reports (2015â€“2022)\nGreenhouse Gas Protocol (Scope 1, 2, 3 guidance)\nMaven Analytics â€” Apple Emissions Dataset"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-03.html",
    "href": "projects/standalone_visualizations/sa_2026-01-03.html",
    "title": "Building a Hypothesis-Driven Financial Analysis Dashboard",
    "section": "",
    "text": "ðŸš€ Live app:Microsoft Financial Analysis Dashboard\nðŸ’» Source code:GitHub repository"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-03.html#introduction",
    "href": "projects/standalone_visualizations/sa_2026-01-03.html#introduction",
    "title": "Building a Hypothesis-Driven Financial Analysis Dashboard",
    "section": "Introduction",
    "text": "Introduction\nMicrosoftâ€™s reported financial results over the past decade point to a company that is larger, more profitable, and more cash-generative than at any point in its history. Revenue has more than doubled since FY2016, operating margins have expanded materially, and free cash flow has remained consistently strong.\nThe harder question is whether these improvements reflect structural change in the business model â€” or simply the arithmetic effects of scale and favorable mix.\nThis post summarizes a disciplined financial analysis of Microsoftâ€™s consolidated results from FY2016â€“FY2023, focusing on what the data supports, what it suggests, and what it cannot resolve on its own."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-03.html#questions-this-analysis-examines",
    "href": "projects/standalone_visualizations/sa_2026-01-03.html#questions-this-analysis-examines",
    "title": "Building a Hypothesis-Driven Financial Analysis Dashboard",
    "section": "Questions This Analysis Examines",
    "text": "Questions This Analysis Examines\n\nHas revenue growth accelerated in recent years, or primarily reflected scale?\nAre margin improvements better explained by business mix than cost compression?\nHas cash generation remained resilient alongside continued investment?\nDo balance sheet trends indicate increased financial flexibility?\n\nEach question is evaluated using historical, consolidated disclosures only.\n\nWhy a Hypothesis-Driven Approach\nRather than presenting metrics in isolation, this analysis is structured around explicit, testable hypotheses.\nThis approach forces clarity on what the data can support, helps distinguish observation from interpretation, and makes analytical limits visible rather than implicit."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-03.html#dashboard-walkthrough",
    "href": "projects/standalone_visualizations/sa_2026-01-03.html#dashboard-walkthrough",
    "title": "Building a Hypothesis-Driven Financial Analysis Dashboard",
    "section": "Dashboard Walkthrough",
    "text": "Dashboard Walkthrough\nExecutive Brief\n\nThe Executive Brief provides a consolidated view of revenue, margins, cash generation, and capital efficiency.\nEach hypothesis is explicitly labeled according to evidentiary strength to avoid binary conclusions.\nGrowth & Mix\n\nThis section evaluates whether observed revenue growth reflects acceleration or scale effects, alongside changes in reported segment composition.\nProfitability Drivers\n\nMargin trends are presented alongside R&D intensity to contextualize profitability without implying cost compression.\nCash Engine\n\nThis section examines operating cash flow and free cash flow (proxy) trends to assess cash generation resilience during sustained investment periods.\nBalance Sheet & Capital\n\nBalance sheet metrics are used to describe financial flexibility without inferring future capital allocation decisions.\nData Explorer\n\nThe Data Explorer provides full transparency, allowing users to inspect, filter, and export the underlying dataset."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-03.html#what-this-analysis-does-not-conclude",
    "href": "projects/standalone_visualizations/sa_2026-01-03.html#what-this-analysis-does-not-conclude",
    "title": "Building a Hypothesis-Driven Financial Analysis Dashboard",
    "section": "What This Analysis Does Not Conclude",
    "text": "What This Analysis Does Not Conclude\n\nIt does not determine causality behind growth or margin changes\nIt does not forecast future performance\nIt does not assess valuation or shareholder returns\nIt does not infer segment-level profitability\n\nAll results are descriptive and bounded by the limitations of consolidated historical disclosures."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-03.html#closing-note",
    "href": "projects/standalone_visualizations/sa_2026-01-03.html#closing-note",
    "title": "Building a Hypothesis-Driven Financial Analysis Dashboard",
    "section": "Closing Note",
    "text": "Closing Note\nCareful financial analysis often adds the most value not by producing bold conclusions, but by clarifying where confidence is warranted â€” and where restraint is appropriate."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-03.html#appendix-methodology-build-notes",
    "href": "projects/standalone_visualizations/sa_2026-01-03.html#appendix-methodology-build-notes",
    "title": "Building a Hypothesis-Driven Financial Analysis Dashboard",
    "section": "Appendix: Methodology & Build Notes",
    "text": "Appendix: Methodology & Build Notes\nData Sources\n\nSEC EDGAR XBRL Company Facts API\n\nMicrosoft Form 10-K filings (FY2016â€“FY2023)\nKey Methodological Choices\n\nConsolidated revenue concepts were normalized across accounting standard changes.\nFree Cash Flow is presented as a simplified proxy (Operating Cash Flow âˆ’ CapEx).\nSegment data reflects revenue only; segment-level margins are not disclosed.\nApplication Architecture\n\nR Shiny with modular architecture\nggplot2 + ggiraph for interactive charts\nreactable for data exploration"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-03.html#purpose-scope-and-disclaimer",
    "href": "projects/standalone_visualizations/sa_2026-01-03.html#purpose-scope-and-disclaimer",
    "title": "Building a Hypothesis-Driven Financial Analysis Dashboard",
    "section": "Purpose, Scope, and Disclaimer",
    "text": "Purpose, Scope, and Disclaimer\nThis dashboard is an independent analytical exercise created for portfolio and educational purposes only.\nIt is not affiliated with, endorsed by, or produced by Microsoft Corporation.\nAll data are derived from publicly available SEC filings.\nNo representation is made regarding accuracy beyond the source disclosures.\nThis work does not constitute investment advice, valuation guidance, or financial recommendations."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-03.html#what-the-analysis-finds",
    "href": "projects/standalone_visualizations/sa_2026-01-03.html#what-the-analysis-finds",
    "title": "Building a Hypothesis-Driven Financial Analysis Dashboard",
    "section": "What the Analysis Finds",
    "text": "What the Analysis Finds\nBased on consolidated historical disclosures from FY2016â€“FY2023, the analysis supports the following directional conclusions:\n\n\nRevenue growth has increased over time, but the evidence suggests a combination of scale effects and changing business mix rather than a discrete acceleration inflection.\n\nMargin expansion is more consistent with revenue mix effects than broad-based cost compression, as profitability improved alongside sustained R&D intensity.\n\nCash generation remained resilient throughout the period, with free cash flow (proxy) maintaining a stable relationship to revenue despite continued investment.\n\nBalance sheet trends indicate increased financial flexibility, though they do not imply future capital allocation decisions.\n\nThese findings are descriptive and bounded by the limitations of consolidated financial disclosures. They are explored in detail through the dashboard sections that follow."
  },
  {
    "objectID": "data_visualizations/SWD Challenge/2026/swd_2026_01.html",
    "href": "data_visualizations/SWD Challenge/2026/swd_2026_01.html",
    "title": "60% started Geraltâ€™s journey. Only 22% finished it.",
    "section": "",
    "text": "Challenge\nThis monthâ€™s challenge invites you to thoughtfully present partial data to ensure the information is interpreted correctly.\nAdditional information can be found HERE\nVisualization\n\n\n\n\n\nFigureÂ 1: Stacked bar chart showing Steam achievement unlock rates for The Witcher 3â€™s eight story milestones. Each bar represents 100% of players. Purple segments show players who reached each milestone; gray segments show those who didnâ€™t. The first milestone (Tutorial Complete) shows 60.7% reached, while the final milestone (Game Complete) shows only 22.2% reachedâ€”a 38.5 percentage point drop. The purple segments visibly shrink from left to right, demonstrating that most player journeys are partial: many started but didnâ€™t finish.\n\n\nSteps to Create this Graphic \n1. Load Packages & Setup\n\nShow code```{r}\n#| label: load\n\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  dplyr,\n  readr,\n  tidyr,\n  stringr,\n  ggplot2,\n  ggtext,\n  showtext,\n  janitor,\n  scales,\n  glue\n)\n\n### |- figure size ---- \ncamcorder::gg_record(\n  dir    = here::here(\"temp_plots\"),\n  device = \"png\",\n  width  = 12,\n  height = 8,\n  units  = \"in\",\n  dpi    = 320\n)\n\n# Source utility functions\nsuppressMessages(source(here::here(\"R/utils/fonts.R\")))\nsource(here::here(\"R/utils/social_icons.R\"))\nsource(here::here(\"R/utils/image_utils.R\"))\nsource(here::here(\"R/themes/base_theme.R\"))\n```\n\n\n2. Read in the Data\n\nShow code```{r}\n#| label: read\n\ndf &lt;- read_csv(\n  here::here(\"data/SWDchallenge/2026/witcher_story_progression.csv\"),\n  show_col_types = FALSE\n)\n\n### |- Data Source ----\n# Primary Source: Steam Community - The Witcher 3: Wild Hunt Global Achievement Statistics\n# URL: https://steamcommunity.com/stats/292030/achievements\n# Date Accessed: January 1, 2026\n# Game: The Witcher 3: Wild Hunt (CD Projekt Red, 2015)\n# Steam App ID: 292030\n```\n\n\n3. Examine the Data\n\nShow code```{r}\n#| label: examine\n#| include: true\n#| eval: true\n#| results: 'hide'\n#| warning: false\n\nglimpse(df)\nskimr::skim_without_charts(df) \n```\n\n\n4. Tidy Data\n\nShow code```{r}\n#| label: tidy\n\nwitcher_df &lt;- df |&gt;\n  clean_names() |&gt;\n  mutate(\n    milestone = row_number(),\n    milestone_label = case_when(\n      milestone == 1 ~ \"Tutorial\\nComplete\",\n      milestone == 2 ~ \"First Major\\nQuest\",\n      milestone == 3 ~ \"Mid-Game\\nQuest #1\",\n      milestone == 4 ~ \"Mid-Game\\nQuest #2\",\n      milestone == 5 ~ \"Mid-Game\\nQuest #3\",\n      milestone == 6 ~ \"Late-Game\\nQuest\",\n      milestone == 7 ~ \"Near\\nEnd\",\n      milestone == 8 ~ \"Game\\nComplete\",\n      TRUE ~ achievement_name\n    ),\n    reached = pct_unlocked / 100,\n    not_yet = 1 - reached\n  )\n\nplot_df &lt;- witcher_df |&gt;\n  select(milestone, milestone_label, achievement_name, reached, not_yet) |&gt;\n  pivot_longer(\n    cols = c(reached, not_yet),\n    names_to = \"status\",\n    values_to = \"share\"\n  ) |&gt;\n  mutate(\n    status = factor(\n      status,\n      levels = c(\"reached\", \"not_yet\"),\n      labels = c(\"Reached this milestone\", \"Did not reach (partial journey)\")\n    )\n  )\n\nstart_pct &lt;- witcher_df |&gt; slice(1) |&gt; pull(reached)\nfinish_pct &lt;- witcher_df |&gt; slice(8) |&gt; pull(reached)\ndrop_pp &lt;- (start_pct - finish_pct) * 100\n```\n\n\n5. Visualization Parameters\n\nShow code```{r}\n#| label: params\n\n### |-  plot aesthetics ----\ncolors &lt;- get_theme_colors(\n  palette = list(\n    col_reached = \"#473472\",   \n    col_partial = \"#D3D3D3\",   \n    col_white   = \"white\"\n  )\n)\n\n### |-  titles and caption ----\ntitle_text &lt;- \"60% started Geralt's journey. Only 22% finished it.\"\n\nsubtitle_text &lt;- glue(\n  \"Steam achievement unlock rates for &lt;i&gt;The Witcher 3: Wild Hunt&lt;/i&gt; story milestones (snapshot). \",\n  \"Each bar represents &lt;b&gt;100% of players&lt;/b&gt;.&lt;br&gt;\",\n  \"&lt;span style='color:#473472'&gt;&lt;b&gt;Purple = reached this milestone&lt;/b&gt;&lt;/span&gt; | \",\n  \"&lt;span style='color:#999999'&gt;&lt;b&gt;Gray = partial journey&lt;/b&gt;&lt;/span&gt;. \",\n  \"Later bars look 'incomplete' because many players haven't reached them yetâ€”\",\n  \"not because data is missing.\"\n)\n\ncaption_text &lt;- create_swd_caption(\n  year = 2026,\n  month = \"Jan\",\n  source_text = \"Steam Community achievement statistics (The Witcher 3: Wild Hunt, appID 292030)\"\n)\n\n### |-  fonts ----\nsetup_fonts()\nfonts &lt;- get_font_families()\n\n### |-  plot theme ----\n# Start with base theme\nbase_theme &lt;- create_base_theme(colors)\n\n# Add weekly-specific theme elements\nweekly_theme &lt;- extend_weekly_theme(\n  base_theme,\n  theme(\n    # Text styling\n    plot.title = element_text(\n      face = \"bold\", family = fonts$title, size = rel(1.4),\n      color = colors$palette$title, margin = margin(b = 10), hjust = 0\n    ),\n    plot.subtitle = element_text(\n      family = fonts$subtitle, lineheight = 1.2,\n      color = colors$palette$subtitle, size = rel(0.9), margin = margin(b = 20), hjust = 0\n    ),\n    \n    ## Grid\n    panel.grid = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank(),\n    \n    # Axes\n    axis.title.x =  element_text(size = rel(0.9), color = \"gray30\", margin = margin(t = 20)),\n    axis.title.y = element_text(size = rel(0.9), color = \"gray30\",  margin = margin(r = 20)),\n    axis.text = element_text(color = \"gray30\"),\n    # axis.text.y = element_text(size = rel(0.95)),\n    axis.ticks = element_blank(),\n    \n    # Facets\n    strip.background = element_rect(fill = \"gray95\", color = NA),\n    strip.text = element_text(\n      face = \"bold\",\n      color = \"gray20\",\n      size = rel(1),\n      margin = margin(t = 8, b = 8)\n    ),\n    panel.spacing = unit(2, \"lines\"),\n    \n    # Legend elements\n    legend.position = \"right\",\n    legend.title = element_text(\n      family = fonts$subtitle,\n      color = colors$palette$text, size = rel(0.8), face = \"bold\"\n    ),\n    legend.text = element_text(\n      family = fonts$tsubtitle,\n      color = colors$palette$text, size = rel(0.7)\n    ),\n    legend.margin = margin(t = 0, r = 0, b = 0, l = 10),\n    \n    # Plot margin\n    plot.margin = margin(10, 20, 10, 20)\n  )\n)\n\n# Set theme\ntheme_set(weekly_theme)\n```\n\n\n6. Plot\n\nShow code```{r}\n#| label: plot\n\np &lt;- ggplot(plot_df, aes(x = milestone, y = share, fill = status)) +\n\n  # Geoms\n  geom_col(width = 0.78, color = \"grey55\", linewidth = 0.4) +\n  geom_label(\n    data = witcher_df |&gt; filter(milestone == 1),\n    aes(x = milestone, y = 0.42, label = percent(reached, accuracy = 0.1)),\n    inherit.aes = FALSE,\n    fill = colors$palette$col_reached,\n    color = \"white\",\n    label.size = 0,\n    size = 4,\n    fontface = \"bold\",\n    label.padding = unit(0.25, \"lines\")\n  ) +\n  geom_label(\n    data = witcher_df |&gt; filter(milestone == 8),\n    aes(x = milestone, y = 0.82, label = percent(reached, accuracy = 0.1)),\n    inherit.aes = FALSE,\n    fill = colors$palette$col_reached,\n    color = \"white\",\n    label.size = 0,\n    size = 4,\n    fontface = \"bold\",\n    label.padding = unit(0.65, \"lines\")\n  ) +\n\n  # Annotate\n  annotate(\n    \"text\",\n    x = 1, y = 1.045, label = \"Started\",\n    color = colors$palette$col_reached, fontface = \"bold\", size = 3.9, hjust = 0.5\n  ) +\n  annotate(\n    \"text\",\n    x = 8, y = 1.045, label = \"Finished\",\n    color = colors$palette$col_reached, fontface = \"bold\", size = 3.9, hjust = 0.5\n  ) +\n  annotate(\n    \"segment\",\n    x = 1.25, xend = 7.75, y = 1.02, yend = 1.02,\n    linewidth = 0.35, color = \"grey55\",\n    arrow = arrow(ends = \"both\", type = \"closed\", length = unit(0.12, \"inches\"))\n  ) +\n  annotate(\n    \"text\",\n    x = 4.5, y = 1.055,\n    label = glue(\"{round(drop_pp, 1)} percentage point drop\"),\n    size = 3.6, color = \"grey45\", fontface = \"italic\", hjust = 0.5\n  ) +\n  annotate(\n    \"label\",\n    x = 8.6, y = 0.63,\n    label = \"Partial journeys (not missing data)\\nMost players stopped before finishing.\",\n    hjust = 0, vjust = 1,\n    size = 3.4, color = \"grey20\",\n    fill = \"white\", label.size = 0.25, label.r = unit(0.18, \"lines\"),\n    label.padding = unit(0.35, \"lines\")\n  ) +\n\n  # Scales\n  scale_x_continuous(\n    breaks = 1:8,\n    labels = witcher_df$milestone_label,\n    expand = expansion(mult = c(0.04, 0.08))\n  ) +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    limits = c(0, 1.08),\n    expand = expansion(mult = c(0, 0))\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"Reached this milestone\" = colors$palette$col_reached,\n      \"Did not reach (partial journey)\" = colors$palette$col_partial\n    ),\n    breaks = c(\"Reached this milestone\", \"Did not reach (partial journey)\")\n  ) +\n  coord_cartesian(clip = \"off\") +\n\n  # Labs\n  labs(\n    title = title_text,\n    subtitle = subtitle_text,\n    x = \"Story progression milestones\",\n    y = \"Share of players\",\n    fill = NULL,\n    caption = caption_text\n  ) +\n\n  # Theme\n  theme(\n    plot.title = element_markdown(\n      size = rel(2),\n      family = fonts$title,\n      face = \"bold\",\n      color = colors$title,\n      lineheight = 1.15,\n      margin = margin(t = 5, b = 5)\n    ),\n    plot.subtitle = element_markdown(\n      size = rel(0.8),\n      family = fonts$subtitle,\n      color = alpha(colors$subtitle, 0.88),\n      lineheight = 1.3,\n      margin = margin(t = 5, b = 20)\n    ),\n    plot.caption = element_markdown(\n      size = rel(0.65),\n      family = fonts$subtitle,\n      color = colors$caption,\n      hjust = 0,\n      lineheight = 1.4,\n      margin = margin(t = 20, b = 5)\n    ),\n    legend.position.inside = c(0.12, 0.92),\n    legend.justification = c(0, 1),\n    legend.key.spacing.y = unit(0.3, \"cm\"),\n    legend.key.height = unit(0.8, \"lines\"),\n    legend.key.width = unit(1.2, \"lines\"),\n    legend.text = element_text(size = rel(0.7)),\n    legend.margin = margin(r = 10),\n  )\n```\n\n\n7. Save\n\nShow code```{r}\n#| label: save\n\n### |-  plot image ----  \nsave_plot(\n  p, \n  type = 'swd', \n  year = 2026, \n  month = 01, \n  width  = 12,\n  height = 8,\n  )\n```\n\n\n8. Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/La_Paz\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] here_1.0.1     glue_1.8.0     scales_1.3.0   janitor_2.2.0  showtext_0.9-7\n [6] showtextdb_3.0 sysfonts_0.8.9 ggtext_0.1.2   ggplot2_3.5.1  stringr_1.5.1 \n[11] tidyr_1.3.1    readr_2.1.5    dplyr_1.1.4    pacman_0.5.1  \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 tzdb_0.5.0       \n [5] vctrs_0.6.5       tools_4.4.0       generics_0.1.3    curl_6.0.0       \n [9] parallel_4.4.0    gifski_1.32.0-1   tibble_3.2.1      fansi_1.0.6      \n[13] pkgconfig_2.0.3   skimr_2.1.5       lifecycle_1.0.4   farver_2.1.2     \n[17] compiler_4.4.0    textshaping_0.4.0 munsell_0.5.1     repr_1.1.7       \n[21] codetools_0.2-20  snakecase_0.11.1  htmltools_0.5.8.1 yaml_2.3.10      \n[25] pillar_1.9.0      crayon_1.5.3      camcorder_0.1.0   magick_2.8.5     \n[29] commonmark_1.9.2  tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n[33] purrr_1.0.2       labeling_0.4.3    rsvg_2.6.1        rprojroot_2.0.4  \n[37] fastmap_1.2.0     grid_4.4.0        colorspace_2.1-1  cli_3.6.4        \n[41] magrittr_2.0.3    base64enc_0.1-3   utf8_1.2.4        withr_3.0.2      \n[45] bit64_4.5.2       lubridate_1.9.3   timechange_0.3.0  rmarkdown_2.29   \n[49] bit_4.5.0         ragg_1.3.3        hms_1.1.3         evaluate_1.0.1   \n[53] knitr_1.49        markdown_1.13     rlang_1.1.6       gridtext_0.1.5   \n[57] Rcpp_1.0.13-1     xml2_1.3.6        renv_1.0.3        svglite_2.1.3    \n[61] rstudioapi_0.17.1 vroom_1.6.5       jsonlite_1.8.9    R6_2.5.1         \n[65] systemfonts_1.1.0\n\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in swd_2026_01.qmd. For the full repository, click here.\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\nSWD Challenge:\n\nStorytelling with Data: January 2026 - Plot Partial Information\n\n\nData Source:\n\nSteam Community. (2026). The Witcher 3: Wild Hunt - Global Achievement Statistics. Retrieved January 1, 2026, from https://steamcommunity.com/stats/292030/achievements\n\n\nGame Information:\n\nCD Projekt Red. (2015). The Witcher 3: Wild Hunt [Video game]. Steam. https://store.steampowered.com/app/292030/\n\nWitcher Wiki: The Witcher 3 Achievements\n\n\nSupporting References:\n\nSteam Community Guide: The Witcher 3 - 100% Achievement Guide (for understanding achievement progression and validation)\nTrueAchievements.com: The Witcher 3 Achievement Data (cross-reference)\n\nData Details:\n\nSteam App ID: 292030\nDate Accessed: January 1, 2026\nData represents cumulative achievement unlock percentages from game launch (May 2015) through January 2026\nSample size: Millions of Steam players (exact number not publicly disclosed)\n\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\n\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\n\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\n\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-07.html",
    "href": "projects/standalone_visualizations/sa_2026-01-07.html",
    "title": "Designing an Executive-Grade R&D Portfolio Simulator",
    "section": "",
    "text": "ðŸš€ Live app:Pharma R&D Portfolio Simulator\nðŸ’» Source code:GitHub repository"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-07.html#executive-overview",
    "href": "projects/standalone_visualizations/sa_2026-01-07.html#executive-overview",
    "title": "Designing an Executive-Grade R&D Portfolio Simulator",
    "section": "Executive Overview",
    "text": "Executive Overview\nPharmaceutical R&D portfolio decisions are rarely about optimizing a single metric.\nThey require balancing near-term output, execution risk, capital efficiency, speed, and long-term learningâ€”often under conditions of uncertainty and incomplete information.\nThis project presents an interactive R Shiny simulator designed to support structured strategic reasoning about R&D portfolio allocation. Rather than predicting outcomes or recommending specific investments, the simulator provides a transparent framework for exploring how portfolio strategies perform under different strategic priorities.\nThe emphasis is on decision support, not prescription.\nFor organizations navigating pipeline trade-offs, this distinction matters: the goal is clarity about how choices behave, not claims about what to choose."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-07.html#strategic-questions-this-simulator-examines",
    "href": "projects/standalone_visualizations/sa_2026-01-07.html#strategic-questions-this-simulator-examines",
    "title": "Designing an Executive-Grade R&D Portfolio Simulator",
    "section": "Strategic Questions This Simulator Examines",
    "text": "Strategic Questions This Simulator Examines\nThe simulator is designed to help explore questions commonly faced by R&D leadership and portfolio governance teams:\n\nHow do different portfolio configurations perform across competing strategic objectives?\nWhen do objectives align, and when do they meaningfully diverge?\nWhat trade-offs emerge between maximizing near-term approvals and building long-term optionality?\nHow sensitive are portfolio outcomes to therapeutic area risk profiles?\nUnder what conditions does specialization outperform diversification?\n\nThese questions are addressed through probability-weighted simulation, not forecasting."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-07.html#analytical-design-a-multi-objective-framework",
    "href": "projects/standalone_visualizations/sa_2026-01-07.html#analytical-design-a-multi-objective-framework",
    "title": "Designing an Executive-Grade R&D Portfolio Simulator",
    "section": "Analytical Design: A Multi-Objective Framework",
    "text": "Analytical Design: A Multi-Objective Framework\nRather than optimizing for a single outcome, portfolios are evaluated across five strategic objectives, each representing a different organizational priority:\n\n\nMaximize Expected Approvals â€“ total approvals over the portfolio lifecycle\n\n\nPredictability â€“ approvals per asset (execution reliability)\n\n\nLearning Optionality â€“ early-stage asset exposure as a proxy for discovery\n\n\nSpeed to Market â€“ approvals per year\n\n\nCapital Efficiency â€“ approvals per $100M invested\n\nNo objective is treated as universally â€œcorrect.â€ Trade-offs are expected and explicitly surfaced."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-07.html#data-foundations-and-modeling-discipline",
    "href": "projects/standalone_visualizations/sa_2026-01-07.html#data-foundations-and-modeling-discipline",
    "title": "Designing an Executive-Grade R&D Portfolio Simulator",
    "section": "Data Foundations and Modeling Discipline",
    "text": "Data Foundations and Modeling Discipline\nLiterature-Based Inputs\nBaseline parameters are drawn from peer-reviewed and industry sources, including:\n\nPhase transition success rates (Norstella / Citeline)\nTrial duration estimates (Wong et al., Biostatistics)\nR&D cost estimates (JAMA Network Open)\nTherapeutic-area-specific success profiles (ACSH)\n\nEmpirical therapeutic areas include:\n\nOverall (industry average)\nOncology\nVaccines\nAnti-Infectives\nModeled Strategic Scenarios\nWhere direct literature estimates do not exist, explicit modeling assumptions are applied to explore strategic postures (e.g., fast-track timelines, cost-efficient rare disease focus). These assumptions are documented, adjustable, and intentionally simplified.\nThe simulator distinguishes clearly between empirical inputs and modeled scenarios."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-07.html#simulation-approach",
    "href": "projects/standalone_visualizations/sa_2026-01-07.html#simulation-approach",
    "title": "Designing an Executive-Grade R&D Portfolio Simulator",
    "section": "Simulation Approach",
    "text": "Simulation Approach\nPortfolio outcomes are calculated using probability-weighted attrition modeling.\nRather than assuming all assets progress through all phases, costs and timelines are weighted by historical phase-transition probabilities. This reflects real-world portfolio economics, where early failures reduce downstream costs and timelines.\nKey outputs include:\n\nExpected approvals\n\nProbability-weighted total cost\n\nAverage development timeline\n\nNormalized efficiency metrics\n\nThis approach emphasizes structural realism over predictive precision."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-07.html#dashboard-structure",
    "href": "projects/standalone_visualizations/sa_2026-01-07.html#dashboard-structure",
    "title": "Designing an Executive-Grade R&D Portfolio Simulator",
    "section": "Dashboard Structure",
    "text": "Dashboard Structure\nThe simulator is organized into four complementary views:\nExecutive Brief\n\nAn executive-facing entry point that allows users to select a strategic priority and view:\n\nSuggested portfolio configurations aligned with selected priority\n\nKey performance metrics\n\nExplicit trade-offs (â€œwhat improvesâ€ vs.Â â€œwhat is sacrificedâ€)\nPortfolio Builder\n An interactive workspace for configuring:\n\nPhase allocation (early vs.Â late)\nTherapeutic area focus\nCost assumptions\n\nwith real-time feedback against strategic KPIs and preset scenarios.\nTrade-off Explorer\n\nA comparative analysis view that enables:\n\nMulti-scenario selection\n\nNormalized radar-chart comparison across objectives\n\nSide-by-side metrics with dynamic interpretation\nMethods & Data\n\nA transparency-focused section documenting:\n\nData sources and citations\n\nModeling assumptions\n\nNormalization logic\n\nKnown limitations"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-07.html#what-the-simulator-reveals",
    "href": "projects/standalone_visualizations/sa_2026-01-07.html#what-the-simulator-reveals",
    "title": "Designing an Executive-Grade R&D Portfolio Simulator",
    "section": "What the Simulator Reveals",
    "text": "What the Simulator Reveals\nAcross scenarios and assumptions, several consistent patterns emerge:\n\nOutput-maximizing strategies tend to cluster, particularly when late-stage assets dominate the portfolio.\nLearning-focused portfolios often diverge from output-focused ones, highlighting a fundamental trade-off between near-term results and long-term optionality.\nTherapeutic area risk profiles materially affect outcome magnitude, even when strategy rankings remain stable.\nUnder certain conditions, objectives alignâ€”simplifying decisions. Under others, trade-offs become unavoidable and must be made explicit.\n\nThese findings are descriptive, not prescriptive."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-07.html#scope-and-limitations",
    "href": "projects/standalone_visualizations/sa_2026-01-07.html#scope-and-limitations",
    "title": "Designing an Executive-Grade R&D Portfolio Simulator",
    "section": "Scope and Limitations",
    "text": "Scope and Limitations\nThis simulator intentionally does not:\n\nPredict individual asset outcomes\n\nModel company-specific pipelines or proprietary data\n\nEstimate valuation, NPV, or financial return\n\nAccount for competitive dynamics or regulatory acceleration pathways\n\nLearning optionality is proxied by early-stage asset exposure, not measured scientific output.\nAll simulations assume independent trial outcomes and industry-average parameters.\nThese constraints are deliberate to preserve interpretability and avoid overreach."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-07.html#why-this-framework-is-useful",
    "href": "projects/standalone_visualizations/sa_2026-01-07.html#why-this-framework-is-useful",
    "title": "Designing an Executive-Grade R&D Portfolio Simulator",
    "section": "Why This Framework Is Useful",
    "text": "Why This Framework Is Useful\nStrategic portfolio discussions often fail not due to lack of data, but due to implicit priorities and unexamined trade-offs.\nThis simulator provides a structured way to:\n\nMake priorities explicit\n\nCompare strategies on common footing\n\nExplore sensitivity to assumptions\n\nSupport disciplined executive discussion\n\nIt is designed as a thinking tool, not a decision engine."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-07.html#appendix-methodology-build-notes",
    "href": "projects/standalone_visualizations/sa_2026-01-07.html#appendix-methodology-build-notes",
    "title": "Designing an Executive-Grade R&D Portfolio Simulator",
    "section": "Appendix: Methodology & Build Notes",
    "text": "Appendix: Methodology & Build Notes\nData Sources\n\nNorstella/Citeline (2024) â€“ Phase transition probabilities\nWong et al., Biostatistics (2019) â€“ Trial duration estimates\nJAMA Network Open (2024) â€“ R&D cost benchmarks\nACSH (2020) â€“ Therapeutic area success profiles\nApplication Architecture\n\nR Shiny with shiny.semantic (Appsilon framework)\nModular architecture (4 independent tabs)\nggiraph + fmsb for interactive visualizations\nreactable for data tables"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-07.html#purpose-scope-and-disclaimer",
    "href": "projects/standalone_visualizations/sa_2026-01-07.html#purpose-scope-and-disclaimer",
    "title": "Designing an Executive-Grade R&D Portfolio Simulator",
    "section": "Purpose, Scope, and Disclaimer",
    "text": "Purpose, Scope, and Disclaimer\nThis simulator is an independent analytical exercise created for portfolio and educational purposes only.\nIt is not affiliated with, endorsed by, or produced by any pharmaceutical company.\nAll parameters are derived from publicly available peer-reviewed literature. No representation is made regarding applicability to specific company contexts.\nThis work does not constitute investment advice, clinical guidance, or strategic recommendations."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-07.html#closing",
    "href": "projects/standalone_visualizations/sa_2026-01-07.html#closing",
    "title": "Designing an Executive-Grade R&D Portfolio Simulator",
    "section": "Closing",
    "text": "Closing\nThis project demonstrates how analytical restraint, transparency, and multi-objective framing can be combined into an executive-grade decision-support application.\nBy focusing on structure rather than prediction, the simulator helps clarify how strategic choices behaveâ€”without claiming to know what should be chosen."
  },
  {
    "objectID": "data_visualizations/TidyTuesday/2026/tt_2026_01.html",
    "href": "data_visualizations/TidyTuesday/2026/tt_2026_01.html",
    "title": "The Prescription Takeover",
    "section": "",
    "text": "FigureÂ 1: Line chart showing U.S. Google search trends from 2016 to 2025 for diet-related terms. Combined searches for GLP-1 drugs (Ozempic, Wegovy, Mounjaro) rose from near zero in 2020 to surpass fad diets (keto, Paleo) in late 2023. Fad diets peaked around 2019 at 120 combined search interest and declined to about 25 by 2025. The generic term â€˜dietâ€™ remained relatively stable around 50-75 throughout. A shaded â€˜Prescription Eraâ€™ highlights the post-2023 period where pharmaceutical solutions dominate over behavioral diets.\n\n\nSteps to Create this Graphic \n1. Load Packages & Setup\n\nShow code```{r}\n#| label: load\n#| warning: false\n#| message: false\n#| results: \"hide\"\n\n## 1. LOAD PACKAGES & SETUP ----\nsuppressPackageStartupMessages({\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n    tidyverse,     # Easily Install and Load the 'Tidyverse'\n    ggtext,        # Improved Text Rendering Support for 'ggplot2'\n    showtext,      # Using Fonts More Easily in R Graphs\n    ggrepel,       # Non-overlapping Text Labels\n    janitor,       # Simple Tools for Examining and Cleaning Dirty Data\n    scales,        # Scale Functions for Visualization\n    glue           # Interpreted String Literals\n)\n})\n\n### |- figure size ----\ncamcorder::gg_record(\n  dir    = here::here(\"temp_plots\"),\n  device = \"png\",\n  width  = 8,\n  height = 6,\n  units  = \"in\",\n  dpi    = 320\n)\n\n# Source utility functions\nsuppressMessages(source(here::here(\"R/utils/fonts.R\")))\nsource(here::here(\"R/utils/social_icons.R\"))\nsource(here::here(\"R/utils/image_utils.R\"))\nsource(here::here(\"R/themes/base_theme.R\"))\n```\n\n\n2. Read in the Data\n\nShow code```{r}\n#| label: read\n#| include: true\n#| eval: true\n#| warning: false\n\n# pak::pkg_install('gtrendsR')\n# library(gtrendsR)\n# library(tidyverse)\n\n# Pull first batch\n# terms_diet &lt;- c(\"diet\", \"keto\", \"intermittent fasting\", \"calorie counting\", \"Ozempic\")\n# trends_diet &lt;- gtrends(\n#     keyword = terms_diet,\n#     geo = \"US\",\n#     time = \"2016-01-01 2025-01-07\"\n# )\n\n# Pull second batch\n# terms_expanded &lt;- c(\"Wegovy\", \"Mounjaro\", \"Paleo\")\n# trends_expanded &lt;- gtrends(\n#     keyword = terms_expanded,\n#     geo = \"US\",\n#     time = \"2016-01-01 2025-01-07\"\n# )\n\n# Combine and clean\n# diet_combined &lt;- bind_rows(\n#     trends_diet$interest_over_time,\n#     trends_expanded$interest_over_time\n# ) |&gt;\n#     mutate(\n#         hits = case_when(\n#             hits == \"&lt;1\" ~ \"0.5\",\n#             TRUE ~ hits\n#         ),\n#         hits = as.numeric(hits)\n#     )\n\n# Save combined data\n# write_csv(diet_combined, \"2026/Week_01/diet_trends_combined.csv\")\n\nraw_data &lt;- read_csv(\n  here::here(\"data/TidyTuesday/2026/diet_trends_combined.csv\")) |&gt; \n    clean_names()\n```\n\n\n3. Examine the Data\n\nShow code```{r}\n#| label: examine\n#| include: true\n#| eval: true\n#| results: 'hide'\n#| warning: false\n\nglimpse(raw_data)\n```\n\n\n4. Tidy Data\n\nShow code```{r}\n#| label: tidy-fixed\n#| warning: false\n\n### |-  clean individual terms ----\ndiet_clean &lt;- raw_data |&gt;\n    mutate(\n        hits = case_when(\n            hits == \"&lt;1\" ~ 0.5,\n            TRUE ~ as.numeric(hits)\n        ),\n        date = as.Date(date),\n        year = year(date),\n        month = month(date)\n    ) |&gt;\n    select(date, year, month, keyword, hits)\n\n### |-  create grouped categories ----\ndiet_grouped &lt;- diet_clean |&gt;\n    mutate(\n        category = case_when(\n            keyword %in% c(\"keto\", \"Paleo\") ~ \"Fad Diets\",\n            keyword %in% c(\"Ozempic\", \"Wegovy\", \"Mounjaro\") ~ \"GLP-1 Drugs\",\n            keyword == \"diet\" ~ \"diet\",\n            TRUE ~ \"Other\"\n        )\n    ) |&gt;\n    # Exclude minor terms\n    filter(category != \"Other\") |&gt;\n    group_by(date, year, month, category) |&gt;\n    summarise(\n        hits = sum(hits, na.rm = TRUE),\n        .groups = \"drop\"\n    )\n\n### |-  find the crossover point ----\ncrossover_data &lt;- diet_grouped |&gt;\n    filter(category %in% c(\"Fad Diets\", \"GLP-1 Drugs\")) |&gt;\n    pivot_wider(names_from = category, values_from = hits) |&gt;\n    filter(`GLP-1 Drugs` &gt; `Fad Diets`) |&gt;\n    slice_min(date, n = 1)\n\ncrossover_date &lt;- crossover_data$date\ncrossover_date\n\n# Get the intersection y-value for annotation\ncrossover_y &lt;- crossover_data$`GLP-1 Drugs`\n\n# Create label data for end of lines \nlabel_data &lt;- diet_grouped |&gt;\n    filter(date == max(date)) |&gt;\n    mutate(\n        label = case_when(\n            category == \"GLP-1 Drugs\" ~ \"GLP-1 Drugs\\n(Ozempic, Wegovy, Mounjaro)\",\n            category == \"Fad Diets\" ~ \"Fad Diets\\n(keto, Paleo)\",\n            TRUE ~ category\n        )\n    )\n\n# Define prescription era start\nprescription_era_start &lt;- as.Date(\"2023-10-01\")\n```\n\n[1] \"2022-10-01\"\n\n\n5. Visualization Parameters\n\nShow code```{r}\n#| label: params\n#| include: true\n#| warning: false\n\n### |-  plot aesthetics ----\ncolors &lt;- get_theme_colors(\n  palette = list(\n      \"diet\" = \"gray50\",\n      \"Fad Diets\" = \"#3498db\",\n      \"GLP-1 Drugs\" = \"#e74c3c\"\n  )\n)\n\n### |- titles and caption ----\ntitle_text &lt;- str_glue(\"The Prescription Takeover\")\n\nsubtitle_text &lt;- str_glue(\n    \"U.S. Google searches show a dramatic shift: combined interest in &lt;span style='color:#e74c3c;'&gt;**GLP-1 drugs**&lt;/span&gt;&lt;br&gt;\",\n    \"(Ozempic, Wegovy, Mounjaro) has overtaken &lt;span style='color:#3498db;'&gt;**fad diets**&lt;/span&gt; (keto, Paleo) since late 2023.\"\n)\n\ncaption_text &lt;- create_social_caption(\n    tt_year = 2026,\n    tt_week = 01,\n    source_text = \"Google Trends (US), 2016-2025 via { gtrendsR }\"\n)\n\n### |-  fonts ----\nsetup_fonts()\nfonts &lt;- get_font_families()\n\n### |-  plot theme ----\n# Start with base theme\nbase_theme &lt;- create_base_theme(colors)\n\n# Add weekly-specific theme elements\nweekly_theme &lt;- extend_weekly_theme(\n  base_theme,\n  theme(\n    # Text styling\n    plot.title = element_text(\n      face = \"bold\", family = fonts$title, size = rel(1.4),\n      color = colors$title, margin = margin(b = 10), hjust = 0\n    ),\n    plot.subtitle = element_markdown(\n      face = \"italic\", family = fonts$subtitle, lineheight = 1.2,\n      color = colors$subtitle, size = rel(0.9), margin = margin(b = 20), hjust = 0\n    ),\n\n    # Grid\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major = element_line(color = \"gray90\", linewidth = 0.25),\n\n    # Axes\n    axis.title = element_text(size = rel(0.8), color = \"gray30\"),\n    axis.text = element_text(color = \"gray30\"),\n    axis.text.y = element_text(size = rel(0.85)),\n    axis.ticks = element_blank(),\n\n    # Facets\n    strip.background = element_rect(fill = \"gray95\", color = NA),\n    strip.text = element_text(\n      face = \"bold\",\n      color = \"gray20\",\n      size = rel(0.9),\n      margin = margin(t = 6, b = 4)\n    ),\n    panel.spacing = unit(1.5, \"lines\"),\n\n    # Legend elements\n    legend.position = \"plot\",\n    legend.title = element_text(\n      family = fonts$subtitle,\n      color = colors$text, size = rel(0.8), face = \"bold\"\n    ),\n    legend.text = element_text(\n      family = fonts$tsubtitle,\n      color = colors$text, size = rel(0.7)\n    ),\n    legend.margin = margin(t = 15),\n\n    # Plot margin\n    plot.margin = margin(20, 20, 20, 20),\n    \n  )\n)\n\n# Set theme\ntheme_set(weekly_theme)\n```\n\n\n6. Plot\n\nShow code```{r}\n#| label: plot\n#| warning: false\n\n### |- Plot ----\np &lt;- diet_grouped |&gt;\n    ggplot(aes(x = date, y = hits, color = category)) +\n    \n    # Geoms\n    geom_line(linewidth = 0.4, alpha = 0.25) +\n    geom_smooth(\n        method = \"loess\",\n        span = 0.2,\n        se = FALSE,\n        linewidth = 1.8\n    ) +\n    geom_text_repel(\n        data = label_data |&gt; \n            filter(category == \"GLP-1 Drugs\"),\n        aes(label = label),\n        hjust = 0,\n        direction = \"y\",\n        nudge_x = 50,\n        nudge_y = 5,\n        segment.color = NA,\n        family = fonts$text,\n        fontface = \"bold\",\n        size = 3,\n        lineheight = 0.85,\n        box.padding = 0.5\n    ) +\n    geom_text_repel(\n        data = label_data |&gt; \n            filter(category != \"GLP-1 Drugs\"),\n        aes(label = label),\n        hjust = 0,\n        direction = \"y\",\n        nudge_x = 50,\n        # nudge_y = 5,\n        segment.color = NA,\n        family = fonts$text,\n        fontface = \"bold\",\n        size = 3,\n        lineheight = 0.85,\n        box.padding = 0.5\n    ) +\n    \n    # Annotate\n    annotate(\n        \"rect\",\n        xmin = prescription_era_start,\n        xmax = max(diet_grouped$date) + 60,\n        ymin = -Inf,\n        ymax = Inf,\n        fill = \"#e74c3c\",\n        alpha = 0.05\n    ) +\n    annotate(\n        \"text\",\n        x = prescription_era_start + 200,\n        y = 130,\n        label = \"Prescription Era\",\n        family = fonts$text,\n        size = 3,\n        color = \"gray30\",\n        fontface = \"bold.italic\"\n    ) +\n    annotate(\n        \"point\",\n        x = crossover_date,\n        y = crossover_y,\n        size = 3,\n        color = \"gray20\"\n    ) +\n    annotate(\n        \"text\",\n        x = crossover_date - 90,\n        y = crossover_y + 15,\n        label = \"GLP-1 surpasses\\nfad diets\",\n        family = fonts$text,\n        size = 2.8,\n        color = \"gray30\",\n        hjust = 1,\n        lineheight = 0.9\n    ) +\n    annotate(\n        \"curve\",\n        x = crossover_date - 80,\n        y = crossover_y + 10,\n        xend = crossover_date - 10,\n        yend = crossover_y + 2,\n        curvature = 0.2,\n        arrow = arrow(length = unit(0.15, \"cm\"), type = \"closed\"),\n        color = \"gray40\",\n        linewidth = 0.4\n    ) +\n    \n    # Scales\n    scale_color_manual(\n        values = c(\n            \"diet\" = \"gray50\",\n            \"Fad Diets\" = \"#3498db\",\n            \"GLP-1 Drugs\" = \"#e74c3c\"\n        )\n    ) +\n    scale_x_date(\n        date_breaks = \"2 years\",\n        date_labels = \"%Y\",\n        expand = expansion(mult = c(0.02, 0.18))\n    ) +\n    scale_y_continuous(\n        breaks = seq(0, 100, 25),\n        limits = c(0, 130),\n        expand = expansion(mult = c(0, 0.02))\n    ) +\n    coord_cartesian(clip = \"off\") +\n    \n    # Labs\n    labs(\n        title = title_text,\n        subtitle = subtitle_text,\n        caption = caption_text,\n        y = \"Combined Search Interest\"\n    ) +\n    \n    # Theme\n    theme(\n    plot.title = element_markdown(\n        size = rel(2.3),\n        family = fonts$title,\n        face = \"bold\",\n        color = colors$title,\n        lineheight = 1.15,\n        margin = margin(t = 8, b = 5)\n    ),\n    plot.subtitle = element_markdown(\n        size = rel(0.9),\n        family = fonts$subtitle,\n        color = alpha(colors$subtitle, 0.88),\n        lineheight = 1.5,\n        margin = margin(t = 5, b = 20)\n    ),\n    plot.caption = element_markdown(\n        size = rel(0.65),\n        family = fonts$subtitle,\n        color = colors$caption,\n        hjust = 0,\n        lineheight = 1.4,\n        margin = margin(t = 20, b = 5)\n    )\n)\n```\n\n\n7. Save\n\nShow code```{r}\n#| label: save\n#| warning: false\n\n### |-  plot image ----  \nsave_plot(\n  plot = p, \n  type = \"tidytuesday\", \n  year = 2026, \n  week = 01, \n  width  = 8,\n  height = 6,\n  )\n```\n\n\n8. Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/La_Paz\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] here_1.0.1      glue_1.8.0      scales_1.3.0    janitor_2.2.0  \n [5] ggrepel_0.9.6   showtext_0.9-7  showtextdb_3.0  sysfonts_0.8.9 \n [9] ggtext_0.1.2    lubridate_1.9.3 forcats_1.0.0   stringr_1.5.1  \n[13] dplyr_1.1.4     purrr_1.0.2     readr_2.1.5     tidyr_1.3.1    \n[17] tibble_3.2.1    ggplot2_3.5.1   tidyverse_2.0.0 pacman_0.5.1   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 lattice_0.22-6   \n [5] tzdb_0.5.0        vctrs_0.6.5       tools_4.4.0       generics_0.1.3   \n [9] curl_6.0.0        parallel_4.4.0    gifski_1.32.0-1   fansi_1.0.6      \n[13] pkgconfig_2.0.3   Matrix_1.7-0      lifecycle_1.0.4   farver_2.1.2     \n[17] compiler_4.4.0    textshaping_0.4.0 munsell_0.5.1     codetools_0.2-20 \n[21] snakecase_0.11.1  htmltools_0.5.8.1 yaml_2.3.10       crayon_1.5.3     \n[25] pillar_1.9.0      camcorder_0.1.0   magick_2.8.5      nlme_3.1-164     \n[29] commonmark_1.9.2  tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n[33] splines_4.4.0     rsvg_2.6.1        rprojroot_2.0.4   fastmap_1.2.0    \n[37] grid_4.4.0        colorspace_2.1-1  cli_3.6.4         magrittr_2.0.3   \n[41] utf8_1.2.4        withr_3.0.2       bit64_4.5.2       timechange_0.3.0 \n[45] rmarkdown_2.29    bit_4.5.0         ragg_1.3.3        hms_1.1.3        \n[49] evaluate_1.0.1    knitr_1.49        markdown_1.13     mgcv_1.9-1       \n[53] rlang_1.1.6       gridtext_0.1.5    Rcpp_1.0.13-1     xml2_1.3.6       \n[57] renv_1.0.3        svglite_2.1.3     rstudioapi_0.17.1 vroom_1.6.5      \n[61] jsonlite_1.8.9    R6_2.5.1          systemfonts_1.1.0\n\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in tt_2026_01.qmd.\nFor the full repository, click here.\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\n\n\nData Source:\n\nTidyTuesday 2026 Week 01: Bring your own data\n\n\nGoogle Trends - Search interest data for U.S., 2016-2025\nSearch terms: â€œdietâ€, â€œketoâ€, â€œPaleoâ€, â€œOzempicâ€, â€œWegovyâ€, â€œMounjaroâ€\n\n\n\nR Package:\n\nMassicotte, P. and Eddelbuettel, D. (2024). gtrendsR: Perform and Display Google Trends Queries. R package. CRAN | GitHub\n\n\n\n\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\n\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\n\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\n\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n Back to topCitationBibTeX citation:@online{ponce2026,\n  author = {Ponce, Steven},\n  title = {The {Prescription} {Takeover}},\n  date = {2026-01-08},\n  url = {https://stevenponce.netlify.app/data_visualizations/TidyTuesday/2026/tt_2026_01.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPonce, Steven. 2026. â€œThe Prescription Takeover.â€ January\n8, 2026. https://stevenponce.netlify.app/data_visualizations/TidyTuesday/2026/tt_2026_01.html."
  },
  {
    "objectID": "data_visualizations/TidyTuesday/2026/tt_2026_02.html",
    "href": "data_visualizations/TidyTuesday/2026/tt_2026_02.html",
    "title": "Africaâ€™s Indigenous Language Families Span the Continentr",
    "section": "",
    "text": "FigureÂ 1: Scatter plot showing African language families by geographic concentration versus number of countries. Indigenous families (Niger-Congo, Afroasiatic, Nilo-Saharan) cluster in the upper-left with low concentration and 20-40 countries. Colonial languages (English, French) appear in the lower-right with high concentration in only 3-4 countries.\n\n\nSteps to Create this Graphic \n1. Load Packages & Setup\n\nShow code```{r}\n#| label: load\n#| warning: false\n#| message: false\n#| results: \"hide\"\n\n## 1. LOAD PACKAGES & SETUP ----\nsuppressPackageStartupMessages({\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n    tidyverse,     # Easily Install and Load the 'Tidyverse'\n    ggtext,        # Improved Text Rendering Support for 'ggplot2'\n    showtext,      # Using Fonts More Easily in R Graphs\n    ggrepel,       # Non-overlapping Text Labels\n    janitor,       # Simple Tools for Examining and Cleaning Dirty Data\n    scales,        # Scale Functions for Visualization\n    glue           # Interpreted String Literals\n)\n})\n\n### |- figure size ----\ncamcorder::gg_record(\n  dir    = here::here(\"temp_plots\"),\n  device = \"png\",\n  width  = 8,\n  height = 6,\n  units  = \"in\",\n  dpi    = 320\n)\n\n# Source utility functions\nsuppressMessages(source(here::here(\"R/utils/fonts.R\")))\nsource(here::here(\"R/utils/social_icons.R\"))\nsource(here::here(\"R/utils/image_utils.R\"))\nsource(here::here(\"R/themes/base_theme.R\"))\n```\n\n\n2. Read in the Data\n\nShow code```{r}\n#| label: read\n#| include: true\n#| eval: true\n#| warning: false\n\ntt &lt;- tidytuesdayR::tt_load(2026, week = 02)\n\nafrica_raw &lt;- tt$africa |&gt; clean_names()\n\ntidytuesdayR::readme(tt)\nrm(tt)\n```\n\n\n3. Examine the Data\n\nShow code```{r}\n#| label: examine\n#| include: true\n#| eval: true\n#| results: 'hide'\n#| warning: false\n\nglimpse(africa_raw)\n```\n\n\n4. Tidy Data\n\nShow code```{r}\n#| label: tidy-fixed\n#| warning: false\n\n#' Note:\n#' HHI (Herfindahl-Hirschman Index) measures market concentration - originally used \n#' in economics to see if one company dominates a market. We're adapting it to see \n#' if one country dominates a language family's speaker base.\n#' \n\n### |-  calculate HHI concentration + country coverage ----\nfamily_summary &lt;- africa_raw |&gt;\n    filter(!is.na(native_speakers), native_speakers &gt; 0) |&gt;\n    group_by(family, country) |&gt;\n    summarise(\n        speakers = sum(native_speakers), \n        .groups = \"drop\"\n        ) |&gt;\n    group_by(family) |&gt;\n    mutate(\n        total = sum(speakers),\n        share = speakers / total\n    ) |&gt;\n    summarise(\n        hhi_concentration = sum(share^2),\n        n_countries = n_distinct(country),\n        .groups = \"drop\"\n    ) |&gt;\n    filter(n_countries &gt; 1) |&gt;\n    group_by(family) |&gt;\n    slice_max(n_countries, n = 1) |&gt;\n    ungroup() |&gt;\n    mutate(\n        family_group = if_else(family %in% c(\"English\", \"French\"),\n                               \"Colonial\",\n                               \"Indigenous\")\n    )\n\n### |-  labels for key points ----\nlabel_df &lt;- family_summary |&gt;\n    filter(\n        str_detect(family, regex(\"^English$|^French$|Niger|Afroasiatic|Nilo\", ignore_case = TRUE))\n    )\n```\n\n\n5. Visualization Parameters\n\nShow code```{r}\n#| label: params\n#| include: true\n#| warning: false\n\n### |-  plot aesthetics ----\ncolors &lt;- get_theme_colors(\n  palette = c(\n      \"Colonial\"   = \"#E76F51\",\n      \"Indigenous\" = \"gray40\"\n  )\n)\n\n### |- titles and caption ----\ntitle_text &lt;- str_glue(\"Africa's Indigenous Language Families Span the Continent\")\n\nsubtitle_text &lt;- str_glue(\n    \"Niger-Congo, Afroasiatic, and Nilo-Saharan are spoken natively across 20â€“40 countries&lt;br&gt;with speakers evenly distributed. \", \n    \"&lt;b style='color:#E76F51'&gt;Colonial languages&lt;/b&gt; cluster in fewer regions.\",\n)\n\ncaption_text &lt;- create_social_caption(\n    tt_year = 2026,\n    tt_week = 02,\n    source_text = \"Wikipedia 'Languages of Africa' | Concentration = Herfindahl-Hirschman Index\"\n)\n\n### |-  fonts ----\nsetup_fonts()\nfonts &lt;- get_font_families()\n\n### |-  plot theme ----\n# Start with base theme\nbase_theme &lt;- create_base_theme(colors)\n\n# Add weekly-specific theme elements\nweekly_theme &lt;- extend_weekly_theme(\n  base_theme,\n  theme(\n    # Text styling\n    plot.title = element_text(\n      face = \"bold\", family = fonts$title, size = rel(1.4),\n      color = colors$title, margin = margin(b = 10), hjust = 0\n    ),\n    plot.subtitle = element_markdown(\n      face = \"italic\", family = fonts$subtitle, lineheight = 1.2,\n      color = colors$subtitle, size = rel(0.9), margin = margin(b = 20), hjust = 0\n    ),\n\n    # Grid\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major = element_line(color = \"gray90\", linewidth = 0.25),\n\n    # Axes\n    axis.title.x = element_text(size = 9.5, color = \"gray30\", margin = margin(t = 8)),\n    axis.title.y = element_text(size = 9.5, color = \"gray30\", margin = margin(r = 8)),\n    # axis.title = element_text(size = rel(0.8), color = \"gray30\"),\n    axis.text = element_text(color = \"gray30\"),\n    axis.text.y = element_text(size = rel(0.85)),\n    axis.ticks = element_blank(),\n\n    # Facets\n    strip.background = element_rect(fill = \"gray95\", color = NA),\n    strip.text = element_text(\n      face = \"bold\",\n      color = \"gray20\",\n      size = rel(0.9),\n      margin = margin(t = 6, b = 4)\n    ),\n    panel.spacing = unit(1.5, \"lines\"),\n\n    # Legend elements\n    legend.position = \"plot\",\n    legend.title = element_text(\n      family = fonts$subtitle,\n      color = colors$text, size = rel(0.8), face = \"bold\"\n    ),\n    legend.text = element_text(\n      family = fonts$tsubtitle,\n      color = colors$text, size = rel(0.7)\n    ),\n    legend.margin = margin(t = 15),\n\n    # Plot margin\n    plot.margin = margin(20, 20, 20, 20),\n    \n  )\n)\n\n# Set theme\ntheme_set(weekly_theme)\n```\n\n\n6. Plot\n\nShow code```{r}\n#| label: plot\n#| warning: false\n\n### |- Plot ----\np &lt;- ggplot(family_summary, aes(x = hhi_concentration, y = n_countries)) +\n    # Geoms\n    geom_point(\n        aes(color = family_group),\n        size = 3,\n        alpha = 0.85\n    ) +\n    geom_text_repel(\n        data = label_df,\n        aes(label = family, color = family_group),\n        size = 3.0,\n        fontface = \"bold\",\n        box.padding = 0.4,\n        point.padding = 0.3,\n        segment.color = \"gray70\",\n        segment.size = 0.3,\n        max.overlaps = Inf,\n        seed = 123\n    ) +\n    # Scales\n    scale_color_manual(\n        values = colors$palette,\n        guide = \"none\"\n    ) +\n    scale_x_continuous(\n        limits = c(0, 1.1),\n        breaks = c(0, 0.25, 0.5, 0.75, 1)\n    ) +\n    scale_y_continuous(\n        breaks = seq(0, 45, by = 10)\n    ) +\n    # Labs\n    labs(\n        title = title_text,\n        subtitle = subtitle_text,\n        caption = caption_text,\n        x = \"Speaker Concentration\\n(0 = evenly spread across countries, 1 = single country dominates)\",\n        y = \"Number of Countries\"\n    ) + \n    # Theme\n    theme(\n        axis.title.y = element_text(\n            angle = 0,           # Makes it horizontal\n            vjust = 1.02,        # Pushes it to the top of the axis\n            hjust = 0.5,\n            margin = margin(r = -50) # Adjusts distance from the axis\n        ),\n    plot.title = element_markdown(\n        size = rel(1.4),\n        family = fonts$title,\n        face = \"bold\",\n        color = colors$title,\n        lineheight = 1.15,\n        margin = margin(t = 0, b = 5)\n    ),\n    plot.subtitle = element_markdown(\n        size = rel(0.8),\n        family = fonts$subtitle,\n        color = alpha(colors$subtitle, 0.88),\n        lineheight = 1.5,\n        margin = margin(t = 5, b = 20)\n    ),\n    plot.caption = element_markdown(\n        size = rel(0.5),\n        family = fonts$subtitle,\n        color = colors$caption,\n        hjust = 0,\n        lineheight = 1.4,\n        margin = margin(t = 20, b = 5)\n    )\n)\n```\n\n\n7. Save\n\nShow code```{r}\n#| label: save\n#| warning: false\n\n### |-  plot image ----  \nsave_plot(\n  plot = p, \n  type = \"tidytuesday\", \n  year = 2026, \n  week = 02, \n  width  = 8,\n  height = 6,\n  )\n```\n\n\n8. Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] here_1.0.1      glue_1.8.0      scales_1.3.0    janitor_2.2.0  \n [5] ggrepel_0.9.6   showtext_0.9-7  showtextdb_3.0  sysfonts_0.8.9 \n [9] ggtext_0.1.2    lubridate_1.9.3 forcats_1.0.0   stringr_1.5.1  \n[13] dplyr_1.1.4     purrr_1.0.2     readr_2.1.5     tidyr_1.3.1    \n[17] tibble_3.2.1    ggplot2_3.5.1   tidyverse_2.0.0 pacman_0.5.1   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6       httr2_1.0.6        xfun_0.49          htmlwidgets_1.6.4 \n [5] gh_1.4.1           tzdb_0.5.0         vctrs_0.6.5        tools_4.4.0       \n [9] generics_0.1.3     parallel_4.4.0     curl_6.0.0         gifski_1.32.0-1   \n[13] fansi_1.0.6        pkgconfig_2.0.3    lifecycle_1.0.4    farver_2.1.2      \n[17] compiler_4.4.0     textshaping_0.4.0  munsell_0.5.1      codetools_0.2-20  \n[21] snakecase_0.11.1   htmltools_0.5.8.1  yaml_2.3.10        crayon_1.5.3      \n[25] pillar_1.9.0       camcorder_0.1.0    magick_2.8.5       commonmark_1.9.2  \n[29] tidyselect_1.2.1   digest_0.6.37      stringi_1.8.4      rsvg_2.6.1        \n[33] rprojroot_2.0.4    fastmap_1.2.0      grid_4.4.0         colorspace_2.1-1  \n[37] cli_3.6.4          magrittr_2.0.3     utf8_1.2.4         withr_3.0.2       \n[41] rappdirs_0.3.3     bit64_4.5.2        timechange_0.3.0   rmarkdown_2.29    \n[45] tidytuesdayR_1.1.2 gitcreds_0.1.2     bit_4.5.0          ragg_1.3.3        \n[49] hms_1.1.3          evaluate_1.0.1     knitr_1.49         markdown_1.13     \n[53] rlang_1.1.6        gridtext_0.1.5     Rcpp_1.0.13-1      xml2_1.3.6        \n[57] renv_1.0.3         vroom_1.6.5        svglite_2.1.3      rstudioapi_0.17.1 \n[61] jsonlite_1.8.9     R6_2.5.1           systemfonts_1.1.0 \n\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in tt_2026_02.qmd.\nFor the full repository, click here.\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\n\n\nData Source:\n\nTidyTuesday 2026 Week 02: The Languages of Africa\n\n\n\n\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\n\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\n\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\n\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n Back to topCitationBibTeX citation:@online{ponce2026,\n  author = {Ponce, Steven},\n  title = {Africaâ€™s {Indigenous} {Language} {Families} {Span} the\n    {Continentr}},\n  date = {2026-01-11},\n  url = {https://stevenponce.netlify.app/data_visualizations/TidyTuesday/2026/tt_2026_02.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPonce, Steven. 2026. â€œAfricaâ€™s Indigenous Language Families Span\nthe Continentr.â€ January 11, 2026. https://stevenponce.netlify.app/data_visualizations/TidyTuesday/2026/tt_2026_02.html."
  },
  {
    "objectID": "data_visualizations/MakeoverMonday/2026/mm_2026_02.html",
    "href": "data_visualizations/MakeoverMonday/2026/mm_2026_02.html",
    "title": "The Global Housing Bubble is Losing Air",
    "section": "",
    "text": "Original\nThe original visualization comes from The Biggest Housing Bubble Risks Globally\n\n\nOriginal visualization\n\nMakeover\n\n\n\n\n\nFigureÂ 1: Two-panel visualization comparing housing bubble risk trajectories for 9 global cities from 2020 to 2025. Left panel: Slope chart showing dramatic divergenceâ€”Toronto, Hong Kong, and Munich fell from 1.8 to below 1.0 (teal lines), while Miami rose from 0.5 to 1.7 (grey lines). Right panel: Scatter plot of current risk score versus 5-year change, with point size reflecting magnitude of change. Cooling markets cluster in the lower-left quadrant; Hong Kong shows the most significant decline (-1.3 points).\n\n\nSteps to Create this Graphic\n1. Load Packages & Setup\n\nShow code```{r}\n#| label: load\n#| warning: false\n#| message: false\n#| results: \"hide\"\n\n## 1. LOAD PACKAGES & SETUP ----\nsuppressPackageStartupMessages({\n  if (!require(\"pacman\")) install.packages(\"pacman\")\n  pacman::p_load(\n    tidyverse, janitor, skimr, scales, ggtext, showtext, glue,\n    patchwork, ggrepel          # Interpreted String Literals\n)\n})\n\n### |- figure size ----\ncamcorder::gg_record(\n    dir    = here::here(\"temp_plots\"),\n    device = \"png\",\n    width  = 12,\n    height = 8,\n    units  = \"in\",\n    dpi    = 320\n)\n\n# Source utility functions\nsuppressMessages(source(here::here(\"R/utils/fonts.R\")))\nsource(here::here(\"R/utils/social_icons.R\"))\nsource(here::here(\"R/utils/image_utils.R\"))\nsource(here::here(\"R/themes/base_theme.R\"))\n```\n\n\n2. Read in the Data\n\nShow code```{r}\n#| label: read\n#| include: true\n#| eval: true\n#| warning: false\n#|\n\n### |- Current data (2025) ----\nhousing_bubble_raw &lt;- readxl::read_excel(\n   here::here(\"data/MakeoverMonday/2026/Housing bubbles.xlsx\")) |&gt;\n  clean_names()\n\n### |- Historical data (2020-2025) from UBS reports ----\n\n# Source: UBS Global Real Estate Bubble Index reports 2020-2025\n# https://www.ubs.com/global/en/wealth-management/insights/2024/global-real-estate-bubble-index.html\n# Note: Historical data compiled from annual UBS reports\n\nhistorical_raw &lt;- tribble(\n  ~city, ~year_2020, ~year_2021, ~year_2022, ~year_2023, ~year_2024, ~year_2025,\n  \"Miami\", 0.5, 0.8, 1.4, 1.8, 1.8, 1.7,\n  \"Tokyo\", 0.7, 0.7, 0.6, 0.9, 1.2, 1.6,\n  \"Zurich\", 1.5, 1.8, 1.7, 1.7, 1.5, 1.6,\n  \"Los Angeles\", 0.7, 1.0, 1.2, 1.2, 1.2, 1.1,\n  \"Toronto\", 1.8, 2.0, 2.2, 1.2, 0.9, 0.8,\n  \"Frankfurt\", 1.5, 2.2, 2.2, 1.1, 0.8, 0.8,\n  \"Munich\", 1.8, 2.3, 2.0, 1.1, 0.9, 0.6,\n  \"Hong Kong\", 1.8, 1.7, 1.7, 1.2, 0.7, 0.5,\n  \"Vancouver\", 1.0, 1.6, 1.7, 1.1, 0.9, 0.8\n)\n```\n\n\n3. Examine the Data\n\nShow code```{r}\n#| label: examine\n#| include: true\n#| eval: true\n#| results: 'hide'\n#| warning: false\n\nglimpse(housing_bubble_raw)\nglimpse(historical_raw)\n```\n\n\n4. Tidy Data\n\nShow code```{r}\n#| label: tidy\n#| warning: false\n\nslope_data &lt;- historical_raw |&gt;\n  mutate(\n    change     = year_2025 - year_2020,\n    direction  = if_else(change &lt; 0, \"Cooling\", \"Rising\"),\n    label_2020 = sprintf(\"%s  %.1f\", city, year_2020),\n    label_2025 = sprintf(\"%s  %.1f\", city, year_2025)\n  ) |&gt;\n  arrange(desc(year_2025)) |&gt;\n  mutate(city = factor(city, levels = unique(city)))\n```\n\n\n5. Visualization Parameters\n\nShow code```{r}\n#| label: params\n#| include: true\n#| warning: false\n\n### |-  plot aesthetics ----\n# Get base colors with custom palette\ncolors &lt;- get_theme_colors(\n  palette = list(\n    cooling    = \"#0D7377\",\n    rising     = \"#C4C4C4\"\n  )\n)\n\n### |-  Main titles ----\ntitle_text &lt;- \"The Global Housing Bubble is Losing Air\"\n\nsubtitle_text &lt;- str_glue(\n  \"While Miami and Tokyo continue to heat up, the primary global trend is a **significant cooling** of major hubs.&lt;br&gt;\",\n  \"Former 'Bubble Risk' leaders like \",\n  \"&lt;span style='color:{colors$palette$cooling};'&gt;**Toronto, Frankfurt, and Hong Kong**&lt;/span&gt;\",\n  \" have seen their risk scores halved since 2020.\"\n)\n\ncaption_text &lt;- create_mm_caption(\n  mm_year = 2026, mm_week = 02,\n  source_text = str_glue(\n    \"UBS Global Real Estate Bubble Index 2025\"\n  )\n)\n\n### |-  fonts ----\nsetup_fonts()\nfonts &lt;- get_font_families()\n\n### |-  plot theme ----\n\n# Start with base theme\nbase_theme &lt;- create_base_theme(colors)\n\n# Add weekly-specific theme elements\nweekly_theme &lt;- extend_weekly_theme(\n  base_theme,\n  theme(\n    # # Text styling\n    plot.title = element_text(\n      size = rel(1.5), family = fonts$title, face = \"bold\",\n      color = colors$title, lineheight = 1.1, hjust = 0,\n      margin = margin(t = 5, b = 10)\n    ),\n    plot.subtitle = element_markdown(\n      size = rel(0.9), family = fonts$subtitle, face = \"italic\",\n      color = alpha(colors$subtitle, 0.9), lineheight = 1.1,\n      margin = margin(t = 0, b = 20)\n    ),\n\n    # Legend formatting\n    legend.position = \"plot\",\n    legend.justification = \"right\",\n    legend.margin = margin(l = 12, b = 5),\n    legend.key.size = unit(0.8, \"cm\"),\n    legend.box.margin = margin(b = 10),\n\n    # Axis formatting\n    axis.ticks.y = element_blank(),\n    axis.ticks.x = element_line(color = \"gray\", linewidth = 0.5),\n    axis.title.x = element_text(\n      face = \"bold\", size = rel(0.85),\n      margin = margin(t = 10), family = fonts$subtitle,\n      color = \"gray40\"\n    ),\n    axis.title.y = element_text(\n      face = \"bold\", size = rel(0.85),\n      margin = margin(r = 10), family = fonts$subtitle,\n      color = \"gray40\"\n    ),\n    axis.text.x = element_text(\n      size = rel(0.85), family = fonts$subtitle,\n      color = \"gray40\"\n    ),\n    axis.text.y = element_markdown(\n      size = rel(0.85), family = fonts$subtitle,\n      color = \"gray40\"\n    ),\n\n    # Grid lines\n    panel.grid.minor = element_line(color = \"#ecf0f1\", linewidth = 0.2),\n    panel.grid.major = element_line(color = \"#ecf0f1\", linewidth = 0.4),\n\n    # Margin\n    plot.margin = margin(20, 20, 20, 20)\n  )\n)\n\n# Set theme\ntheme_set(weekly_theme)\n```\n\n\n6. Plot\n\nShow code```{r}\n#| label: plot\n#| warning: false\n\n### |-  p1: slope chart ----\np1 &lt;-\nggplot(slope_data) +\n  # Geoms\n  geom_segment(\n    aes(\n      x = 1, xend = 2,\n      y = year_2020, yend = year_2025,\n      color = direction, alpha = direction, linewidth = direction\n    )\n  ) +\n  geom_point(aes(x = 1, y = year_2020, color = direction, alpha = direction), size = 2) +\n  geom_point(aes(x = 2, y = year_2025, color = direction, alpha = direction), size = 3) +\n  geom_text_repel(\n    aes(x = 1, y = year_2020, label = label_2020),\n    direction = \"y\",\n    hjust = 1,\n    nudge_x = -0.15,\n    size = 3.5,\n    segment.color = NA,\n    family = fonts$text,\n    color = colors$text     \n  ) +\n  geom_text_repel(\n    aes(x = 2, y = year_2025, label = label_2025, color = direction),\n    direction = \"y\",\n    hjust = 0,\n    nudge_x = 0.15,\n    size = 3.8,\n    fontface = \"bold\",\n    segment.color = NA,\n    family = fonts$text,\n    seed = 123\n  ) +\n  # Scales\n  scale_color_manual(values = c(\"Cooling\" = colors$palette$cooling, \"Rising\" = colors$palette$rising)) +\n  scale_alpha_manual(values = c(\"Cooling\" = 1, \"Rising\" = 0.4)) +\n  scale_linewidth_manual(values = c(\"Cooling\" = 1.2, \"Rising\" = 0.5)) +\n  scale_x_continuous(\n    limits = c(0.4, 2.6),\n    breaks = c(1, 2),\n    labels = c(\"2020\", \"2025\")\n  ) +\n  # Labs\n  labs(subtitle = \"Bubble Risk Index: 5-Year Trajectory\", x = NULL, y = NULL) +\n  # Theme\n  theme(\n    panel.grid.minor = element_blank(),\n    panel.grid.major.y = element_blank(),\n    axis.text.y = element_blank(),\n    legend.position = \"none\"\n    )\n\n### |-  p2: quadrant chart ----\np2 &lt;-\nggplot(slope_data, aes(x = year_2025, y = change)) +\n  # Geoms\n  geom_hline(yintercept = 0, color = \"grey80\", linetype = \"dashed\") +\n  geom_vline(xintercept = 1, color = \"grey80\", linetype = \"dashed\") +\n  geom_point(aes(color = direction, alpha = direction, size = abs(change))) +\n  geom_text_repel(\n    aes(label = city, color = direction),\n    size = 3.5,\n    fontface = \"bold\",\n    box.padding = 0.5, \n    seed = 123\n  ) +\n  # Scales\n  scale_color_manual(values = c(\"Cooling\" = colors$palette$cooling, \"Rising\" = colors$palette$rising)) +\n  scale_alpha_manual(values = c(\"Cooling\" = 1, \"Rising\" = 0.4)) +\n  scale_size(range = c(2.5, 8)) +\n  coord_cartesian(xlim = c(0, 2)) +\n  # Labs\n  labs(\n    subtitle = \"Current Risk vs. Velocity of Change\",\n    x = \"Risk Score in 2025\",\n    y = \"5-Year Net Change\"\n  ) +\n  # Theme\n  theme(\n    legend.position = \"none\",\n    panel.grid.major = element_line(color = \"grey95\")\n  )\n\n### |-  combined plot ----\ncombined_plot &lt;- p1 + p2 +\n  plot_layout(widths = c(1.15, 1)) +\n  plot_annotation(\n    title = title_text,\n    subtitle = subtitle_text,\n    caption = caption_text,\n    theme = theme(\n      plot.title = element_text(\n        size = rel(2.4),\n        family = fonts$title,\n        face = \"bold\",\n        color = colors$title,\n        lineheight = 1.15,\n        margin = margin(t = 5, b = 10)\n      ),\n      plot.subtitle = element_markdown(\n        size = rel(0.8),\n        family = fonts$subtitle,\n        color = alpha(colors$subtitle, 0.88),\n        lineheight = 1.5,\n        margin = margin(t = 5, b = 10)\n      ),\n      plot.caption = element_markdown(\n        size = rel(0.55),\n        family = fonts$subtitle,\n        color = colors$caption,\n        hjust = 0,\n        lineheight = 1.4,\n        margin = margin(t = 20, b = 5)\n      ),\n    )\n  )\n```\n\n\n7. Save\n\nShow code```{r}\n#| label: save\n#| warning: false\n\n### |-  plot image ----  \nsave_plot_patchwork(\n  plot = combined_plot, \n  type = \"makeovermonday\", \n  year = current_year,\n  week = current_week,\n  width = 12, \n  height = 8\n  )\n```\n\n\n8. Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] here_1.0.1      ggrepel_0.9.6   patchwork_1.3.0 glue_1.8.0     \n [5] showtext_0.9-7  showtextdb_3.0  sysfonts_0.8.9  ggtext_0.1.2   \n [9] scales_1.3.0    skimr_2.1.5     janitor_2.2.0   lubridate_1.9.3\n[13] forcats_1.0.0   stringr_1.5.1   dplyr_1.1.4     purrr_1.0.2    \n[17] readr_2.1.5     tidyr_1.3.1     tibble_3.2.1    ggplot2_3.5.1  \n[21] tidyverse_2.0.0 pacman_0.5.1   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6       xfun_0.49          htmlwidgets_1.6.4  tzdb_0.5.0        \n [5] yulab.utils_0.1.8  vctrs_0.6.5        tools_4.4.0        generics_0.1.3    \n [9] curl_6.0.0         gifski_1.32.0-1    fansi_1.0.6        pkgconfig_2.0.3   \n[13] ggplotify_0.1.2    readxl_1.4.3       lifecycle_1.0.4    compiler_4.4.0    \n[17] farver_2.1.2       munsell_0.5.1      repr_1.1.7         codetools_0.2-20  \n[21] snakecase_0.11.1   htmltools_0.5.8.1  yaml_2.3.10        pillar_1.9.0      \n[25] camcorder_0.1.0    magick_2.8.5       commonmark_1.9.2   tidyselect_1.2.1  \n[29] digest_0.6.37      stringi_1.8.4      labeling_0.4.3     rsvg_2.6.1        \n[33] rprojroot_2.0.4    fastmap_1.2.0      grid_4.4.0         colorspace_2.1-1  \n[37] cli_3.6.4          magrittr_2.0.3     base64enc_0.1-3    utf8_1.2.4        \n[41] withr_3.0.2        timechange_0.3.0   rmarkdown_2.29     cellranger_1.1.0  \n[45] hms_1.1.3          evaluate_1.0.1     knitr_1.49         markdown_1.13     \n[49] gridGraphics_0.5-1 rlang_1.1.6        gridtext_0.1.5     Rcpp_1.0.13-1     \n[53] xml2_1.3.6         renv_1.0.3         svglite_2.1.3      rstudioapi_0.17.1 \n[57] jsonlite_1.8.9     R6_2.5.1           fs_1.6.5           systemfonts_1.1.0 \n\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in mm_2026_02.qmd.\nFor the full repository, click here.\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\n\n\nData:\n\nMakeover Monday 2026 Week 2: The Biggest Housing Bubble Risks Globally\n\n\n\n\nArticle\n\nThe Biggest Housing Bubble Risks Globally\n\n\n\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\n\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\n\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\n\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n Back to topCitationBibTeX citation:@online{ponce2026,\n  author = {Ponce, Steven},\n  title = {The {Global} {Housing} {Bubble} Is {Losing} {Air}},\n  date = {2026-01-12},\n  url = {https://stevenponce.netlify.app/data_visualizations/MakeoverMonday/2026/mm_2026_02.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPonce, Steven. 2026. â€œThe Global Housing Bubble Is Losing\nAir.â€ January 12, 2026. https://stevenponce.netlify.app/data_visualizations/MakeoverMonday/2026/mm_2026_02.html."
  },
  {
    "objectID": "data_visualizations/TidyTuesday/2026/tt_2026_03.html",
    "href": "data_visualizations/TidyTuesday/2026/tt_2026_03.html",
    "title": "How Far Does APOD Take Us?",
    "section": "",
    "text": "FigureÂ 1: Histogram showing the distribution of distances mentioned in NASAâ€™s Astronomy Picture of the Day explanations from 2007-2025, plotted on a logarithmic scale from 1 to 10 billion light-years. The distribution peaks sharply between 1,000 and 2,000 light-years (labeled â€œThe Nebula Peakâ€), where nebulae and star clusters reside. Five vertical reference lines mark key cosmic landmarks: Proxima Centauri at 4 light-years, the Orion Nebula at 1,500 light-years, the Galactic center at 26,000 light-years, the Milky Way diameter at 100,000 light-years, and the Andromeda Galaxy at 2.5 million light-years. A secondary peak appears around 10-100 million light-years, representing distant galaxies.\n\n\nSteps to Create this Graphic\n1. Load Packages & Setup\n\nShow code```{r}\n#| label: load\n#| warning: false\n#| message: false\n#| results: \"hide\"\n\n## 1. LOAD PACKAGES & SETUP ----\nsuppressPackageStartupMessages({\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n    tidyverse,     # Easily Install and Load the 'Tidyverse'\n    ggtext,        # Improved Text Rendering Support for 'ggplot2'\n    showtext,      # Using Fonts More Easily in R Graphs\n    ggrepel,       # Non-overlapping Text Labels\n    janitor,       # Simple Tools for Examining and Cleaning Dirty Data\n    scales,        # Scale Functions for Visualization\n    glue           # Interpreted String Literals\n)\n})\n\n### |- figure size ----\ncamcorder::gg_record(\n  dir    = here::here(\"temp_plots\"),\n  device = \"png\",\n  width  = 8,\n  height = 6,\n  units  = \"in\",\n  dpi    = 320\n)\n\n# Source utility functions\nsuppressMessages(source(here::here(\"R/utils/fonts.R\")))\nsource(here::here(\"R/utils/social_icons.R\"))\nsource(here::here(\"R/utils/image_utils.R\"))\nsource(here::here(\"R/themes/base_theme.R\"))\n```\n\n\n2. Read in the Data\n\nShow code```{r}\n#| label: read\n#| include: true\n#| eval: true\n#| warning: false\n\ntt &lt;- tidytuesdayR::tt_load(2026, week = 03)\napod_raw &lt;- tt$apod |&gt; clean_names()\nrm(tt)\n```\n\n\n3. Examine the Data\n\nShow code```{r}\n#| label: examine\n#| include: true\n#| eval: true\n#| results: 'hide'\n#| warning: false\n\nglimpse(apod_raw)\n```\n\n\n4. Tidy Data\n\nShow code```{r}\n#| label: tidy-fixed\n#| warning: false\n\n# Extract light-year distances from explanations\nextract_distances &lt;- function(text) {\n  if (is.na(text)) {\n    return(NA_real_)\n  }\n  pattern &lt;- \"(\\\\d{1,3}(?:,\\\\d{3})*(?:\\\\.\\\\d+)?)\\\\s*(million|billion)?\\\\s*light[\\\\-\\\\s]years?\"\n  matches &lt;- str_match_all(tolower(text), pattern)[[1]]\n  if (nrow(matches) == 0) {\n    return(NA_real_)\n  }\n\n  val &lt;- str_remove_all(matches[, 2], \",\") |&gt; as.numeric()\n  multiplier &lt;- case_when(\n    matches[, 3] == \"million\" ~ 1e6,\n    matches[, 3] == \"billion\" ~ 1e9,\n    TRUE ~ 1\n  )\n  return(val * multiplier)\n}\n\n# Build distance dataset\ndistances_clean &lt;- apod_raw |&gt;\n  mutate(dist_val = map(explanation, extract_distances)) |&gt;\n  unnest(dist_val) |&gt;\n  filter(!is.na(dist_val), dist_val &gt; 0, dist_val &lt; 1e10)\n\nlandmarks &lt;- tibble(\n  distance = c(4.24, 1500, 26000, 100000, 2500000),\n  label = c(\n    \"Nearest star\\n(Proxima Centauri)\",\n    \"Orion Nebula\\n(APOD favorite)\",\n    \"Galactic\\ncenter\",\n    \"Milky Way\\ndiameter\",\n    \"Andromeda\\nGalaxy\"\n  ),\n  y_pos = c(255, 255, 275, 255, 255)\n)\n```\n\n\n5. Visualization Parameters\n\nShow code```{r}\n#| label: params\n#| include: true\n#| warning: false\n\n### |-  plot aesthetics ----\ncolors &lt;- get_theme_colors(\n  palette = list(\n      bar =   \"#b066a2\",     \n      line =  \"#58a6ff\"\n  )\n)\n\n### |- titles and caption ----\ntitle_text = \"How Far Does APOD Take Us?\"\n\nsubtitle_text = str_glue(\n    \"Distribution of distances mentioned in NASA's **Astronomy Picture of the Day** (2007-2025).&lt;br&gt;\",\n    \"Most content focuses on our galaxy, peaking where **nebulae and star clusters** reside.\"\n    )\n\ncaption_text &lt;- create_social_caption(\n    tt_year = 2026,\n    tt_week = 03,\n    source_text = \"NASA APOD Archive via NASA API\"\n)\n\n### |-  fonts ----\nsetup_fonts()\nfonts &lt;- get_font_families()\n\n### |-  plot theme ----\n# Start with base theme\nbase_theme &lt;- create_base_theme(colors)\n\n# Add weekly-specific theme elements\nweekly_theme &lt;- extend_weekly_theme(\n  base_theme,\n  theme(\n    # Text styling\n    plot.title = element_text(\n      face = \"bold\", family = fonts$title, size = rel(1.4),\n      color = colors$title, margin = margin(b = 10), hjust = 0\n    ),\n    plot.subtitle = element_markdown(\n      face = \"italic\", family = fonts$subtitle, lineheight = 1.2,\n      color = colors$subtitle, size = rel(0.9), margin = margin(b = 20), hjust = 0\n    ),\n\n    # Grid\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major = element_line(color = \"gray90\", linewidth = 0.25),\n\n    # Axes\n    axis.title = element_text(size = rel(0.8), color = \"gray30\"),\n    axis.text = element_text(color = \"gray30\"),\n    axis.text.y = element_text(size = rel(0.85)),\n    axis.ticks = element_blank(),\n\n    # Facets\n    strip.background = element_rect(fill = \"gray95\", color = NA),\n    strip.text = element_text(\n      face = \"bold\",\n      color = \"gray20\",\n      size = rel(0.9),\n      margin = margin(t = 6, b = 4)\n    ),\n    panel.spacing = unit(1.5, \"lines\"),\n\n    # Legend elements\n    legend.position = \"plot\",\n    legend.title = element_text(\n      family = fonts$subtitle,\n      color = colors$text, size = rel(0.8), face = \"bold\"\n    ),\n    legend.text = element_text(\n      family = fonts$tsubtitle,\n      color = colors$text, size = rel(0.7)\n    ),\n    legend.margin = margin(t = 15),\n\n    # Plot margin\n    plot.margin = margin(10, 20, 10, 20),\n    \n  )\n)\n\n# Set theme\ntheme_set(weekly_theme)\n```\n\n\n6. Plot\n\nShow code```{r}\n#| label: plot\n#| warning: false\n\n### |- Plot ----\np &lt;- ggplot(distances_clean, aes(x = dist_val)) +\n  # Annotate\n  annotate(\"rect\",\n    xmin = 800, xmax = 3000, ymin = 0, ymax = 300,\n    fill = colors$palette$bar, alpha = 0.08\n  ) +\n  annotate(\"text\",\n    x = 1800, y = 290, label = \"THE NEBULA PEAK\",\n    family = fonts$text, size = 4, color = colors$palette$bar, fontface = \"bold\"\n  ) +\n  # Geoms\n  geom_histogram(\n    fill = colors$palette$bar, color = \"white\",\n    bins = 60, alpha = 0.9\n  ) +\n  geom_segment(\n    data = landmarks,\n    aes(x = distance, xend = distance, y = 0, yend = 300),\n    linetype = \"dotted\",\n    color = colors$palette$line,\n    linewidth = 0.5\n  ) +\n  geom_text(\n    data = landmarks, aes(x = distance, y = y_pos, label = label),\n    size = 2.8, family = fonts$text, fontface = \"bold\",\n    lineheight = 0.85, vjust = 1, color = colors$text\n  ) +\n  # Scales\n  scale_x_log10(\n    expand = expansion(mult = c(0.02, 0.05)),\n    breaks = 10^(0:10),\n    labels = label_log()\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +\n  coord_cartesian(clip = \"off\") +\n  # Labs\n  labs(\n    title = title_text,\n    subtitle = subtitle_text,\n    caption = caption_text,\n    x = \"Distance (light-years)\",\n    y = \"Number of\\nMentions\"\n  ) +\n  # Theme\n  theme(\n    axis.title.y = element_text(angle = 0, vjust = 0.95, hjust = 0, size = rel(0.8), face = \"bold\", color = colors$text),\n    axis.title.x = element_text(size = rel(0.8), face = \"bold\", color = colors$text),\n    axis.text = element_text(, color = colors$text, size = rel(0.6)),\n    plot.title = element_markdown(\n      size = rel(1.8),\n      family = fonts$title,\n      face = \"bold\",\n      color = colors$title,\n      lineheight = 1.15,\n      margin = margin(t = 5, b = 5)\n    ),\n    plot.subtitle = element_markdown(\n      size = rel(0.65),\n      family = fonts$subtitle,\n      color = colors$subtitle,\n      lineheight = 1.5,\n      margin = margin(t = 5, b = 5)\n    ),\n    plot.caption = element_markdown(\n      size = rel(0.45),\n      family = fonts$subtitle,\n      color = colors$caption,\n      hjust = 0,\n      lineheight = 1.4,\n      margin = margin(t = 10, b = 5)\n    ),\n  )\n```\n\n\n7. Save\n\nShow code```{r}\n#| label: save\n#| warning: false\n\n### |-  plot image ----  \nsave_plot(\n  plot = p, \n  type = \"tidytuesday\", \n  year = 2026, \n  week = 03, \n  width  = 8,\n  height = 6,\n  )\n```\n\n\n8. Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] here_1.0.1      glue_1.8.0      scales_1.3.0    janitor_2.2.0  \n [5] ggrepel_0.9.6   showtext_0.9-7  showtextdb_3.0  sysfonts_0.8.9 \n [9] ggtext_0.1.2    lubridate_1.9.3 forcats_1.0.0   stringr_1.5.1  \n[13] dplyr_1.1.4     purrr_1.0.2     readr_2.1.5     tidyr_1.3.1    \n[17] tibble_3.2.1    ggplot2_3.5.1   tidyverse_2.0.0 pacman_0.5.1   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6       httr2_1.0.6        xfun_0.49          htmlwidgets_1.6.4 \n [5] gh_1.4.1           tzdb_0.5.0         vctrs_0.6.5        tools_4.4.0       \n [9] generics_0.1.3     parallel_4.4.0     curl_6.0.0         gifski_1.32.0-1   \n[13] fansi_1.0.6        pkgconfig_2.0.3    lifecycle_1.0.4    farver_2.1.2      \n[17] compiler_4.4.0     textshaping_0.4.0  munsell_0.5.1      codetools_0.2-20  \n[21] snakecase_0.11.1   htmltools_0.5.8.1  yaml_2.3.10        crayon_1.5.3      \n[25] pillar_1.9.0       camcorder_0.1.0    magick_2.8.5       commonmark_1.9.2  \n[29] tidyselect_1.2.1   digest_0.6.37      stringi_1.8.4      labeling_0.4.3    \n[33] rsvg_2.6.1         rprojroot_2.0.4    fastmap_1.2.0      grid_4.4.0        \n[37] colorspace_2.1-1   cli_3.6.4          magrittr_2.0.3     utf8_1.2.4        \n[41] withr_3.0.2        rappdirs_0.3.3     bit64_4.5.2        timechange_0.3.0  \n[45] rmarkdown_2.29     tidytuesdayR_1.1.2 gitcreds_0.1.2     bit_4.5.0         \n[49] ragg_1.3.3         hms_1.1.3          evaluate_1.0.1     knitr_1.49        \n[53] markdown_1.13      rlang_1.1.6        gridtext_0.1.5     Rcpp_1.0.13-1     \n[57] xml2_1.3.6         renv_1.0.3         vroom_1.6.5        svglite_2.1.3     \n[61] rstudioapi_0.17.1  jsonlite_1.8.9     R6_2.5.1           systemfonts_1.1.0 \n\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in tt_2026_03.qmd.\nFor the full repository, click here.\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\n\n\nData Source:\n\nTidyTuesday 2026 Week 03: Astronomy Picture of the Day (APOD) Archive\n\n\n\n\nCosmic Distance Landmarks:\n\nNASA Imagine the Universe: Milky Way Galaxy\n\nNASA Science: Orion Nebula (M42)\n\nNASA Science: Andromeda Galaxy (M31)\n\nESA Gaia Mission: Proxima Centauri parallax measurements\n\n\n\n\nArticle:\n\nNASA Science: How Big is Space?\n\n\n\n\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\n\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\n\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\n\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n Back to topCitationBibTeX citation:@online{ponce2026,\n  author = {Ponce, Steven},\n  title = {How {Far} {Does} {APOD} {Take} {Us?}},\n  date = {2026-01-18},\n  url = {https://stevenponce.netlify.app/data_visualizations/TidyTuesday/2026/tt_2026_03.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPonce, Steven. 2026. â€œHow Far Does APOD Take Us?â€ January\n18, 2026. https://stevenponce.netlify.app/data_visualizations/TidyTuesday/2026/tt_2026_03.html."
  },
  {
    "objectID": "data_visualizations/MakeoverMonday/2026/mm_2026_03.html",
    "href": "data_visualizations/MakeoverMonday/2026/mm_2026_03.html",
    "title": "The Accelerating Rise of Women+ Conductors on Broadway",
    "section": "",
    "text": "Original\nThe original visualization comes from Women+ Conductors on Broadway\n\n\nOriginal visualization\n\nMakeover\n\n\n\n\n\nFigureÂ 1: A two-panel visualization showing the growth of women+ conductors on Broadway. The left panel displays a cumulative area chart from 1954 to present, showing slow early growth that accelerates sharply after 2000, reaching approximately 100 unique conductors by 2024, with an annotation noting the 50th conductor was reached in 2000. The right panel shows horizontal stacked bar charts comparing role distribution across four eras: Pre-1980 was split between Leadership (49%) and Support (46%); 1980-1999 was dominated by Support roles (84%); 2000-2019 showed more balance with Support (50%), Leadership (26%), and Supplemental (23%); and 2020+ shows the most diverse mix with Supplemental (41%), Support (34%), and Leadership (25%). Sample sizes range from 39 positions pre-1980 to 102 in 2000-2019.\n\n\nSteps to Create this Graphic\n1. Load Packages & Setup\n\nShow code```{r}\n#| label: load\n#| warning: false\n#| message: false\n#| results: \"hide\"\n\n## 1. LOAD PACKAGES & SETUP ----\nsuppressPackageStartupMessages({\n  if (!require(\"pacman\")) install.packages(\"pacman\")\n  pacman::p_load(\n    tidyverse, ggtext, showtext, scales, glue, patchwork, janitor, readxl\n)\n})\n\n### |- figure size ----\ncamcorder::gg_record(\n    dir    = here::here(\"temp_plots\"),\n    device = \"png\",\n    width  = 12,\n    height = 8,\n    units  = \"in\",\n    dpi    = 320\n)\n\n# Source utility functions\nsuppressMessages(source(here::here(\"R/utils/fonts.R\")))\nsource(here::here(\"R/utils/social_icons.R\"))\nsource(here::here(\"R/utils/image_utils.R\"))\nsource(here::here(\"R/themes/base_theme.R\"))\n```\n\n\n2. Read in the Data\n\nShow code```{r}\n#| label: read\n#| include: true\n#| eval: true\n#| warning: false\n#|\n\n### |- Current data (2025) ----\nconductor_raw &lt;- readxl::read_excel(\n   here::here(\"data/MakeoverMonday/2026/Conductor Timeline Data_Contest.xlsx\")) |&gt;\n  clean_names()\n```\n\n\n3. Examine the Data\n\nShow code```{r}\n#| label: examine\n#| include: true\n#| eval: true\n#| results: 'hide'\n#| warning: false\n\nglimpse(conductor_raw)\nskimr::skim(conductor_raw) |&gt; summary()\n```\n\n\n4. Tidy Data\n\nShow code```{r}\n#| label: tidy\n#| warning: false\n\n# Define role tiers\nrole_tiers &lt;- tribble(\n  ~role,                         ~tier,          ~tier_order,\n  \"Music Supervisor\",            \"Leadership\",   1,\n  \"Music Director\",              \"Leadership\",   1,\n  \"Conductor\",                   \"Leadership\",   1,\n  \"Co-Music Director\",           \"Leadership\",   1,\n  \"Co-Music Supervisor\",         \"Leadership\",   1,\n  \"Associate Music Director\",    \"Support\",      2,\n  \"Associate Music Supervisor\",  \"Support\",      2,\n  \"Associate Conductor\",         \"Support\",      2,\n  \"Resident Music Supervisor\",   \"Support\",      2,\n  \"Assistant Music Director\",    \"Support\",      2,\n  \"Assistant Conductor\",         \"Support\",      2,\n  \"Alternate Conductor\",         \"Supplemental\", 3,\n  \"Substitute Conductor\",        \"Supplemental\", 3,\n  \"Children's Music Director\",   \"Specialized\",  4\n)\n\nconductor_clean &lt;- conductor_raw |&gt;\n  mutate(\n    year = year(opening_date),\n    era = case_when(\n      year &lt; 1980 ~ \"Pre-1980\",\n      year &gt;= 1980 & year &lt; 2000 ~ \"1980-1999\",\n      year &gt;= 2000 & year &lt; 2020 ~ \"2000-2019\",\n      year &gt;= 2020 ~ \"2020+\"\n    )\n  ) |&gt;\n  left_join(role_tiers, by = \"role\") |&gt;\n  filter(!is.na(era), !is.na(tier))\n\n# Panel 1 Data: Cumulative\ncumulative_data &lt;- conductor_clean |&gt;\n  distinct(person_id, year) |&gt;\n  group_by(person_id) |&gt;\n  summarize(first_year = min(year), .groups = \"drop\") |&gt;\n  count(first_year) |&gt;\n  arrange(first_year) |&gt;\n  mutate(cumulative = cumsum(n))\n\nlatest_val &lt;- filter(cumulative_data, first_year == max(first_year))\n\nm50 &lt;- filter(cumulative_data, cumulative &gt;= 50) |&gt; slice(1)\n\n# Panel 2 Data: Role Stats with Chronological Ordering\nrole_era_stats &lt;- conductor_clean |&gt;\n  group_by(era) |&gt;\n  mutate(era_n = n()) |&gt;\n  ungroup() |&gt;\n  mutate(era_label = glue(\"**{era}**&lt;br&gt;(n={era_n})\")) |&gt;\n  mutate(era_label = fct_reorder(era_label, year, .desc = TRUE)) |&gt;\n  count(era_label, tier) |&gt;\n  group_by(era_label) |&gt;\n  mutate(pct = n / sum(n)) |&gt;\n  ungroup() |&gt;\n  mutate(tier = factor(tier, levels = rev(c(\"Leadership\", \"Support\", \"Supplemental\", \"Specialized\"))))\n```\n\n\n5. Visualization Parameters\n\nShow code```{r}\n#| label: params\n#| include: true\n#| warning: false\n\n### |-  plot aesthetics ----\n# Get base colors with custom palette\ncolors &lt;- get_theme_colors(\n  palette = list(\n    leadership = \"#134050\", \n    support = \"#4A90A4\",\n    supplemental = \"#7FB3C4\",\n    specialized = \"#B8D4DE\"\n  )\n)\n\ntier_colors &lt;- c(\n  \"Leadership\" = colors$palette$leadership,\n  \"Support\" = colors$palette$support,\n  \"Supplemental\" = colors$palette$supplemental,\n  \"Specialized\" = colors$palette$specialized\n)\n\n### |-  Main titles ----\ntitle_text &lt;- \"The Accelerating Rise of Women+ Conductors on Broadway\"\n\nsubtitle_text &lt;- str_glue(\n  \"While it took 46 years to reach the first 50 unique conductors, that number doubled in just the next 24 years.&lt;br&gt;\",\n  \"Today, **Leadership roles** account for over 40% of positions in the 2020s.\"\n)\n\ncaption_text &lt;- create_mm_caption(\n  mm_year = 2026, mm_week = 03,\n  source_text = str_glue(\n    \"Maestra Music\"\n  )\n)\n\n### |-  fonts ----\nsetup_fonts()\nfonts &lt;- get_font_families()\n\n### |-  plot theme ----\n\n# Start with base theme\nbase_theme &lt;- create_base_theme(colors)\n\n# Add weekly-specific theme elements\nweekly_theme &lt;- extend_weekly_theme(\n  base_theme,\n  theme(\n    # # Text styling\n    plot.title = element_text(\n      size = rel(1.5), family = fonts$title, face = \"bold\",\n      color = colors$title, lineheight = 1.1, hjust = 0,\n      margin = margin(t = 5, b = 10)\n    ),\n    plot.subtitle = element_markdown(\n      size = rel(0.9), family = fonts$subtitle, face = \"italic\",\n      color = alpha(colors$subtitle, 0.9), lineheight = 1.1,\n      margin = margin(t = 0, b = 20)\n    ),\n\n    # Legend formatting\n    legend.position = \"plot\",\n    legend.justification = \"right\",\n    legend.margin = margin(l = 12, b = 5),\n    legend.key.size = unit(0.8, \"cm\"),\n    legend.box.margin = margin(b = 10),\n\n    # Axis formatting\n    axis.line.x = element_line(color = \"#252525\", linewidth = .1),\n    axis.ticks.y = element_blank(),\n    axis.ticks.x = element_line(color = \"gray\", linewidth = 0.5),\n    axis.title.x = element_text(\n      face = \"bold\", size = rel(0.85),\n      margin = margin(t = 10), family = fonts$subtitle,\n      color = \"gray40\"\n    ),\n    axis.title.y = element_text(\n      face = \"bold\", size = rel(0.85),\n      margin = margin(r = 10), family = fonts$subtitle,\n      color = \"gray40\"\n    ),\n    axis.text.x = element_text(\n      size = rel(0.85), family = fonts$subtitle,\n      color = \"gray40\"\n    ),\n    axis.text.y = element_markdown(\n      size = rel(0.85), family = fonts$subtitle,\n      color = \"gray40\"\n    ),\n\n    # Grid lines\n    panel.grid.minor = element_line(color = \"#ecf0f1\", linewidth = 0.2),\n    panel.grid.major = element_line(color = \"#ecf0f1\", linewidth = 0.4),\n\n    # Margin\n    plot.margin = margin(20, 20, 20, 20)\n  )\n)\n\n# Set theme\ntheme_set(weekly_theme)\n```\n\n\n6. Plot\n\nShow code```{r}\n#| label: plot\n#| warning: false\n\n### |-  p1: cummulative growth ----\np1 &lt;-\n  ggplot(cumulative_data, aes(first_year, cumulative)) +\n  # Geoms\n  geom_area(fill = colors$palette$leadership, alpha = 0.1) +\n  geom_line(color = colors$palette$leadership, linewidth = 1.2) +\n  geom_point(data = m50, color = colors$palette$leadership, size = 2) +\n  geom_point(data = latest_val, color = colors$palette$leadership, size = 3) +\n  # Annotate\n  annotate(\"richtext\",\n    x = 1990, y = 62, label = \"50th reached&lt;br&gt;in **2000**\",\n    fill = NA, label.color = NA, family = fonts$text, size = 3.5\n  ) +\n  annotate(\"text\",\n    x = 2024, y = 108, label = \"103 Unique\\nConductors\",\n    fontface = \"bold\", color = colors$leadership, family = fonts$text, hjust = 1, lineheight = 0.9\n  ) +\n  # Scales\n  scale_x_continuous(limits = c(1954, 2025), breaks = seq(1960, 2020, 20)) +\n  scale_y_continuous(limits = c(0, 115), breaks = seq(0, 100, 25)) +\n  # Labs\n  labs(title = \"Cumulative Growth\", x = NULL, y = NULL) +\n  # Theme\n  theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank())\n\n### |-  p2: role mix ----\n# label data\nlabel_data &lt;- role_era_stats |&gt;\n  arrange(era_label, desc(tier)) |&gt;\n  group_by(era_label) |&gt;\n  mutate(\n    cumsum_pct = cumsum(pct),\n    label_pos = cumsum_pct - pct / 2,\n    # Color logic: Light bars get dark text\n    label_col = if_else(tier %in% c(\"Specialized\", \"Supplemental\"), colors$text, \"white\"),\n    # Label logic: Direct legend for top bar, % only for others if &gt; 7%\n    display_label = case_when(\n      str_detect(era_label, \"2020\") ~ glue(\"**{percent(pct, 1)}**&lt;br&gt;{tier}\"),\n      pct &gt;= 0.08 ~ glue(\"**{percent(pct, 1)}**\"),\n      TRUE ~ \"\"\n    )\n  )\n\np2 &lt;-\nggplot(role_era_stats, aes(era_label, pct, fill = tier)) +\n  # Geoms\n  geom_col(width = 0.7, color = \"white\", linewidth = 0.2) +\n  geom_richtext(data = label_data,\n                aes(y = label_pos, label = display_label, color = label_col),\n                fill = NA, label.color = NA, family = fonts$text, size = 3, lineheight = 1) +\n  # Scales\n  scale_fill_manual(values = tier_colors) +\n  scale_color_identity() +\n  scale_y_continuous(labels = percent_format(), expand = c(0, 0)) +\n  coord_flip() +\n  # Labs\n  labs(title = \"Role Mix by Era\", x = NULL, y = NULL) +\n  # theme_minimal(base_family = fonts$text) +\n  # Theme\n  theme(\n    legend.position = \"none\", \n    panel.grid = element_blank(),\n    axis.text.y = element_markdown(lineheight = 1.1)\n    )\n\n### |-  combined plot ----\ncombined_plot &lt;- p1 + p2 +\n  plot_layout(widths = c(1, 1.15)) +\n  plot_annotation(\n    title = title_text,\n    subtitle = subtitle_text,\n    caption = caption_text,\n    theme = theme(\n      plot.title = element_text(\n        size = rel(1.8),\n        family = fonts$title,\n        face = \"bold\",\n        color = colors$title,\n        lineheight = 1.15,\n        margin = margin(t = 5, b = 10)\n      ),\n      plot.subtitle = element_markdown(\n        size = rel(0.75),\n        family = fonts$subtitle,\n        color = alpha(colors$subtitle, 0.88),\n        lineheight = 1.5,\n        margin = margin(t = 5, b = 10)\n      ),\n      plot.caption = element_markdown(\n        size = rel(0.55),\n        family = fonts$subtitle,\n        color = colors$caption,\n        hjust = 0,\n        lineheight = 1.4,\n        margin = margin(t = 20, b = 5)\n      ),\n    )\n  )\n```\n\n\n7. Save\n\nShow code```{r}\n#| label: save\n#| warning: false\n\n### |-  plot image ----  \nsave_plot_patchwork(\n  plot = combined_plot, \n  type = \"makeovermonday\", \n  year = current_year,\n  week = current_week,\n  width = 12, \n  height = 8\n  )\n```\n\n\n8. Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] here_1.0.1      readxl_1.4.3    janitor_2.2.0   patchwork_1.3.0\n [5] glue_1.8.0      scales_1.3.0    showtext_0.9-7  showtextdb_3.0 \n [9] sysfonts_0.8.9  ggtext_0.1.2    lubridate_1.9.3 forcats_1.0.0  \n[13] stringr_1.5.1   dplyr_1.1.4     purrr_1.0.2     readr_2.1.5    \n[17] tidyr_1.3.1     tibble_3.2.1    ggplot2_3.5.1   tidyverse_2.0.0\n[21] pacman_0.5.1   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6       xfun_0.49          htmlwidgets_1.6.4  tzdb_0.5.0        \n [5] yulab.utils_0.1.8  vctrs_0.6.5        tools_4.4.0        generics_0.1.3    \n [9] curl_6.0.0         gifski_1.32.0-1    fansi_1.0.6        pkgconfig_2.0.3   \n[13] ggplotify_0.1.2    skimr_2.1.5        lifecycle_1.0.4    compiler_4.4.0    \n[17] farver_2.1.2       munsell_0.5.1      repr_1.1.7         codetools_0.2-20  \n[21] snakecase_0.11.1   htmltools_0.5.8.1  yaml_2.3.10        pillar_1.9.0      \n[25] camcorder_0.1.0    magick_2.8.5       commonmark_1.9.2   tidyselect_1.2.1  \n[29] digest_0.6.37      stringi_1.8.4      labeling_0.4.3     rsvg_2.6.1        \n[33] rprojroot_2.0.4    fastmap_1.2.0      grid_4.4.0         colorspace_2.1-1  \n[37] cli_3.6.4          magrittr_2.0.3     base64enc_0.1-3    utf8_1.2.4        \n[41] withr_3.0.2        timechange_0.3.0   rmarkdown_2.29     cellranger_1.1.0  \n[45] hms_1.1.3          evaluate_1.0.1     knitr_1.49         markdown_1.13     \n[49] gridGraphics_0.5-1 rlang_1.1.6        gridtext_0.1.5     Rcpp_1.0.13-1     \n[53] xml2_1.3.6         renv_1.0.3         svglite_2.1.3      rstudioapi_0.17.1 \n[57] jsonlite_1.8.9     R6_2.5.1           fs_1.6.5           systemfonts_1.1.0 \n\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in mm_2026_03.qmd.\nFor the full repository, click here.\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\n\n\nData:\n\nMakeover Monday 2026 Week 3: Women+ Conductors on Broadway\n\n\n\n\nArticle\n\nWomen+ Conductors on Broadway\n\n\n\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\n\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\n\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\n\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n Back to topCitationBibTeX citation:@online{ponce2026,\n  author = {Ponce, Steven},\n  title = {The {Accelerating} {Rise} of {Women+} {Conductors} on\n    {Broadway}},\n  date = {2026-01-19},\n  url = {https://stevenponce.netlify.app/data_visualizations/MakeoverMonday/2026/mm_2026_03.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPonce, Steven. 2026. â€œThe Accelerating Rise of Women+ Conductors\non Broadway.â€ January 19, 2026. https://stevenponce.netlify.app/data_visualizations/MakeoverMonday/2026/mm_2026_03.html."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-23.html",
    "href": "projects/standalone_visualizations/sa_2026-01-23.html",
    "title": "Oh My God, Bob!",
    "section": "",
    "text": "FigureÂ 1: Data visualization titled â€˜Oh My God, Bob!â€™ analyzing 2,420 god-mentions across 16 seasons of Bobâ€™s Burgers. A treemap shows â€˜My Godâ€™ dominates at 56%, followed by â€˜Godâ€™ at 37% and â€˜Thank Godâ€™ at 5%. A bar chart ranks the most devout episodes, with S8E6 â€˜Bleakening Pts 1 & 2â€™ leading with 24 mentions.\n\n\nSteps to Create this Graphic\n1. Load Packages & Setup\n\nShow code```{r}\n#| label: load\n#| warning: false\n#| message: false\n#| results: \"hide\"\n\n## 1. LOAD PACKAGES & SETUP ----\nsuppressPackageStartupMessages({\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  tidyverse,         # Easily Install and Load the 'Tidyverse'\n  ggtext,            # Improved Text Rendering Support for 'ggplot2'\n  showtext,          # Using Fonts More Easily in R Graphs\n  janitor,           # Simple Tools for Examining and Cleaning Dirty Data\n  skimr,             # Compact and Flexible Summaries of Data\n  scales,            # Scale Functions for Visualization\n  glue,              # Interpreted String Literals\n  patchwork,         # The Composer of Plots\n  treemapify,        # Draw Treemaps in 'ggplot2'\n  bobsburgersR       # Bob's Burgers Datasets for Data Visualization\n)  \n})\n\n### |- figure size ----\ncamcorder::gg_record(\n  dir    = here::here(\"temp_plots\"),\n  device = \"png\",\n  width  = 14,\n  height = 9,\n  units  = \"in\",\n  dpi    = 320\n)\n\n# Source utility functions\nsuppressMessages(source(here::here(\"R/utils/fonts.R\")))\nsource(here::here(\"R/utils/social_icons.R\"))\nsource(here::here(\"R/utils/image_utils.R\"))\nsource(here::here(\"R/themes/base_theme.R\"))\n```\n\n\n2. Read in the Data\n\nShow code```{r}\n#| label: read\n#| include: true\n#| eval: true\n#| warning: false\n\ntranscript_data &lt;- bobsburgersR::transcript_data\n```\n\n\n3. Examine the Data\n\nShow code```{r}\n#| label: examine\n#| include: true\n#| eval: true\n#| results: 'hide'\n#| warning: false\n\nglimpse(transcript_data)\nskim_without_charts(transcript_data)\n```\n\n\n4. Tidy Data\n\nShow code```{r}\n#| label: tidy-fixed\n#| warning: false\n\n# Filter for \"god\" mentions\ngod_mentions &lt;- transcript_data |&gt;\n  filter(\n    str_detect(raw_text, regex(\"\\\\bgod\\\\b|\\\\bgods\\\\b|goddamn\", ignore_case = TRUE)),\n    !str_detect(raw_text, regex(\"godfather|godmother|godparent|godchild\", ignore_case = TRUE))\n  ) |&gt;\n  mutate(\n    type = if_else(is.na(dialogue), \"Sound Effect\", \"Spoken\"),\n    dialogue_clean = coalesce(dialogue, raw_text)\n  )\n\n# Categorize god mentions\ngod_categorized &lt;- god_mentions |&gt;\n  mutate(\n    god_type = case_when(\n      str_detect(raw_text, regex(\"oh my god\", ignore_case = TRUE)) ~ \"Oh My God\",\n      str_detect(raw_text, regex(\"for god'?s sake\", ignore_case = TRUE)) ~ \"For God's Sake\",\n      str_detect(raw_text, regex(\"god damn|goddamn\", ignore_case = TRUE)) ~ \"Goddamn\",\n      str_detect(raw_text, regex(\"thank god\", ignore_case = TRUE)) ~ \"Thank God\",\n      str_detect(raw_text, regex(\"dear god\", ignore_case = TRUE)) ~ \"Dear God\",\n      str_detect(raw_text, regex(\"good god\", ignore_case = TRUE)) ~ \"Good God\",\n      str_detect(raw_text, regex(\"oh god\", ignore_case = TRUE)) ~ \"Oh God\",\n      str_detect(raw_text, regex(\"my god\", ignore_case = TRUE)) ~ \"My God\",\n      str_detect(raw_text, regex(\"\\\\bgod\\\\b\", ignore_case = TRUE)) ~ \"God\",\n      TRUE ~ \"Other\"\n    )\n  )\n\n# Summary stats\ntotal_mentions &lt;- nrow(god_categorized)\ntotal_seasons &lt;- n_distinct(god_categorized$season)\n\n# Lexicon breakdown\ngod_lexicon &lt;- god_categorized |&gt;\n  count(god_type, sort = TRUE) |&gt;\n  mutate(pct = n / sum(n))\n\n# Top episodes\ntop_episodes &lt;- god_categorized |&gt;\n  count(season, episode, title, sort = TRUE) |&gt;\n  head(10)\n\n# Most devout episodes data\ntop_eps_plot &lt;- top_episodes |&gt;\n  head(6) |&gt;\n  mutate(\n    ep_label = glue(\"S{season}E{episode}\"),\n    title_short = str_trunc(title, 34),\n    full_label = glue(\"{ep_label}:\\n{title_short}\"),\n    full_label = fct_reorder(full_label, n),\n    is_top = n == max(n)\n  )\n```\n\n\n5. Visualization Parameters\n\nShow code```{r}\n#| label: params\n#| include: true\n#| warning: false\n\n### |-  plot aesthetics ----\ncolors &lt;- get_theme_colors(\n  palette = list(\n    yellow     = \"#D4A03C\",\n    green      = \"#94994a\",\n    red        = \"#b85244\",\n    blue       = \"#8db8e2\",\n    gray_light = \"#D3D3D3\",\n    black      = \"#2B2B2B\",\n    gray       = \"#5A5A5A\",\n    light_gray = \"#9A9A9A\",\n    off_white  = \"#FAF9F6\"\n  )\n)\n\n### |- titles and caption ----\ntitle_text &lt;- \"Oh My God, Bob!\"\n\nsubtitle_text &lt;- str_glue(\n  \"\\\"My God\\\" accounts for 56% of 2,420 god-mentions across 16 seasons of Bob's Burgers\"\n)\n\ncaption_text &lt;- create_standalone_caption(                       \n  source_text = \"{ bobsburgersR } v0.2.0 (transcripts)\"\n)\n\n### |-  fonts ----\nsetup_fonts()\nfonts &lt;- get_font_families()\n\n### |-  plot theme ----\n# Start with base theme\nbase_theme &lt;- create_base_theme(colors)\n\n# Add weekly-specific theme elements\nweekly_theme &lt;- extend_weekly_theme(\n  base_theme,\n  theme(\n    # Text styling\n    plot.title = element_text(\n      face = \"bold\", family = fonts$title, size = rel(1.4),        \n      color = colors$title, margin = margin(b = 10), hjust = 0\n    ),\n    plot.subtitle = element_text(\n      face = \"italic\", family = fonts$subtitle, lineheight = 1.2,\n      color = colors$subtitle, size = rel(0.85), margin = margin(b = 20), hjust = 0    \n    ),\n    \n    # Grid\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major = element_line(color = \"gray90\", linewidth = 0.25),\n    \n    # Axes\n    axis.title = element_text(size = rel(0.8), color = \"gray30\"),\n    axis.text = element_text(color = \"gray30\"),\n    axis.text.y = element_text(size = rel(0.85)),\n    axis.ticks = element_blank(),\n    \n    # Facets\n    strip.background = element_rect(fill = \"gray95\", color = NA),\n    strip.text = element_text(\n      face = \"bold\",\n      color = \"gray20\",\n      size = rel(0.9),\n      margin = margin(t = 6, b = 4)\n    ),\n    panel.spacing = unit(1.5, \"lines\"),\n    \n    # Legend elements\n    legend.position = \"plot\",\n    legend.title = element_text(\n      family = fonts$subtitle,\n      color = colors$text, size = rel(0.8), face = \"bold\"\n    ),\n    legend.text = element_text(\n      family = fonts$tsubtitle,\n      color = colors$text, size = rel(0.7)\n    ),\n    legend.margin = margin(t = 15),\n    \n    # Plot margin\n    plot.margin = margin(10, 20, 10, 20),\n    \n  )\n)\n\n# Set theme\ntheme_set(weekly_theme)\n```\n\n\n6. Plot\n\nShow code```{r}\n#| label: plot\n#| warning: false\n\n# P1: KPI \np1 &lt;- ggplot() +\n  # KPI 1: Total mentions\n  annotate(\"text\",\n    x = 1, y = 1.1, label = comma(total_mentions),\n    size = 14, fontface = \"bold\", family = \"title\", color = colors$palette$green\n  ) +\n  annotate(\"text\",\n    x = 1, y = 0.7, label = \"god-mentions\",\n    size = 4.5, family = \"text\", color = colors$palette$gray\n  ) +\n  # KPI 2: Champion episode\n  annotate(\"text\",\n    x = 3, y = 1.1, label = \"S8E6\",\n    size = 12, fontface = \"bold\", family = \"title\", color = colors$palette$green\n  ) +\n  annotate(\"text\",\n    x = 3, y = 0.7, label = \"top episode (24 mentions)\",\n    size = 4.5, family = \"text\", color = colors$palette$gray\n  ) +\n  # KPI 3: Line 1 Club\n  annotate(\"text\",\n    x = 5, y = 1.1, label = \"4\",\n    size = 14, fontface = \"bold\", family = \"title\", color = colors$palette$green\n  ) +\n  annotate(\"text\",\n    x = 5, y = 0.7, label = \"episodes open with 'god'\",\n    size = 4.5, family = \"text\", color = colors$palette$gray\n  ) +\n  xlim(0, 6) +\n  ylim(0.4, 1.4) +\n  theme_void() +\n  theme(\n    plot.background = element_rect(fill = colors$palette$off_white, color = NA),\n    plot.margin = margin(10, 20, 5, 20)\n  )\n\n# P2: treemap\n# treemap data\ntreemap_data &lt;- god_lexicon |&gt;\n  filter(god_type != \"Other\") |&gt;\n  mutate(\n    label_full = paste0(god_type, \"\\n\", percent(pct, accuracy = 1)),\n    # Only show label if &gt;= 3%\n    label_display = if_else(pct &gt;= 0.03, label_full, \"\"),\n    # Color assignment - gray for small categories\n    fill_color = case_when(\n      god_type == \"My God\" ~ colors$palette$green,\n      god_type == \"God\" ~ colors$palette$yellow,\n      god_type == \"Thank God\" ~ colors$palette$red,\n      TRUE ~ colors$palette$gray_light\n    )\n  )\n\ntreemap_colors &lt;- setNames(treemap_data$fill_color, treemap_data$god_type)\n\np2 &lt;- treemap_data |&gt;\n  ggplot(aes(area = n, fill = god_type, label = label_display)) +\n  geom_treemap(color = \"white\", size = 2) +\n  geom_treemap_text(\n    family = \"text\",\n    color = \"white\",\n    place = \"centre\",\n    size = 14,\n    fontface = \"bold\",\n    min.size = 4\n  ) +\n  scale_fill_manual(values = treemap_colors) +\n  labs(\n    title = \"The God Lexicon\",\n    subtitle = \"\\\"My God\\\" dominates at 56% of all mentions\"\n  )\n\n# P3: Most devout episodes\np3 &lt;- top_eps_plot |&gt;\n  ggplot(aes(x = n, y = full_label)) +\n  geom_col(aes(fill = is_top), width = 0.75, show.legend = FALSE) +\n  geom_text(\n    aes(\n      label = if_else(is_top, glue(\"{ n } *\"), as.character(n)),\n      fontface = if_else(is_top, \"bold\", \"plain\"),\n    ),\n    hjust = -0.2,\n    size = 3.8,\n    family = \"text\",\n    color = colors$palette$gray\n  ) +\n  scale_fill_manual(values = c(\"TRUE\" = colors$palette$green, \"FALSE\" = colors$palette$yellow)) +\n  scale_x_continuous(expand = expansion(mult = c(0, 0.12))) +\n  labs(\n    title = \"Most Devout Episodes\",\n    subtitle = \"Episodes with the most god-mentions\",\n    x = \"Mentions\",\n    y = NULL\n  )\n\n# Combine: Final Layout\ncombined_plot &lt;-\n  p1 / (p2 | p3) +\n  plot_layout(heights = c(0.25, 1))\n\ncombined_plot &lt;- combined_plot +\n  plot_annotation(\n    title = title_text,\n    subtitle = subtitle_text,\n    caption = caption_text,\n  theme = theme(\n    plot.title = element_text(\n      size = rel(2.14),\n      family = fonts$title,\n      face = \"bold\",\n      color = colors$title,\n      lineheight = 1.15,\n      margin = margin(t = 5, b = 5)\n    ),\n    plot.subtitle = element_text(\n      size = rel(1.0),\n      family = fonts$subtitle,\n      color = colors$subtitle,\n      lineheight = 1.5,\n      margin = margin(t = 5, b = 15)\n    ),\n    plot.caption = element_markdown(\n      size = rel(0.65),\n      family = fonts$subtitle,\n      color = colors$caption,\n      hjust = 0,\n      lineheight = 1.4,\n      margin = margin(t = 20, b = 5)\n    ),\n    plot.margin = margin(12, 18, 10, 18)\n  )\n)\n```\n\n\n7. Save\n\nShow code```{r}\n#| label: save\n#| warning: false\n\n### |-  plot image ----  \nsave_plot_patchwork(\n  plot = combined_plot, \n  type = \"standalone\", \n  year = 2026,\n  width  = 14,\n  height = 9,\n  )\n```\n\n\n8. Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] here_1.0.1         bobsburgersR_0.2.0 treemapify_2.5.6   patchwork_1.3.0   \n [5] glue_1.8.0         scales_1.3.0       skimr_2.1.5        janitor_2.2.0     \n [9] showtext_0.9-7     showtextdb_3.0     sysfonts_0.8.9     ggtext_0.1.2      \n[13] lubridate_1.9.3    forcats_1.0.0      stringr_1.5.1      dplyr_1.1.4       \n[17] purrr_1.0.2        readr_2.1.5        tidyr_1.3.1        tibble_3.2.1      \n[21] ggplot2_3.5.1      tidyverse_2.0.0    pacman_0.5.1      \n\nloaded via a namespace (and not attached):\n [1] ggfittext_0.10.2   gtable_0.3.6       xfun_0.49          htmlwidgets_1.6.4 \n [5] tzdb_0.5.0         yulab.utils_0.1.8  vctrs_0.6.5        tools_4.4.0       \n [9] generics_0.1.3     curl_6.0.0         gifski_1.32.0-1    fansi_1.0.6       \n[13] pkgconfig_2.0.3    ggplotify_0.1.2    lifecycle_1.0.4    compiler_4.4.0    \n[17] farver_2.1.2       munsell_0.5.1      repr_1.1.7         codetools_0.2-20  \n[21] snakecase_0.11.1   htmltools_0.5.8.1  yaml_2.3.10        pillar_1.9.0      \n[25] camcorder_0.1.0    magick_2.8.5       commonmark_1.9.2   tidyselect_1.2.1  \n[29] digest_0.6.37      stringi_1.8.4      labeling_0.4.3     rsvg_2.6.1        \n[33] rprojroot_2.0.4    fastmap_1.2.0      grid_4.4.0         colorspace_2.1-1  \n[37] cli_3.6.4          magrittr_2.0.3     base64enc_0.1-3    utf8_1.2.4        \n[41] withr_3.0.2        timechange_0.3.0   rmarkdown_2.29     hms_1.1.3         \n[45] evaluate_1.0.1     knitr_1.49         markdown_1.13      gridGraphics_0.5-1\n[49] rlang_1.1.6        gridtext_0.1.5     Rcpp_1.0.13-1      xml2_1.3.6        \n[53] renv_1.0.3         svglite_2.1.3      rstudioapi_0.17.1  jsonlite_1.8.9    \n[57] R6_2.5.1           fs_1.6.5           systemfonts_1.1.0 \n\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in sa_2026-01-23.qmd.\nFor the full repository, click here.\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\n\n\nData Source:\n\nbobsburgersR R Package v0.2.0: GitHub Repository\n\nTranscript Data: Springfield! Springfield!\n\n\n\n\nBobâ€™s Burgers:\n\nOfficial Show Page: FOX - Bobâ€™s Burgers\n\nWikipedia: Bobâ€™s Burgers Episode List\n\n\n\n\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\n\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\n\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\n\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n Back to topCitationBibTeX citation:@online{ponce2026,\n  author = {Ponce, Steven},\n  title = {Oh {My} {God,} {Bob!}},\n  date = {2026-01-23},\n  url = {https://stevenponce.netlify.app/projects/standalone_visualizations/sa_2026-01-23.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPonce, Steven. 2026. â€œOh My God, Bob!â€ January 23, 2026. https://stevenponce.netlify.app/projects/standalone_visualizations/sa_2026-01-23.html."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-23.html#framing-the-problem",
    "href": "projects/standalone_visualizations/sa_2026-01-23.html#framing-the-problem",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "1. Framing the problem",
    "text": "1. Framing the problem\nForecasting clinical trial timelines is an appealing problem in pharmaceutical analytics. Timelines influence portfolio planning, resourcing, and cross-functional expectations across R&D organizations. At the same time, experienced trial teams recognize that duration is shaped by factors that are difficult to observe earlyâ€”protocol complexity, enrollment dynamics, site performance, and evolving standards of care.\nThis project approaches trial duration forecasting as a validation problem first, rather than an optimization exercise. The objective is not to produce an operational forecasting tool, but to evaluate what level of prospective signal is realistically supported by publicly available registry data."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-23.html#what-question-this-analysis-tests",
    "href": "projects/standalone_visualizations/sa_2026-01-23.html#what-question-this-analysis-tests",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "2. What question this analysis tests",
    "text": "2. What question this analysis tests\nThe core question is intentionally narrow:\nCan ClinicalTrials.gov registry features support prospective forecasting of oncology trial duration?\nTo answer this, I built an end-to-end modeling pipeline and Shiny dashboard using completed oncology treatment trials. The target variable is registry-defined duration (Start Date â†’ Completion Date), which may include extended follow-up and should not be interpreted as a direct proxy for last-patientâ€“last-visit (LPLV); predictors are limited to information available in the registry at study start.\nThe emphasis is on aligning validation strategy with intended use, rather than maximizing retrospective fit."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-23.html#when-random-validation-appears-convincing",
    "href": "projects/standalone_visualizations/sa_2026-01-23.html#when-random-validation-appears-convincing",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "3. When random validation appears convincing",
    "text": "3. When random validation appears convincing\nUsing a conventional random train/test split, the model appeared to perform well:\n\nRÂ² â‰ˆ 0.84\n\nMedian absolute error â‰ˆ 7 months\n\nAt face value, this resembles performance often reported in exploratory analytics. However, random splits implicitly allow information from later-era trials to influence predictions for earlier-era trials. For a forward-looking use case, this validation strategy is inappropriate.\nAt this stage, the model was answering the wrong question."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-23.html#what-changes-under-time-based-validation",
    "href": "projects/standalone_visualizations/sa_2026-01-23.html#what-changes-under-time-based-validation",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "4. What changes under time-based validation",
    "text": "4. What changes under time-based validation\nWhen the validation strategy was changed to reflect prospective useâ€”training on earlier trials and testing on later trialsâ€”performance dropped sharply:\n\n\n\nValidation Approach\nTest RÂ²\nMedian Absolute Error\n\n\n\n\nRandom split\n0.84\n7 months\n\n\nTime-based split\n0.04\n21 months\n\n\n\nThis result reflects two structural realities:\n\nTemporal drift: Median trial duration decreased substantially across eras, meaning relationships learned from earlier trials do not generalize cleanly to later ones.\nRegistry feature limitations: Key drivers of durationâ€”protocol complexity, endpoint strategy, enrollment velocity, and operational executionâ€”are largely absent from ClinicalTrials.gov.\n\nUnder these conditions, low prospective RÂ² is not a modeling failure; it is the most honest estimate the data can provide."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-23.html#why-this-matters-in-pharma-analytics",
    "href": "projects/standalone_visualizations/sa_2026-01-23.html#why-this-matters-in-pharma-analytics",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "5. Why this matters in pharma analytics",
    "text": "5. Why this matters in pharma analytics\nIn pharmaceutical decision-making, forecasts are used prospectively: to inform planning, resource allocation, and expectations. Validation strategies that mix past and future data can materially overstate confidence and lead to incorrect conclusions.\nThis case study demonstrates that how a model is validated matters more than which algorithm is chosen. A model that performs well retrospectively but fails under time-based testing may still be useful diagnosticallyâ€”but it should not be positioned as a forecasting tool.\nFrom an analytics governance perspective, this distinction is critical."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-23.html#what-this-project-doesand-does-notclaim",
    "href": "projects/standalone_visualizations/sa_2026-01-23.html#what-this-project-doesand-does-notclaim",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "6. What this project doesâ€”and does notâ€”claim",
    "text": "6. What this project doesâ€”and does notâ€”claim\nThis project demonstrates:\n\nHow to design validation strategies that align with prospective use\nHow temporal drift can invalidate apparently strong models\nHow registry-only features constrain forecasting power\n\nIt explicitly does not claim:\n\nThat oncology trial duration is predictable from registry data alone\nThat this model should be used for operational timeline planning\nThat algorithmic complexity would resolve the observed limitations\n\nThe results are conditional on the data sources and features used."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-23.html#what-would-be-required-for-planning-grade-forecasting",
    "href": "projects/standalone_visualizations/sa_2026-01-23.html#what-would-be-required-for-planning-grade-forecasting",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "7. What would be required for planning-grade forecasting",
    "text": "7. What would be required for planning-grade forecasting\nIf the objective were operational forecasting, additional data would be required, including:\n\nProtocol complexity and amendment history\nEndpoint structure and follow-up requirements\nEnrollment trajectory and screen-failure dynamics\nSite and geography-level performance history\nCompetitive and standard-of-care context\n\nThese factors are typically available only through internal systems, not public registries."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-23.html#dashboard-preview",
    "href": "projects/standalone_visualizations/sa_2026-01-23.html#dashboard-preview",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "Dashboard Preview",
    "text": "Dashboard Preview\n\nThe dashboard is structured to make validation behavior visible and to discourage overinterpretation of point predictions.\n\nExecutive Brief Surfaces key metrics (RÂ², MAE, sample size) with appropriate caveats about prospective use limitations. \nDuration Forecaster Interactive scenario sandbox for exploring how trial characteristics relate to predicted durationâ€”positioned as educational, not operational. \nFeature Explorer Visualizes Elastic Net coefficients and feature distributions to understand which registry variables the model weighted. \nModel Performance Diagnostic plots comparing actual vs.Â predicted duration, with error breakdown by phase and sponsor type. \nMethods & Data Documents the data pipeline, inclusion criteria, and validation methodologyâ€”including the key lesson on why time-based validation matters."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-23.html#appendix-methodology-build-notes",
    "href": "projects/standalone_visualizations/sa_2026-01-23.html#appendix-methodology-build-notes",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "Appendix: Methodology & Build Notes",
    "text": "Appendix: Methodology & Build Notes\n\nAnalytical Pipeline\n\nData acquisition â€“ ClinicalTrials.gov API (oncology interventional trials)\nCohort filtering â€“ Treatment purpose, Phase 2â€“3, completed studies\nFeature engineering â€“ Log transforms, ratios, categorical encoding\nValidation design â€“ Time-based split aligned to prospective use\nModeling â€“ Elastic Net regression via tidymodels\nDiagnostics â€“ Error analysis and residual inspection\n\n\n\nModel specification\n\nAlgorithm: Elastic Net (glmnet)\nTarget: Log-transformed duration (months)\nCross-validation: 10-fold CV within training data only\nBaseline comparisons: Linear regression, Random Forest, XGBoost\nSelection criterion: Stability, interpretability, and behavior under time-based validation\n\n\n\nTechnical stack\n\nLanguage: R\nFramework: Shiny (modular architecture)\nUI: shiny.semantic (Appsilon)\nModeling: tidymodels\nVisualization: ggplot2, ggiraph, reactable\nDeployment: shinyapps.io\n\n\n\nReferences\n\nClinicalTrials.gov â€“ U.S. National Library of Medicine\nTidymodels documentation â€“ https://www.tidymodels.org/\nAppsilon shiny.semantic â€“ https://appsilon.github.io/shiny.semantic/\nWong, C.H., Siah, K.W., & Lo, A.W. (2019). Estimation of clinical trial success rates and related parameters. Biostatistics, 20(2), 273â€“286."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-23.html#closing-reflection",
    "href": "projects/standalone_visualizations/sa_2026-01-23.html#closing-reflection",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "Closing reflection",
    "text": "Closing reflection\n\n\n\n\n\n\nNote\n\n\n\nThe most important outcome of this project is not a performance metric, but a methodological lesson: honest validation protects decision-makers from false confidence.\nIn trial analytics, recognizing the limits of available data is as important as extracting signal from it."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-19.html",
    "href": "projects/standalone_visualizations/sa_2026-01-19.html",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "",
    "text": "ðŸš€ Live App:\nClinical Trial Duration Forecaster\nðŸ’» Source Code:\nGitHub repository"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-19.html#framing-the-problem",
    "href": "projects/standalone_visualizations/sa_2026-01-19.html#framing-the-problem",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "1. Framing the problem",
    "text": "1. Framing the problem\nForecasting clinical trial timelines is an appealing problem in pharmaceutical analytics. Timelines influence portfolio planning, resourcing, and cross-functional expectations across R&D organizations. At the same time, experienced trial teams recognize that duration is shaped by factors that are difficult to observe earlyâ€”protocol complexity, enrollment dynamics, site performance, and evolving standards of care.\nThis project approaches trial duration forecasting as a validation problem first, rather than an optimization exercise. The objective is not to produce an operational forecasting tool, but to evaluate what level of prospective signal is realistically supported by publicly available registry data."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-19.html#what-question-this-analysis-tests",
    "href": "projects/standalone_visualizations/sa_2026-01-19.html#what-question-this-analysis-tests",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "2. What question this analysis tests",
    "text": "2. What question this analysis tests\nThe core question is intentionally narrow:\nCan ClinicalTrials.gov registry features support prospective forecasting of oncology trial duration?\nTo answer this, I built an end-to-end modeling pipeline and Shiny dashboard using completed oncology treatment trials. The target variable is registry-defined duration (Start Date â†’ Completion Date), which may include extended follow-up and should not be interpreted as a direct proxy for last-patientâ€“last-visit (LPLV); predictors are limited to information available in the registry at study start.\nThe emphasis is on aligning validation strategy with intended use, rather than maximizing retrospective fit."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-19.html#when-random-validation-appears-convincing",
    "href": "projects/standalone_visualizations/sa_2026-01-19.html#when-random-validation-appears-convincing",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "3. When random validation appears convincing",
    "text": "3. When random validation appears convincing\nUsing a conventional random train/test split, the model appeared to perform well:\n\nRÂ² â‰ˆ 0.84\n\nMedian absolute error â‰ˆ 7 months\n\nAt face value, this resembles performance often reported in exploratory analytics. However, random splits implicitly allow information from later-era trials to influence predictions for earlier-era trials. For a forward-looking use case, this validation strategy is inappropriate.\nAt this stage, the model was answering the wrong question."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-19.html#what-changes-under-time-based-validation",
    "href": "projects/standalone_visualizations/sa_2026-01-19.html#what-changes-under-time-based-validation",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "4. What changes under time-based validation",
    "text": "4. What changes under time-based validation\nWhen the validation strategy was changed to reflect prospective useâ€”training on earlier trials and testing on later trialsâ€”performance dropped sharply:\n\n\n\nValidation Approach\nTest RÂ²\nMedian Absolute Error\n\n\n\n\nRandom split\n0.84\n7 months\n\n\nTime-based split\n0.04\n21 months\n\n\n\nThis result reflects two structural realities:\n\nTemporal drift: Median trial duration decreased substantially across eras, meaning relationships learned from earlier trials do not generalize cleanly to later ones.\nRegistry feature limitations: Key drivers of durationâ€”protocol complexity, endpoint strategy, enrollment velocity, and operational executionâ€”are largely absent from ClinicalTrials.gov.\n\nUnder these conditions, low prospective RÂ² is not a modeling failure; it is the most honest estimate the data can provide."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-19.html#why-this-matters-in-pharma-analytics",
    "href": "projects/standalone_visualizations/sa_2026-01-19.html#why-this-matters-in-pharma-analytics",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "5. Why this matters in pharma analytics",
    "text": "5. Why this matters in pharma analytics\nIn pharmaceutical decision-making, forecasts are used prospectively: to inform planning, resource allocation, and expectations. Validation strategies that mix past and future data can materially overstate confidence and lead to incorrect conclusions.\nThis case study demonstrates that how a model is validated matters more than which algorithm is chosen. A model that performs well retrospectively but fails under time-based testing may still be useful diagnosticallyâ€”but it should not be positioned as a forecasting tool.\nFrom an analytics governance perspective, this distinction is critical."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-19.html#what-this-project-doesand-does-notclaim",
    "href": "projects/standalone_visualizations/sa_2026-01-19.html#what-this-project-doesand-does-notclaim",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "6. What this project doesâ€”and does notâ€”claim",
    "text": "6. What this project doesâ€”and does notâ€”claim\nThis project demonstrates:\n\nHow to design validation strategies that align with prospective use\nHow temporal drift can invalidate apparently strong models\nHow registry-only features constrain forecasting power\n\nIt explicitly does not claim:\n\nThat oncology trial duration is predictable from registry data alone\nThat this model should be used for operational timeline planning\nThat algorithmic complexity would resolve the observed limitations\n\nThe results are conditional on the data sources and features used."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-19.html#what-would-be-required-for-planning-grade-forecasting",
    "href": "projects/standalone_visualizations/sa_2026-01-19.html#what-would-be-required-for-planning-grade-forecasting",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "7. What would be required for planning-grade forecasting",
    "text": "7. What would be required for planning-grade forecasting\nIf the objective were operational forecasting, additional data would be required, including:\n\nProtocol complexity and amendment history\nEndpoint structure and follow-up requirements\nEnrollment trajectory and screen-failure dynamics\nSite and geography-level performance history\nCompetitive and standard-of-care context\n\nThese factors are typically available only through internal systems, not public registries."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-19.html#dashboard-preview",
    "href": "projects/standalone_visualizations/sa_2026-01-19.html#dashboard-preview",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "Dashboard Preview",
    "text": "Dashboard Preview\n\nThe dashboard is structured to make validation behavior visible and to discourage overinterpretation of point predictions.\n\nExecutive Brief Surfaces key metrics (RÂ², MAE, sample size) with appropriate caveats about prospective use limitations. \nDuration Forecaster Interactive scenario sandbox for exploring how trial characteristics relate to predicted durationâ€”positioned as educational, not operational. \nFeature Explorer Visualizes Elastic Net coefficients and feature distributions to understand which registry variables the model weighted. \nModel Performance Diagnostic plots comparing actual vs.Â predicted duration, with error breakdown by phase and sponsor type. \nMethods & Data Documents the data pipeline, inclusion criteria, and validation methodologyâ€”including the key lesson on why time-based validation matters."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-19.html#appendix-methodology-build-notes",
    "href": "projects/standalone_visualizations/sa_2026-01-19.html#appendix-methodology-build-notes",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "Appendix: Methodology & Build Notes",
    "text": "Appendix: Methodology & Build Notes\n\nAnalytical Pipeline\n\nData acquisition â€“ ClinicalTrials.gov API (oncology interventional trials)\nCohort filtering â€“ Treatment purpose, Phase 2â€“3, completed studies\nFeature engineering â€“ Log transforms, ratios, categorical encoding\nValidation design â€“ Time-based split aligned to prospective use\nModeling â€“ Elastic Net regression via tidymodels\nDiagnostics â€“ Error analysis and residual inspection\n\n\n\nModel specification\n\nAlgorithm: Elastic Net (glmnet)\nTarget: Log-transformed duration (months)\nCross-validation: 10-fold CV within training data only\nBaseline comparisons: Linear regression, Random Forest, XGBoost\nSelection criterion: Stability, interpretability, and behavior under time-based validation\n\n\n\nTechnical stack\n\nLanguage: R\nFramework: Shiny (modular architecture)\nUI: shiny.semantic (Appsilon)\nModeling: tidymodels\nVisualization: ggplot2, ggiraph, reactable\nDeployment: shinyapps.io\n\n\n\nReferences\n\nClinicalTrials.gov â€“ U.S. National Library of Medicine\nTidymodels documentation â€“ https://www.tidymodels.org/\nAppsilon shiny.semantic â€“ https://appsilon.github.io/shiny.semantic/\nWong, C.H., Siah, K.W., & Lo, A.W. (2019). Estimation of clinical trial success rates and related parameters. Biostatistics, 20(2), 273â€“286."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-19.html#closing-reflection",
    "href": "projects/standalone_visualizations/sa_2026-01-19.html#closing-reflection",
    "title": "Clinical Trial Duration Forecasting: A Validation-First Case Study",
    "section": "Closing reflection",
    "text": "Closing reflection\n\n\n\n\n\n\nNote\n\n\n\nThe most important outcome of this project is not a performance metric, but a methodological lesson: honest validation protects decision-makers from false confidence.\nIn trial analytics, recognizing the limits of available data is as important as extracting signal from it."
  },
  {
    "objectID": "projects/r_packages/2026-01-20-bobsburgersr-v0.2.0.html",
    "href": "projects/r_packages/2026-01-20-bobsburgersr-v0.2.0.html",
    "title": "bobsburgersR v0.2.0: Seasons 15-16 and TMDB Ratings",
    "section": "",
    "text": "Hex sticker for the bobsburgersR R package"
  },
  {
    "objectID": "projects/r_packages/2026-01-20-bobsburgersr-v0.2.0.html#bobsburgersr-v0.2.0-is-here",
    "href": "projects/r_packages/2026-01-20-bobsburgersr-v0.2.0.html#bobsburgersr-v0.2.0-is-here",
    "title": "bobsburgersR v0.2.0: Seasons 15-16 and TMDB Ratings",
    "section": "bobsburgersR v0.2.0 is Here!",
    "text": "bobsburgersR v0.2.0 is Here!\nIâ€™m excited to announce the release of bobsburgersR v0.2.0! This update brings the package up to date with seasons 15 and 16, expanding coverage to 309 episodes across all 16 seasons of Bobâ€™s Burgers."
  },
  {
    "objectID": "projects/r_packages/2026-01-20-bobsburgersr-v0.2.0.html#whats-new",
    "href": "projects/r_packages/2026-01-20-bobsburgersr-v0.2.0.html#whats-new",
    "title": "bobsburgersR v0.2.0: Seasons 15-16 and TMDB Ratings",
    "section": "Whatâ€™s New",
    "text": "Whatâ€™s New\nSeasons 15-16 Added\nThe dataset now includes the latest episodes, bringing the total from 275 to 309 episodes. Transcript data has also been updated to 204,027 lines of dialogue.\nNew Rating Source: TMDB\nThe most significant change in this release is the switch from IMDb to TMDB (The Movie Database) for episode ratings. IMDb implemented bot protection in 2024 that prevents web scraping, so I migrated to TMDBâ€™s official API.\nBoth rating systems use a 1-10 scale, but they come from different user communities. If youâ€™re comparing ratings across package versions, keep this in mind.\nStay tuned for a follow-up post where Iâ€™ll explore how these TMDB ratings compare across the showâ€™s 16-season history.\nNew Data Columns\nThe episode_data dataset now includes:\n\n\nvotes â€” Number of TMDB user votes for each episode\n\ntmdb_id â€” Unique TMDB episode identifier\n\nruntime â€” Episode length in minutes"
  },
  {
    "objectID": "projects/r_packages/2026-01-20-bobsburgersr-v0.2.0.html#breaking-changes",
    "href": "projects/r_packages/2026-01-20-bobsburgersr-v0.2.0.html#breaking-changes",
    "title": "bobsburgersR v0.2.0: Seasons 15-16 and TMDB Ratings",
    "section": "Breaking Changes",
    "text": "Breaking Changes\nDataset renamed: imdb_wikipedia_data is now episode_data. Update your code accordingly:\n# Old (no longer works)\ndata(\"imdb_wikipedia_data\")\n\n# New\ndata(\"episode_data\")\nColumn renamed: wikipedia_viewers is now us_viewers_millions for clarity.\nColumn renamed: imdb_title is now title."
  },
  {
    "objectID": "projects/r_packages/2026-01-20-bobsburgersr-v0.2.0.html#bug-fixes",
    "href": "projects/r_packages/2026-01-20-bobsburgersr-v0.2.0.html#bug-fixes",
    "title": "bobsburgersR v0.2.0: Seasons 15-16 and TMDB Ratings",
    "section": "Bug Fixes",
    "text": "Bug Fixes\nFixed carriage return characters (\\r) in transcript data for seasons 13-14 that caused display issues."
  },
  {
    "objectID": "projects/r_packages/2026-01-20-bobsburgersr-v0.2.0.html#installation",
    "href": "projects/r_packages/2026-01-20-bobsburgersr-v0.2.0.html#installation",
    "title": "bobsburgersR v0.2.0: Seasons 15-16 and TMDB Ratings",
    "section": "Installation",
    "text": "Installation\nInstall or update from GitHub:\n\nShow code```{r}\n#| label: install\n#| eval: false\n\n# install.packages(\"devtools\")\ndevtools::install_github(\"poncest/bobsburgersR\")\n```"
  },
  {
    "objectID": "projects/r_packages/2026-01-20-bobsburgersr-v0.2.0.html#quick-example",
    "href": "projects/r_packages/2026-01-20-bobsburgersr-v0.2.0.html#quick-example",
    "title": "bobsburgersR v0.2.0: Seasons 15-16 and TMDB Ratings",
    "section": "Quick Example",
    "text": "Quick Example\n\nShow code```{r}\n#| label: example\n#| eval: true\n\nlibrary(bobsburgersR)\nsuppressPackageStartupMessages(library(dplyr))\n\ndata(\"episode_data\")\n\n# Check the data\ncat(\"Total episodes:\", nrow(episode_data), \"\\n\")\ncat(\"Seasons:\", paste(range(episode_data$season), collapse = \"-\"), \"\\n\")\n\n# Average rating by season\nepisode_data |&gt;\n  group_by(season) |&gt;\n  summarise(\n    episodes = n(),\n    avg_rating = round(mean(rating, na.rm = TRUE), 1),\n    .groups = \"drop\"\n  ) |&gt;\n  print(n = 16)\n```\n\nTotal episodes: 309 \nSeasons: 1-16 \n# A tibble: 16 Ã— 3\n   season episodes avg_rating\n    &lt;int&gt;    &lt;int&gt;      &lt;dbl&gt;\n 1      1       13        7.4\n 2      2        9        7.7\n 3      3       23        7.7\n 4      4       22        7.5\n 5      5       21        8  \n 6      6       19        7.8\n 7      7       22        8  \n 8      8       21        8.2\n 9      9       22        7.9\n10     10       22        7.8\n11     11       22        7.8\n12     12       22        7  \n13     13       22        7.3\n14     14       16        7.4\n15     15       22        7.7\n16     16       11        7.1"
  },
  {
    "objectID": "projects/r_packages/2026-01-20-bobsburgersr-v0.2.0.html#whats-next",
    "href": "projects/r_packages/2026-01-20-bobsburgersr-v0.2.0.html#whats-next",
    "title": "bobsburgersR v0.2.0: Seasons 15-16 and TMDB Ratings",
    "section": "Whatâ€™s Next",
    "text": "Whatâ€™s Next\nIâ€™ll continue updating bobsburgersR as new episodes air. If you have suggestions or find issues, feel free to open an issue on GitHub.\n\nCheck out the full changelog in NEWS.md and explore the updated package on GitHub."
  },
  {
    "objectID": "projects/r_packages/2026-01-20-bobsburgersr-v0.2.0.html#session-info",
    "href": "projects/r_packages/2026-01-20-bobsburgersr-v0.2.0.html#session-info",
    "title": "bobsburgersR v0.2.0: Seasons 15-16 and TMDB Ratings",
    "section": "Session Info",
    "text": "Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\nShow code```{r}\n#| label: session-info\n#| eval: true\n\nsessionInfo()\n```\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n[1] dplyr_1.1.4        bobsburgersR_0.2.0\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.37     utf8_1.2.4        R6_2.5.1          codetools_0.2-20 \n [5] fastmap_1.2.0     tidyselect_1.2.1  xfun_0.49         magrittr_2.0.3   \n [9] glue_1.8.0        tibble_3.2.1      knitr_1.49        pkgconfig_2.0.3  \n[13] htmltools_0.5.8.1 generics_0.1.3    rmarkdown_2.29    lifecycle_1.0.4  \n[17] cli_3.6.4         fansi_1.0.6       vctrs_0.6.5       renv_1.0.3       \n[21] compiler_4.4.0    rstudioapi_0.17.1 tools_4.4.0       pillar_1.9.0     \n[25] evaluate_1.0.1    yaml_2.3.10       rlang_1.1.6       jsonlite_1.8.9   \n[29] htmlwidgets_1.6.4"
  },
  {
    "objectID": "projects/r_packages/2026-01-20-bobsburgersr-v0.2.0.html#github-repository",
    "href": "projects/r_packages/2026-01-20-bobsburgersr-v0.2.0.html#github-repository",
    "title": "bobsburgersR v0.2.0: Seasons 15-16 and TMDB Ratings",
    "section": "GitHub Repository",
    "text": "GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nAccess the bobsburgersR repository here"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-21.html",
    "href": "projects/standalone_visualizations/sa_2026-01-21.html",
    "title": "The Secret Sauce: Bobâ€™s Burgers Rating Trends?",
    "section": "",
    "text": "FigureÂ 1: Two-panel chart of Bobâ€™s Burgers TMDB ratings across 16 seasons. Top: season medians range 6.9â€“8.2, with Season 8 highest and Season 12 lowest. Bottom: heatmap of 309 episodes colored by deviation from season medianâ€”red below, gold above. White rings mark holiday episodes.\n\n\nSteps to Create this Graphic\n1. Load Packages & Setup\n\nShow code```{r}\n#| label: load\n#| warning: false\n#| message: false\n#| results: \"hide\"\n\n## 1. LOAD PACKAGES & SETUP ----\nsuppressPackageStartupMessages({\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  tidyverse,         # Easily Install and Load the 'Tidyverse'\n  ggtext,            # Improved Text Rendering Support for 'ggplot2'\n  showtext,          # Using Fonts More Easily in R Graphs\n  janitor,           # Simple Tools for Examining and Cleaning Dirty Data\n  skimr,             # Compact and Flexible Summaries of Data\n  scales,            # Scale Functions for Visualization\n  glue,              # Interpreted String Literals\n  patchwork,         # The Composer of Plots\n  bobsburgersR       # Bob's Burgers Datasets for Data Visualization\n)  \n})\n\n### |- figure size ----\ncamcorder::gg_record(\n  dir    = here::here(\"temp_plots\"),\n  device = \"png\",\n  width  = 8,\n  height = 12,\n  units  = \"in\",\n  dpi    = 320\n)\n\n# Source utility functions\nsuppressMessages(source(here::here(\"R/utils/fonts.R\")))\nsource(here::here(\"R/utils/social_icons.R\"))\nsource(here::here(\"R/utils/image_utils.R\"))\nsource(here::here(\"R/themes/base_theme.R\"))\n```\n\n\n2. Read in the Data\n\nShow code```{r}\n#| label: read\n#| include: true\n#| eval: true\n#| warning: false\n\nepisode_data &lt;- bobsburgersR::episode_data\n```\n\n\n3. Examine the Data\n\nShow code```{r}\n#| label: examine\n#| include: true\n#| eval: true\n#| results: 'hide'\n#| warning: false\n\nglimpse(episode_data)\nskim_without_charts(episode_data)\n```\n\n\n4. Tidy Data\n\nShow code```{r}\n#| label: tidy-fixed\n#| warning: false\n\n# Holiday detection\nholiday_pattern &lt;- \"(?i)Thanksgiving|Christmas|Halloween|Valentine\"\n\nepisodes &lt;- episode_data |&gt;\n  filter(!is.na(rating)) |&gt;\n  mutate(\n    season_num  = as.numeric(as.character(season)),\n    season = factor(season, levels = sort(unique(season_num))),\n    episode_num = as.numeric(as.character(episode)),\n    episode = factor(episode, levels = rev(sort(unique(episode_num)))),\n    is_holiday = str_detect(title, holiday_pattern)\n  )\n\n# Series median (all episodes)\nseries_median &lt;- median(episodes$rating, na.rm = TRUE)\n\n# Season medians (top panel)\nseason_medians &lt;- episodes |&gt;\n  group_by(season_num) |&gt;\n  summarise(median_rating = median(rating, na.rm = TRUE), .groups = \"drop\")\n\n# Clear label toggles ---\nlabel_mode &lt;- \"extremes\"     \ndev_label_cutoff &lt;- 0.9   \n\n# Season-relative deviations (bottom panel)\nheatmap_df &lt;- episodes |&gt;\n  group_by(season) |&gt;\n  mutate(\n    season_median = median(rating, na.rm = TRUE),\n    dev = rating - season_median\n  ) |&gt;\n  ungroup()\n\n# Data-driven dev limits  ---\ndev_limit &lt;- quantile(abs(heatmap_df$dev), 0.95, na.rm = TRUE)\ndev_limit &lt;- max(1.5, as.numeric(dev_limit))  \n\n# Label only meaningful deviations\nheatmap_df &lt;- heatmap_df |&gt;\n  mutate(\n    tile_label = case_when(\n      label_mode == \"all\" ~ as.character(round(rating, 1)),\n      label_mode == \"extremes\" & abs(dev) &gt;= dev_label_cutoff ~ as.character(round(rating, 1)),\n      TRUE ~ \"\"\n    )\n  )\n\n# Selective season labels: first, best, worst, last\nhighlight_seasons &lt;- c(\n  min(season_medians$season_num),\n  season_medians$season_num[which.max(season_medians$median_rating)],\n  season_medians$season_num[which.min(season_medians$median_rating)],\n  max(season_medians$season_num)\n  ) |&gt; \n  unique()\n```\n\n\n5. Visualization Parameters\n\nShow code```{r}\n#| label: params\n#| include: true\n#| warning: false\n\n### |-  plot aesthetics ----\ncolors &lt;- get_theme_colors(\n  palette = list(\n    col_red     = \"#A6192E\",\n    col_gold    = \"#EAAA00\",\n    col_neutral = \"#F5F5F2\"\n  )\n)\n\n### |- titles and caption ----\ntitle_text &lt;- \"&lt;span style='color:#A6192E;'&gt;The Secret Sauce:&lt;/span&gt; Bob\\\\'s Burgers Rating Trends\"\n\nsubtitle_text &lt;- str_glue(\n  \"A Recipe for Consistency: Most episodes stay close to the season average, with gold tiles&lt;br&gt;\", \n  \"highlighting the standout 'Secret Sauce' specials.&lt;br&gt;\n  &lt;span style='font-size:10pt; color:gray50; font-family:sans;'&gt;White rings (â—‹) mark holiday episodes; \n  color intensity shows deviation from each season's median rating.&lt;/span&gt;\"\n)\n\ncaption_text &lt;- create_standalone_caption(\n  source_text = \"{ bobsburgersR } v0.2.0 (TMDB ratings)\"\n)\n\n### |-  fonts ----\nsetup_fonts()\nfonts &lt;- get_font_families()\n\n### |-  plot theme ----\n# Start with base theme\nbase_theme &lt;- create_base_theme(colors)\n\n# Add weekly-specific theme elements\nweekly_theme &lt;- extend_weekly_theme(\n  base_theme,\n  theme(\n    # Text styling\n    plot.title = element_text(\n      face = \"bold\", family = fonts$title, size = rel(1.4),\n      color = colors$title, margin = margin(b = 10), hjust = 0\n    ),\n    plot.subtitle = element_markdown(\n      face = \"italic\", family = fonts$subtitle, lineheight = 1.2,\n      color = colors$subtitle, size = rel(0.9), margin = margin(b = 20), hjust = 0\n    ),\n    \n    # Grid\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major = element_line(color = \"gray90\", linewidth = 0.25),\n    \n    # Axes\n    axis.title = element_text(size = rel(0.8), color = \"gray30\"),\n    axis.text = element_text(color = \"gray30\"),\n    axis.text.y = element_text(size = rel(0.85)),\n    axis.ticks = element_blank(),\n    \n    # Facets\n    strip.background = element_rect(fill = \"gray95\", color = NA),\n    strip.text = element_text(\n      face = \"bold\",\n      color = \"gray20\",\n      size = rel(0.9),\n      margin = margin(t = 6, b = 4)\n    ),\n    panel.spacing = unit(1.5, \"lines\"),\n    \n    # Legend elements\n    legend.position = \"plot\",\n    legend.title = element_text(\n      family = fonts$subtitle,\n      color = colors$text, size = rel(0.6), face = \"bold\"\n    ),\n    legend.text = element_text(\n      family = fonts$tsubtitle,\n      color = colors$text, size = rel(0.7)\n    ),\n    legend.margin = margin(t = 15),\n    \n    # Plot margin\n    plot.margin = margin(10, 20, 10, 20),\n    \n  )\n)\n\n# Set theme\ntheme_set(weekly_theme)\n```\n\n\n6. Plot\n\nShow code```{r}\n#| label: plot\n#| warning: false\n\n### |-  line chart ----\nline_chart &lt;- \nggplot(season_medians, aes(x = season_num, y = median_rating)) +\n  # Geoms\n  geom_hline(\n    yintercept = series_median,\n    linetype = \"dashed\",\n    color = \"gray60\",\n    linewidth = 0.7\n  ) +\n  geom_point(\n    data = episodes,\n    aes(x = season_num, y = rating),\n    position = position_jitter(width = 0.15, height = 0, seed = 123),\n    alpha = 0.08, size = 0.9,\n    color = colors$palette$col_red\n  ) +\n  geom_step(color = colors$palette$col_gold, linewidth = 1.2) +\n  geom_point(color = colors$palette$col_gold, size = 3) +\n  geom_text(\n    data = season_medians |&gt; filter(season_num %in% highlight_seasons),\n    aes(label = round(median_rating, 1)),\n    vjust = -1.5,\n    family = fonts$text,\n    fontface = \"bold\",\n    size = 3\n  ) +\n  # Annotate \n  annotate(\n    \"text\",\n    x = 0.7,\n    y = series_median - 0.6,\n    label = glue(\"Series median: {round(series_median, 1)}\"),\n    hjust = 0,\n    family = fonts$text,\n    size = 3,\n    color = \"gray50\",\n    fontface = \"italic\"\n  ) +\n  # Scales\n  scale_y_continuous(\n    limits = c(4, 10.5),\n    breaks = c(5, 7, 9)\n  ) +\n  scale_x_continuous(\n    breaks = 1:16,\n    limits = c(0.5, 16.2)\n  ) +\n  # Labs\n  labs(y = \"TMDB Rating\", x = NULL) +\n  # Theme\n  theme(\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.title.y = element_text(size = 9, color = \"gray40\")\n  )\n\n# ### |-  heatmap plot ----\nheatmap_plot &lt;- \n  ggplot(heatmap_df, aes(x = season, y = episode)) +\n    # Geoms\n    geom_tile(aes(fill = dev), color = \"white\", linewidth = 0.1) +\n    geom_point(\n      data = heatmap_df |&gt; filter(is_holiday),\n      shape = 1,\n      size = 3.8,\n      color = \"white\",\n      stroke = 0.8,\n      alpha = 0.85\n    ) +\n    geom_text(\n      aes(label = tile_label),\n      size = 2.4,\n      fontface = \"bold\",\n      family = fonts$text,\n      color = \"black\"\n    ) +\n    # Annotate\n    annotate(\n      \"text\",\n      x = 12.5,\n      y = levels(heatmap_df$episode)[1],\n      label = \"â—‹ = Holiday/special episode\",\n      hjust = 0,\n      vjust = 1,\n      size = 2.8,\n      family = \"sans\",\n      color = \"gray40\"\n    ) +\n    # Scales\n    scale_fill_gradient2(\n      low = colors$palette$col_red,\n      mid = colors$palette$col_neutral,\n      high = colors$palette$col_gold,\n      midpoint = 0,\n      limits = c(-dev_limit, dev_limit),\n      oob = squish,\n      breaks = c(-2, -1, 0, 1, 2),\n      name = \"Deviation from\\nseason median\"\n    ) +\n    scale_x_discrete(position = \"top\") +                       \n    coord_cartesian(expand = FALSE) +\n    # Labs\n    labs(x = \"Season\", y = \"Episode Number\") +\n    # Theme\n    theme(\n      axis.text.y = element_text(size = 6.5, color = \"gray40\"),\n      legend.position = \"bottom\",\n      legend.key.width = unit(2, \"cm\"),\n      panel.grid.major.y = element_blank(),\n      panel.grid.minor.y = element_blank(),\n      panel.grid = element_blank(),\n      \n    )\n\n### |-  combined plots ----  \ncombined_plot &lt;- \n    (line_chart / heatmap_plot) +\n      plot_layout(heights = c(0.75, 1.45)) +\n      \n      # Labs\n        plot_annotation(\n          title = title_text,\n          subtitle = subtitle_text,\n          caption = caption_text\n        ) &\n\n        # Theme\n        theme(\n          plot.title = element_markdown(\n            size = rel(1.6),\n            family = fonts$title,\n            face = \"bold\",\n            color = colors$title,\n            lineheight = 1.15,\n            margin = margin(t = 5, b = 5)\n          ),\n          plot.subtitle = element_markdown(\n            size = rel(0.8),\n            family = 'sans',\n            color = colors$subtitle,\n            lineheight = 1.5,\n            margin = margin(t = 5, b = 5)\n          ),\n          plot.caption = element_markdown(\n            size = rel(0.55),\n            family = fonts$subtitle,\n            color = colors$caption,\n            hjust = 0,\n            lineheight = 1.4,\n            margin = margin(t = 20, b = 5)\n          ),\n          legend.title = element_text(hjust = 0.5)\n        )\n```\n\n\n7. Save\n\nShow code```{r}\n#| label: save\n#| warning: false\n\n### |-  plot image ----  \nsave_plot_patchwork(\n  plot = combined_plot, \n  type = \"standalone\", \n  year = 2026,\n  width  = 8,\n  height = 12,\n  )\n```\n\n\n8. Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] here_1.0.1         bobsburgersR_0.2.0 patchwork_1.3.0    glue_1.8.0        \n [5] scales_1.3.0       skimr_2.1.5        janitor_2.2.0      showtext_0.9-7    \n [9] showtextdb_3.0     sysfonts_0.8.9     ggtext_0.1.2       lubridate_1.9.3   \n[13] forcats_1.0.0      stringr_1.5.1      dplyr_1.1.4        purrr_1.0.2       \n[17] readr_2.1.5        tidyr_1.3.1        tibble_3.2.1       ggplot2_3.5.1     \n[21] tidyverse_2.0.0    pacman_0.5.1      \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6       xfun_0.49          htmlwidgets_1.6.4  tzdb_0.5.0        \n [5] yulab.utils_0.1.8  vctrs_0.6.5        tools_4.4.0        generics_0.1.3    \n [9] curl_6.0.0         gifski_1.32.0-1    fansi_1.0.6        pkgconfig_2.0.3   \n[13] ggplotify_0.1.2    lifecycle_1.0.4    compiler_4.4.0     farver_2.1.2      \n[17] munsell_0.5.1      repr_1.1.7         codetools_0.2-20   snakecase_0.11.1  \n[21] htmltools_0.5.8.1  yaml_2.3.10        pillar_1.9.0       camcorder_0.1.0   \n[25] magick_2.8.5       commonmark_1.9.2   tidyselect_1.2.1   digest_0.6.37     \n[29] stringi_1.8.4      rsvg_2.6.1         rprojroot_2.0.4    fastmap_1.2.0     \n[33] grid_4.4.0         colorspace_2.1-1   cli_3.6.4          magrittr_2.0.3    \n[37] base64enc_0.1-3    utf8_1.2.4         withr_3.0.2        timechange_0.3.0  \n[41] rmarkdown_2.29     hms_1.1.3          evaluate_1.0.1     knitr_1.49        \n[45] markdown_1.13      gridGraphics_0.5-1 rlang_1.1.6        gridtext_0.1.5    \n[49] Rcpp_1.0.13-1      xml2_1.3.6         renv_1.0.3         svglite_2.1.3     \n[53] rstudioapi_0.17.1  jsonlite_1.8.9     R6_2.5.1           fs_1.6.5          \n[57] systemfonts_1.1.0 \n\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in sa_2026-01-21.qmd.\nFor the full repository, click here.\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\n\n\nData Source:\n\nbobsburgersR R Package v0.2.0: GitHub Repository\n\nEpisode Ratings: TMDB (The Movie Database)\n\n\n\n\nBobâ€™s Burgers:\n\nOfficial Show Page: FOX - Bobâ€™s Burgers\n\nWikipedia: Bobâ€™s Burgers Episode List\n\n\n\n\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\n\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\n\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\n\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n Back to topCitationBibTeX citation:@online{ponce2026,\n  author = {Ponce, Steven},\n  title = {The {Secret} {Sauce:} {Bobâ€™s} {Burgers} {Rating} {Trends?}},\n  date = {2026-01-21},\n  url = {https://stevenponce.netlify.app/projects/standalone_visualizations/sa_2026-01-21.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPonce, Steven. 2026. â€œThe Secret Sauce: Bobâ€™s Burgers Rating\nTrends?â€ January 21, 2026. https://stevenponce.netlify.app/projects/standalone_visualizations/sa_2026-01-21.html."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-22.html",
    "href": "projects/standalone_visualizations/sa_2026-01-22.html",
    "title": "Bobâ€™s Burgers: The Fart Report",
    "section": "",
    "text": "FigureÂ 1: Three-panel data visualization titled â€˜Bobâ€™s Burgers: The Fart Reportâ€™ analyzing 328 fart mentions across 16 seasons. The top panel shows â€˜The Fart Lexiconâ€™ with vertical bars: â€˜fartâ€™ dominates at 53%, followed by â€˜fartsâ€™ (26%), â€˜fartingâ€™ (11%), â€˜fartedâ€™ (9%), and â€˜fartyâ€™ (2%). Bottom left shows â€˜Fastest to Fartâ€™ episodes, with S3E8 and S3E16 achieving the first fart by Line 1. Bottom right shows â€˜The Fartiest Episodesâ€™ with S6E10 â€˜Lice Things Are Liceâ€™ leading at 18 mentions, highlighted in gold. Color palette uses mustard yellow, teal, and red.\n\n\nSteps to Create this Graphic\n1. Load Packages & Setup\n\nShow code```{r}\n#| label: load\n#| warning: false\n#| message: false\n#| results: \"hide\"\n\n## 1. LOAD PACKAGES & SETUP ----\nsuppressPackageStartupMessages({\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  tidyverse,         # Easily Install and Load the 'Tidyverse'\n  ggtext,            # Improved Text Rendering Support for 'ggplot2'\n  showtext,          # Using Fonts More Easily in R Graphs\n  janitor,           # Simple Tools for Examining and Cleaning Dirty Data\n  skimr,             # Compact and Flexible Summaries of Data\n  scales,            # Scale Functions for Visualization\n  glue,              # Interpreted String Literals\n  patchwork,         # The Composer of Plots\n  bobsburgersR       # Bob's Burgers Datasets for Data Visualization\n)  \n})\n\n### |- figure size ----\ncamcorder::gg_record(\n  dir    = here::here(\"temp_plots\"),\n  device = \"png\",\n  width  = 14,\n  height = 10,\n  units  = \"in\",\n  dpi    = 320\n)\n\n# Source utility functions\nsuppressMessages(source(here::here(\"R/utils/fonts.R\")))\nsource(here::here(\"R/utils/social_icons.R\"))\nsource(here::here(\"R/utils/image_utils.R\"))\nsource(here::here(\"R/themes/base_theme.R\"))\n```\n\n\n2. Read in the Data\n\nShow code```{r}\n#| label: read\n#| include: true\n#| eval: true\n#| warning: false\n\ntranscript_data &lt;- bobsburgersR::transcript_data\n```\n\n\n3. Examine the Data\n\nShow code```{r}\n#| label: examine\n#| include: true\n#| eval: true\n#| results: 'hide'\n#| warning: false\n\nglimpse(transcript_data)\nskim_without_charts(transcript_data)\n```\n\n\n4. Tidy Data\n\nShow code```{r}\n#| label: tidy-fixed\n#| warning: false\n\n# Data Prep: Extract Fart Mentions\nfart_data &lt;- transcript_data |&gt;\n  filter(str_detect(raw_text, regex(\"\\\\bfart(ing|ed|s|y)?\\\\b\", ignore_case = TRUE))) |&gt;\n  mutate(\n    type = if_else(is.na(dialogue), \"Sound Effect\", \"Spoken\"),\n    dialogue_clean = coalesce(dialogue, raw_text)\n  )\n\n# Key stats\ntotal_farts &lt;- nrow(fart_data)\ntotal_seasons &lt;- max(transcript_data$season, na.rm = TRUE)\n\n# Helper Function \nmake_ep_label &lt;- function(season, episode, title, width = 28) {\n  paste0(\"S\", season, \"E\", episode, \": \", str_trunc(title, width))\n}\n\n# P1 Data: The Fart Lexicon\nfart_lexicon &lt;- fart_data |&gt;\n  filter(type == \"Spoken\") |&gt;\n  mutate(\n    variant = case_when(\n      str_detect(tolower(dialogue_clean), \"\\\\bfarting\\\\b\") ~ \"farting\",\n      str_detect(tolower(dialogue_clean), \"\\\\bfarted\\\\b\") ~ \"farted\",\n      str_detect(tolower(dialogue_clean), \"\\\\bfarts\\\\b\") ~ \"farts\",\n      str_detect(tolower(dialogue_clean), \"\\\\bfarty\\\\b\") ~ \"farty\",\n      TRUE ~ \"fart\"\n    )\n  ) |&gt;\n  count(variant, sort = TRUE) |&gt;\n  mutate(\n    pct = n / sum(n),\n    variant = fct_reorder(variant, n)\n  )\n\n# P2 Data: Fastest to Fart\nfastest_to_fart &lt;- fart_data |&gt;\n  group_by(season, episode, title) |&gt;\n  summarise(first_fart_line = min(line, na.rm = TRUE), .groups = \"drop\") |&gt;\n  arrange(first_fart_line) |&gt;\n  slice_head(n = 10) |&gt;\n  mutate(\n    label = make_ep_label(season, episode, title),\n    label = fct_reorder(label, -first_fart_line)\n  )\n\n# P3 Data: The Fartiest Episodes \nfartiest_episodes &lt;- fart_data |&gt;\n  count(season, episode, title, name = \"fart_count\") |&gt;\n  arrange(desc(fart_count)) |&gt;\n  slice_head(n = 15) |&gt;\n  mutate(\n    label = make_ep_label(season, episode, title),\n    label = fct_reorder(label, fart_count),\n    is_champion = row_number() == 1\n  )\n```\n\n\n5. Visualization Parameters\n\nShow code```{r}\n#| label: params\n#| include: true\n#| warning: false\n\n### |-  plot aesthetics ----\ncolors &lt;- get_theme_colors(\n  palette = list(\n    mustard    = \"#E8A838\",\n    burger_red = \"#C44536\",\n    teal       = \"#3D8B8B\",\n    black      = \"#2C3E50\",\n    gray       = \"#7F8C8D\",\n    light_gray = \"#BDC3C7\",\n    champion_gold = \"#D4AF37\"\n  )\n)\n\n### |- titles and caption ----\ntitle_text &lt;- \"Bob's Burgers: The Fart Report\"\n\nsubtitle_text &lt;- str_glue(\n  \"{comma(total_farts)} fart mentions across {total_seasons} seasons of transcript data (yes, we counted!)\"\n)\n\ncaption_text &lt;- create_standalone_caption(                       \n  source_text = \"{ bobsburgersR } v0.2.0 (transcripts)\"\n)\n\n### |-  fonts ----\nsetup_fonts()\nfonts &lt;- get_font_families()\n\n### |-  plot theme ----\n# Start with base theme\nbase_theme &lt;- create_base_theme(colors)\n\n# Add weekly-specific theme elements\nweekly_theme &lt;- extend_weekly_theme(\n  base_theme,\n  theme(\n    # Text styling\n    plot.title = element_text(\n      face = \"bold\", family = fonts$title, size = rel(1.4),        \n      color = colors$title, margin = margin(b = 10), hjust = 0\n    ),\n    plot.subtitle = element_text(\n      face = \"italic\", family = fonts$subtitle, lineheight = 1.2,\n      color = colors$subtitle, size = rel(0.85), margin = margin(b = 20), hjust = 0    \n    ),\n    \n    # Grid\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major = element_line(color = \"gray90\", linewidth = 0.25),\n    \n    # Axes\n    axis.title = element_text(size = rel(0.8), color = \"gray30\"),\n    axis.text = element_text(color = \"gray30\"),\n    axis.text.y = element_text(size = rel(0.85)),\n    axis.ticks = element_blank(),\n    \n    # Facets\n    strip.background = element_rect(fill = \"gray95\", color = NA),\n    strip.text = element_text(\n      face = \"bold\",\n      color = \"gray20\",\n      size = rel(0.9),\n      margin = margin(t = 6, b = 4)\n    ),\n    panel.spacing = unit(1.5, \"lines\"),\n    \n    # Legend elements\n    legend.position = \"plot\",\n    legend.title = element_text(\n      family = fonts$subtitle,\n      color = colors$text, size = rel(0.8), face = \"bold\"\n    ),\n    legend.text = element_text(\n      family = fonts$tsubtitle,\n      color = colors$text, size = rel(0.7)\n    ),\n    legend.margin = margin(t = 15),\n    \n    # Plot margin\n    plot.margin = margin(10, 20, 10, 20),\n    \n  )\n)\n\n# Set theme\ntheme_set(weekly_theme)\n```\n\n\n6. Plot\n\nShow code```{r}\n#| label: plot\n#| warning: false\n\n# P1: The Fart Lexicon \np1 &lt;- ggplot(fart_lexicon, aes(x = variant, y = n)) +\n  geom_col(width = 0.6, fill = colors$palette$mustard) +\n  geom_text(\n    aes(label = glue(\"{n}\\n({percent(pct, 1)})\")),\n    vjust = -0.3,\n    size = 3.5,\n    fontface = \"bold\",\n    color = colors$palette$black,\n    lineheight = 0.9\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.3))) +\n  labs(\n    title = \"The Fart Lexicon\",\n    subtitle = \"How the Belchers conjugate 'fart'\",\n    x = NULL,\n    y = NULL\n  ) +\n  theme(\n    panel.grid.major.x = element_blank(),\n    panel.grid.major.y = element_line(color = \"#EEEEEE\"),\n    axis.text.x = element_text(size = 10, face = \"bold\"),\n    axis.text.y = element_blank()\n  )\n\n# P2: Fastest to Fart \np2 &lt;- ggplot(fastest_to_fart, aes(x = label, y = first_fart_line)) +\n  geom_col(width = 0.7, fill = colors$palette$teal) +\n  geom_text(\n    aes(label = glue(\"Line {first_fart_line}\")),\n    hjust = -0.1,\n    size = 3,\n    color = colors$palette$black\n  ) +\n  coord_flip() +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.25))) +\n  labs(\n    title = \"Fastest to Fart\",\n    subtitle = \"Episodes that waste no time\",\n    x = NULL,\n    y = \"Line number of first fart\"\n  ) +\n  theme(\n    panel.grid.major.y = element_blank(),\n    axis.text.y = element_text(size = rel(0.85)),\n    axis.title.x = element_text(margin = margin(t = 8)),\n    plot.margin = margin(8, 14, 6, 10)\n  )\n\n\n# P3: The Fartiest Episodes \np3 &lt;- ggplot(fartiest_episodes, aes(x = label, y = fart_count)) +\n  geom_col(\n    aes(fill = is_champion),\n    width = 0.7,\n    show.legend = FALSE\n  ) +\n  geom_text(\n    aes(\n      label = if_else(is_champion, glue(\"{fart_count} â˜…\"), as.character(fart_count)),\n      fontface = if_else(is_champion, \"bold\", \"plain\")\n    ),\n    hjust = -0.3,\n    size = 3.5,\n    color = colors$palette$black\n  ) +\n  coord_flip() +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.18))) +\n  scale_fill_manual(\n    values = c(\"FALSE\" = colors$palette$burger_red,\n               \"TRUE\" = colors$palette$champion_gold)\n  ) +\n  labs(\n    title = \"The Fartiest Episodes\",\n    subtitle = \"Episodes with the most fart references\",\n    x = NULL,\n    y = \"Fart mentions\"\n  ) +\n  theme(\n    panel.grid.major.y = element_blank(),\n    axis.text.y = element_text(size = rel(0.85)),\n    axis.title.x = element_text(margin = margin(t = 8)),\n    plot.margin = margin(8, 14, 6, 10)\n  )\n\n# Combine: Final Layout\ncombined_plot &lt;- p1 / (p2 | p3) +\n  plot_layout(heights = c(0.8, 2))\n\ncombined_plot &lt;- combined_plot +\n  plot_annotation(\n    title = title_text,\n    subtitle = subtitle_text,\n    caption = caption_text,\n  theme = theme(\n    plot.title = element_text(\n      size = rel(2.14),\n      family = fonts$title,\n      face = \"bold\",\n      color = colors$title,\n      lineheight = 1.15,\n      margin = margin(t = 5, b = 5)\n    ),\n    plot.subtitle = element_text(\n      size = rel(1.0),\n      family = fonts$subtitle,\n      color = colors$subtitle,\n      lineheight = 1.5,\n      margin = margin(t = 5, b = 15)\n    ),\n    plot.caption = element_markdown(\n      size = rel(0.65),\n      family = fonts$subtitle,\n      color = colors$caption,\n      hjust = 0,\n      lineheight = 1.4,\n      margin = margin(t = 20, b = 5)\n    ),\n    plot.margin = margin(12, 18, 10, 18)\n  )\n)\n```\n\n\n7. Save\n\nShow code```{r}\n#| label: save\n#| warning: false\n\n### |-  plot image ----  \nsave_plot_patchwork(\n  plot = combined_plot, \n  type = \"standalone\", \n  year = 2026,\n  width  = 14,\n  height = 10,\n  )\n```\n\n\n8. Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] here_1.0.1         bobsburgersR_0.2.0 patchwork_1.3.0    glue_1.8.0        \n [5] scales_1.3.0       skimr_2.1.5        janitor_2.2.0      showtext_0.9-7    \n [9] showtextdb_3.0     sysfonts_0.8.9     ggtext_0.1.2       lubridate_1.9.3   \n[13] forcats_1.0.0      stringr_1.5.1      dplyr_1.1.4        purrr_1.0.2       \n[17] readr_2.1.5        tidyr_1.3.1        tibble_3.2.1       ggplot2_3.5.1     \n[21] tidyverse_2.0.0    pacman_0.5.1      \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6       xfun_0.49          htmlwidgets_1.6.4  tzdb_0.5.0        \n [5] yulab.utils_0.1.8  vctrs_0.6.5        tools_4.4.0        generics_0.1.3    \n [9] curl_6.0.0         gifski_1.32.0-1    fansi_1.0.6        pkgconfig_2.0.3   \n[13] ggplotify_0.1.2    lifecycle_1.0.4    compiler_4.4.0     farver_2.1.2      \n[17] munsell_0.5.1      repr_1.1.7         codetools_0.2-20   snakecase_0.11.1  \n[21] htmltools_0.5.8.1  yaml_2.3.10        pillar_1.9.0       camcorder_0.1.0   \n[25] magick_2.8.5       commonmark_1.9.2   tidyselect_1.2.1   digest_0.6.37     \n[29] stringi_1.8.4      labeling_0.4.3     rsvg_2.6.1         rprojroot_2.0.4   \n[33] fastmap_1.2.0      grid_4.4.0         colorspace_2.1-1   cli_3.6.4         \n[37] magrittr_2.0.3     base64enc_0.1-3    utf8_1.2.4         withr_3.0.2       \n[41] timechange_0.3.0   rmarkdown_2.29     hms_1.1.3          evaluate_1.0.1    \n[45] knitr_1.49         markdown_1.13      gridGraphics_0.5-1 rlang_1.1.6       \n[49] gridtext_0.1.5     Rcpp_1.0.13-1      xml2_1.3.6         renv_1.0.3        \n[53] svglite_2.1.3      rstudioapi_0.17.1  jsonlite_1.8.9     R6_2.5.1          \n[57] fs_1.6.5           systemfonts_1.1.0 \n\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in sa_2026-01-22.qmd.\nFor the full repository, click here.\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\n\n\nData Source:\n\nbobsburgersR R Package v0.2.0: GitHub Repository\n\nTranscript Data: Springfield! Springfield!\n\n\n\n\nBobâ€™s Burgers:\n\nOfficial Show Page: FOX - Bobâ€™s Burgers\n\nWikipedia: Bobâ€™s Burgers Episode List\n\n\n\n\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\n\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\n\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\n\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n Back to topCitationBibTeX citation:@online{ponce2026,\n  author = {Ponce, Steven},\n  title = {Bobâ€™s {Burgers:} {The} {Fart} {Report}},\n  date = {2026-01-22},\n  url = {https://stevenponce.netlify.app/projects/standalone_visualizations/sa_2026-01-22.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPonce, Steven. 2026. â€œBobâ€™s Burgers: The Fart Report.â€\nJanuary 22, 2026. https://stevenponce.netlify.app/projects/standalone_visualizations/sa_2026-01-22.html."
  },
  {
    "objectID": "data_visualizations/TidyTuesday/2026/tt_2026_04.html",
    "href": "data_visualizations/TidyTuesday/2026/tt_2026_04.html",
    "title": "Just 25 Companies Hold Half of Brazilâ€™s Corporate Capital",
    "section": "",
    "text": "FigureÂ 1: Dual-panel Lorenz curve visualization showing extreme corporate capital concentration in Brazil. The left panel displays a traditional Lorenz curve in which the red line hugs the bottom axis, indicating that 99% of companies hold just 0.8% of total capital, with a diagonal dashed line representing perfect equality. The right panel zooms in on the top 0.6% of companies, revealing that just 25 firms control 50% of all capital, and 139 firms control 80%. The Gini coefficient of 0.998 indicates near-total wealth capture among 141,332 registered Brazilian companies.\n\n\nSteps to Create this Graphic\n1. Load Packages & Setup\n\nShow code```{r}\n#| label: load\n#| warning: false\n#| message: false\n#| results: \"hide\"\n\n## 1. LOAD PACKAGES & SETUP ----\nsuppressPackageStartupMessages({\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n    tidyverse, ggtext, showtext, janitor, \n    scales, glue, patchwork, ineq, ggrepel\n)\n})\n\n### |- figure size ----\ncamcorder::gg_record(\n  dir    = here::here(\"temp_plots\"),\n  device = \"png\",\n  width  = 12,\n  height = 7,\n  units  = \"in\",\n  dpi    = 320\n)\n\n# Source utility functions\nsuppressMessages(source(here::here(\"R/utils/fonts.R\")))\nsource(here::here(\"R/utils/social_icons.R\"))\nsource(here::here(\"R/utils/image_utils.R\"))\nsource(here::here(\"R/themes/base_theme.R\"))\n```\n\n\n2. Read in the Data\n\nShow code```{r}\n#| label: read\n#| include: true\n#| eval: true\n#| warning: false\n\ntt &lt;- tidytuesdayR::tt_load(2026, week = 04)\ncompanies &lt;- tt$companies |&gt; clean_names()\nrm(tt)\n```\n\n\n3. Examine the Data\n\nShow code```{r}\n#| label: examine\n#| include: true\n#| eval: true\n#| results: 'hide'\n#| warning: false\n\nglimpse(companies)\n```\n\n\n4. Tidy Data\n\nShow code```{r}\n#| label: tidy\n#| warning: false\n\ncompanies_clean &lt;- companies |&gt;\n  mutate(capital_stock = replace_na(capital_stock, 0))\n\nn_companies &lt;- nrow(companies_clean)\ngini_val &lt;- Gini(companies_clean$capital_stock)\n\n# Lorenz Data (Bottom-Up)\nlorenz_bottom &lt;- companies_clean |&gt;\n  arrange(capital_stock) |&gt;\n  mutate(\n    cum_companies = row_number() / n(),\n    cum_capital = cumsum(capital_stock) / sum(capital_stock)\n  )\n\n# Pareto Data (Top-Down Zoom)\nlorenz_top &lt;- companies_clean |&gt;\n  arrange(desc(capital_stock)) |&gt;\n  mutate(\n    top_pct_companies = row_number() / n(),\n    cum_capital = cumsum(capital_stock) / sum(capital_stock)\n  )\n\n# Thresholds\np99 &lt;- lorenz_bottom |&gt; filter(cum_companies &gt;= 0.99) |&gt; slice_head(n = 1)\nhold_50 &lt;- lorenz_top |&gt; filter(cum_capital &gt;= 0.50) |&gt; slice_head(n = 1)\nhold_80 &lt;- lorenz_top |&gt; filter(cum_capital &gt;= 0.80) |&gt; slice_head(n = 1)\nn_25 &lt;- round(hold_50$top_pct_companies * n_companies)\n```\n\n\n5. Visualization Parameters\n\nShow code```{r}\n#| label: params\n#| include: true\n#| warning: false\n\n### |-  plot aesthetics ----\ncolors &lt;- get_theme_colors(\n  palette = list(\n      col_curve &lt;- \"#c0392b\"   \n  )\n)\n\n### |- titles and caption ----\ntitle_text = str_glue(\"Just {n_25} Companies Hold Half of Brazil's Corporate Capital\")\n\nsubtitle_text = str_glue(\n    \"Analysis of {comma(n_companies)} firms shows a Gini Coefficient of {round(gini_val, 3)}, indicating near-total wealth capture.\"\n    )\n\ncaption_text &lt;- create_social_caption(\n    tt_year = 2026,\n    tt_week = 04,\n    source_text = \"Brazilian Ministry of Finance (CNPJ)\"\n)\n\n### |-  fonts ----\nsetup_fonts()\nfonts &lt;- get_font_families()\n\n### |-  plot theme ----\n# Start with base theme\nbase_theme &lt;- create_base_theme(colors)\n\n# Add weekly-specific theme elements\nweekly_theme &lt;- extend_weekly_theme(\n  base_theme,\n  theme(\n    # Text styling\n    plot.title = element_text(\n      face = \"bold\", family = fonts$title, size = rel(1.4),\n      color = colors$title, margin = margin(b = 10), hjust = 0\n    ),\n    plot.subtitle = element_text(\n      face = \"italic\", family = fonts$subtitle, lineheight = 1.2,\n      color = colors$subtitle, size = rel(0.9), margin = margin(b = 20), hjust = 0\n    ),\n\n    # Grid\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major = element_line(color = \"gray90\", linewidth = 0.25),\n\n    # Axes\n    axis.title = element_text(size = rel(0.8), color = \"gray30\"),\n    axis.text = element_text(color = \"gray30\"),\n    axis.text.y = element_text(size = rel(0.85)),\n    axis.ticks = element_blank(),\n\n    # Facets\n    strip.background = element_rect(fill = \"gray95\", color = NA),\n    strip.text = element_text(\n      face = \"bold\",\n      color = \"gray20\",\n      size = rel(0.9),\n      margin = margin(t = 6, b = 4)\n    ),\n    panel.spacing = unit(1.5, \"lines\"),\n\n    # Legend elements\n    legend.position = \"plot\",\n    legend.title = element_text(\n      family = fonts$subtitle,\n      color = colors$text, size = rel(0.8), face = \"bold\"\n    ),\n    legend.text = element_text(\n      family = fonts$tsubtitle,\n      color = colors$text, size = rel(0.7)\n    ),\n    legend.margin = margin(t = 15),\n\n    # Plot margin\n    plot.margin = margin(10, 20, 10, 20),\n    \n  )\n)\n\n# Set theme\ntheme_set(weekly_theme)\n```\n\n\n6. Plot\n\nShow code```{r}\n#| label: plot\n#| warning: false\n\n### |- LEFT PANEL: THE MACRO PROBLEM ----\npanel_left &lt;- lorenz_bottom |&gt;\n  # Geoms\n  ggplot(aes(x = cum_companies, y = cum_capital)) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"gray60\") +\n  geom_ribbon(aes(ymin = cum_capital, ymax = cum_companies), alpha = 0.1, fill = col_curve) +\n  geom_line(color = col_curve, linewidth = 1.2) +\n  # Annotations\n  annotate(\"text\",\n    x = 0.35, y = 0.45, label = \"Line of Perfect Equality\",\n    angle = 45, size = 3.5, color = \"gray50\", fontface = \"italic\"\n  ) +\n  annotate(\"label\",\n    x = 0.70, y = 0.20,\n    label = glue(\"99% of companies hold\\njust {percent(p99$cum_capital, 0.1)} of capital\"),\n    fill = \"white\", color = \"gray20\", size = 3.5, label.size = 0.2\n  ) +\n  annotate(\"curve\",\n    x = 0.85, y = 0.20, xend = 0.98, yend = 0.02,\n    curvature = 0.2, color = \"gray40\", arrow = arrow(length = unit(0.1, \"cm\"))\n  ) +\n  # Scales\n  scale_x_continuous(labels = percent_format()) +\n  scale_y_continuous(labels = percent_format()) +\n  coord_fixed() +\n  # Labs\n  labs(\n    title = \"The Global Context\",\n    subtitle = \"Capital hugs the bottom axis across the entire population\",\n    x = \"Cumulative % of Companies\",\n    y = \"Cumulative % of Capital\"\n  )\n\n### |- RIGHT PANEL: THE POWER CONCENTRATION----\npanel_right &lt;- lorenz_top |&gt;\n  filter(top_pct_companies &lt;= 0.005) |&gt;\n  # Geoms\n  ggplot(aes(x = top_pct_companies, y = cum_capital)) +\n  geom_area(fill = col_curve, alpha = 0.15) +\n  geom_hline(yintercept = c(0.5, 0.8), linetype = \"dotted\", color = \"gray50\") +\n  geom_line(color = col_curve, linewidth = 1.5) +\n  geom_point(data = bind_rows(hold_50, hold_80), size = 4, color = col_curve) +\n  geom_text_repel(\n    data = bind_rows(hold_50, hold_80),\n    aes(label = glue(\"{comma(round(top_pct_companies * n_companies))} firms control {percent(cum_capital)}\")),\n    nudge_x = 0.001, direction = \"y\", hjust = 0, size = 4, fontface = \"bold\"\n  ) +\n  # Scales\n  scale_x_continuous(labels = percent_format(accuracy = 0.1), expand = expansion(mult = c(0, 0.3))) +\n  scale_y_continuous(labels = percent_format(), breaks = c(0, 0.5, 0.8, 1)) +\n  coord_cartesian(clip = \"off\") +\n  # Labs\n  labs(\n    title = \"The Power Concentration\",\n    subtitle = \"Zoomed view: where the actual capital resides\",\n    x = \"Top % of Companies\",\n    y = NULL\n  )\n\n### |- COMBINE ----\ncombined_plot &lt;-(panel_left + panel_right) +\n    plot_annotation(\n        title = title_text,\n        subtitle = subtitle_text,\n        caption = caption_text,\n        theme = theme(\n    plot.title = element_text(\n      size = rel(1.8),\n      family = fonts$title,\n      face = \"bold\",\n      color = colors$title,\n      lineheight = 1.15,\n      margin = margin(t = 5, b = 5)\n    ),\n    plot.subtitle = element_text(\n      size = rel(0.9),\n      family = fonts$subtitle,\n      color = colors$subtitle,\n      lineheight = 1.5,\n      margin = margin(t = 5, b = 5)\n    ),\n    plot.caption = element_markdown(\n      size = rel(0.55),\n      family = fonts$subtitle,\n      color = colors$caption,\n      hjust = 0,\n      lineheight = 1.4,\n      margin = margin(t = 10, b = 5)\n    ),\n  )\n)\n```\n\n\n7. Save\n\nShow code```{r}\n#| label: save\n#| warning: false\n\n### |-  plot image ----  \nsave_plot_patchwork(\n  plot = combined_plot, \n  type = \"tidytuesday\", \n  year = 2026, \n  week = 04, \n  width  = 12,\n  height = 7,\n  )\n```\n\n\n8. Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] here_1.0.1      ggrepel_0.9.6   ineq_0.2-13     patchwork_1.3.0\n [5] glue_1.8.0      scales_1.3.0    janitor_2.2.0   showtext_0.9-7 \n [9] showtextdb_3.0  sysfonts_0.8.9  ggtext_0.1.2    lubridate_1.9.3\n[13] forcats_1.0.0   stringr_1.5.1   dplyr_1.1.4     purrr_1.0.2    \n[17] readr_2.1.5     tidyr_1.3.1     tibble_3.2.1    ggplot2_3.5.1  \n[21] tidyverse_2.0.0 pacman_0.5.1   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6       httr2_1.0.6        xfun_0.49          htmlwidgets_1.6.4 \n [5] gh_1.4.1           tzdb_0.5.0         yulab.utils_0.1.8  vctrs_0.6.5       \n [9] tools_4.4.0        generics_0.1.3     parallel_4.4.0     curl_6.0.0        \n[13] gifski_1.32.0-1    fansi_1.0.6        pkgconfig_2.0.3    ggplotify_0.1.2   \n[17] lifecycle_1.0.4    compiler_4.4.0     farver_2.1.2       munsell_0.5.1     \n[21] codetools_0.2-20   snakecase_0.11.1   htmltools_0.5.8.1  yaml_2.3.10       \n[25] crayon_1.5.3       pillar_1.9.0       camcorder_0.1.0    magick_2.8.5      \n[29] commonmark_1.9.2   tidyselect_1.2.1   digest_0.6.37      stringi_1.8.4     \n[33] labeling_0.4.3     rsvg_2.6.1         rprojroot_2.0.4    fastmap_1.2.0     \n[37] grid_4.4.0         colorspace_2.1-1   cli_3.6.4          magrittr_2.0.3    \n[41] utf8_1.2.4         withr_3.0.2        rappdirs_0.3.3     bit64_4.5.2       \n[45] timechange_0.3.0   rmarkdown_2.29     tidytuesdayR_1.1.2 gitcreds_0.1.2    \n[49] bit_4.5.0          hms_1.1.3          evaluate_1.0.1     knitr_1.49        \n[53] markdown_1.13      gridGraphics_0.5-1 rlang_1.1.6        gridtext_0.1.5    \n[57] Rcpp_1.0.13-1      xml2_1.3.6         renv_1.0.3         vroom_1.6.5       \n[61] svglite_2.1.3      rstudioapi_0.17.1  jsonlite_1.8.9     R6_2.5.1          \n[65] fs_1.6.5           systemfonts_1.1.0 \n\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in tt_2026_04.qmd.\nFor the full repository, click here.\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\n\n\nData Source:\n\nTidyTuesday 2026 Week 04: Brazilian Companies\n\nBrazilian Ministry of Finance: CNPJ Open Data\n\nData Dictionary: CNPJ Metadata (PDF)\n\n\n\n\nMethodology:\n\nLorenz Curve: Wikipedia\n\nGini Coefficient: Wikipedia\n\nR Package ineq: CRAN Documentation\n\n\n\n\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\n\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\n\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\n\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n Back to topCitationBibTeX citation:@online{ponce2026,\n  author = {Ponce, Steven},\n  title = {Just 25 {Companies} {Hold} {Half} of {Brazilâ€™s} {Corporate}\n    {Capital}},\n  date = {2026-01-26},\n  url = {https://stevenponce.netlify.app/data_visualizations/TidyTuesday/2026/tt_2026_04.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPonce, Steven. 2026. â€œJust 25 Companies Hold Half of Brazilâ€™s\nCorporate Capital.â€ January 26, 2026. https://stevenponce.netlify.app/data_visualizations/TidyTuesday/2026/tt_2026_04.html."
  },
  {
    "objectID": "data_visualizations/MakeoverMonday/2026/mm_2026_04.html",
    "href": "data_visualizations/MakeoverMonday/2026/mm_2026_04.html",
    "title": "Americaâ€™s Most In-Demand Jobs: Beyond the Headlines",
    "section": "",
    "text": "Original\nThe original visualization comes from Most Posted US Jobs by State\n\n\nOriginal visualization\n\nMakeover\n\n\n\n\n\nFigureÂ 1: Three-panel dashboard showing Americaâ€™s most in-demand jobs. The left panel displays â€œ49 out of 50 states have Registered Nurse as #1.â€ The right panel shows #2 job distribution: Retail Sales (31 states), Trucking (10 states, amber), Physician (6 states), Software (2 states, purple), and RN (1 state). Bottom panel compares Software vs.Â Trucking states across three metrics: prevalence (2 vs.Â 10 states), average wage ($125k vs.Â $51k), and total employment (82,260 vs.Â 346,870 workers). Purple and amber highlight the Software-Trucking divide; other categories are shown in gray.\n\n\nSteps to Create this Graphic\n1. Load Packages & Setup\n\nShow code```{r}\n#| label: load\n#| warning: false\n#| message: false\n#| results: \"hide\"\n\n## 1. LOAD PACKAGES & SETUP ----\nsuppressPackageStartupMessages({\n  if (!require(\"pacman\")) install.packages(\"pacman\")\n  pacman::p_load(\n  tidyverse, ggtext, showtext, scales, glue, patchwork, janitor\n)\n})\n\n### |- figure size ----\ncamcorder::gg_record(\n    dir    = here::here(\"temp_plots\"),\n    device = \"png\",\n    width  = 14,\n    height = 10,\n    units  = \"in\",\n    dpi    = 320\n)\n\n# Source utility functions\nsuppressMessages(source(here::here(\"R/utils/fonts.R\")))\nsource(here::here(\"R/utils/social_icons.R\"))\nsource(here::here(\"R/utils/image_utils.R\"))\nsource(here::here(\"R/themes/base_theme.R\"))\n```\n\n\n2. Read in the Data\n\nShow code```{r}\n#| label: read\n#| include: true\n#| eval: true\n#| warning: false\n#|\n\n### |- Current data (2025) ----\nstate_summary  &lt;- read_csv(\n   here::here(\"data/MakeoverMonday/2026/mm_wk04_state_summary.csv\")) \n\njob_summary  &lt;- read_csv(\n   here::here(\"data/MakeoverMonday/2026/mm_wk04_job_summary.csv\")) \n```\n\n\n3. Examine the Data\n\nShow code```{r}\n#| label: examine\n#| include: true\n#| eval: true\n#| results: 'hide'\n#| warning: false\n\nglimpse(state_summary)\nglimpse(job_summary)\n```\n\n\n4. Tidy Data\n\nShow code```{r}\n#| label: tidy\n#| warning: false\n\n# Note: Primary data wrangling was performed in data preparation scripts:\n#   - mm_wk04_bls_data_pull.R (BLS OEWS extraction)\n#   - mm_wk04_data_merge.R (merge all sources)\n# \n# This script reads the processed summary files and performs\n# visualization-specific transformations only.\n\n### |- P2 data: #2 job distribution ----\np2_data &lt;- state_summary |&gt;\n  count(second_job, name = \"n_states\") |&gt;\n  mutate(\n    second_job = fct_reorder(second_job, n_states),\n    label = ifelse(n_states == 1, \"1 state\", paste0(n_states, \" states\")),\n    is_hero = second_job %in% c(\n      \"Software Developer / Engineer\",\n      \"Tractor-Trailer Truck Driver\"\n    )\n  )\n\n### |- P3 data: Software vs Trucking comparison ----\np3_data &lt;- state_summary |&gt;\n  filter(second_job %in% c(\n    \"Tractor-Trailer Truck Driver\",\n    \"Software Developer / Engineer\"\n  )) |&gt;\n  group_by(second_job) |&gt;\n  summarise(\n    n_states = n(),\n    total_emp = sum(second_job_emp, na.rm = TRUE),\n    avg_wage = mean(second_job_wage, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt;\n  mutate(\n    job_short = case_when(\n      str_detect(second_job, \"Truck\") ~ \"Trucking\",\n      str_detect(second_job, \"Software\") ~ \"Software\"\n    ),\n    job_short = factor(job_short, levels = c(\"Software\", \"Trucking\"))\n  )\n```\n\n\n5. Visualization Parameters\n\nShow code```{r}\n#| label: params\n#| include: true\n#| warning: false\n\n### |-  plot aesthetics ----\ncolors &lt;- get_theme_colors(\n  palette = list(\n    software      = \"#7B5E9A\",\n    trucking      = \"#C4915E\",\n    neutral       = \"#A0A4A8\",\n    text_headline = \"#2C3E50\",\n    text_dark     = \"#2C3E50\",\n    text_mid      = \"#5D6D7E\",\n    text_light    = \"#95A5A6\"\n  )\n)\n\n### |-  job color mapping ----\njob_colors &lt;- c(\n  \"Software Developer / Engineer\"   = colors$palette$software,\n  \"Tractor-Trailer Truck Driver\"    = colors$palette$trucking,\n  \"Retail Sales Associate\"          = colors$palette$neutral,\n  \"Physician\"                       = colors$palette$neutral,\n  \"Registered Nurse\"                = colors$palette$neutral\n)\n\n### |-  Main titles ----\ntitle_text &lt;- \"America's Most In-Demand Jobs: Beyond the Headlines\"\n\nsubtitle_text &lt;- str_glue(\n  \"Registered Nurses dominate job postings nationwideâ€”but the #2 job reveals a stark divide between Software and Trucking states\"\n)\n\ncaption_text &lt;- create_mm_caption(\n  mm_year = 2026, mm_week = 04,\n  source_text = str_glue(\n    \"Lightcast Job Posting Analytics (Oct 2024-2025) | BLS OEWS May 2024 | Census Bureau 2023\"\n  )\n)\n\n### |-  fonts ----\nsetup_fonts()\nfonts &lt;- get_font_families()\n\n### |-  plot theme ----\n\n# Start with base theme\nbase_theme &lt;- create_base_theme(colors)\n\n# Add weekly-specific theme elements\nweekly_theme &lt;- extend_weekly_theme(\n  base_theme,\n  theme(\n    # # Text styling\n    plot.title = element_text(\n      size = rel(1.3), family = fonts$title, face = \"bold\",\n      color = colors$title, lineheight = 1.1, hjust = 0,\n      margin = margin(t = 5, b = 10)\n    ),\n    plot.subtitle = element_text(\n      size = rel(0.8), family = fonts$subtitle, face = \"italic\",\n      color = alpha(colors$subtitle, 0.9), lineheight = 1.1,\n      margin = margin(t = 0, b = 20)\n    ),\n\n    # Legend formatting\n    legend.position = \"plot\",\n    legend.justification = \"right\",\n    legend.margin = margin(l = 12, b = 5),\n    legend.key.size = unit(0.8, \"cm\"),\n    legend.box.margin = margin(b = 10),\n\n    # Axis formatting\n    # axis.line.x = element_line(color = \"#252525\", linewidth = .1),\n    # axis.ticks.y = element_blank(),\n    axis.ticks.x = element_line(color = \"gray\", linewidth = 0.5),\n    axis.title.x = element_text(\n      face = \"bold\", size = rel(0.85),\n      margin = margin(t = 10), family = fonts$subtitle,\n      color = \"gray40\"\n    ),\n    axis.title.y = element_text(\n      face = \"bold\", size = rel(0.85),\n      margin = margin(r = 10), family = fonts$subtitle,\n      color = \"gray40\"\n    ),\n    axis.text.x = element_text(\n      size = rel(0.85), family = fonts$subtitle,\n      color = \"gray40\"\n    ),\n    axis.text.y = element_markdown(\n      size = rel(0.85), family = fonts$subtitle,\n      color = \"gray40\"\n    ),\n\n    # Grid lines\n    panel.grid.minor = element_line(color = \"#ecf0f1\", linewidth = 0.2),\n    panel.grid.major = element_line(color = \"#ecf0f1\", linewidth = 0.4),\n\n    # Margin\n    plot.margin = margin(20, 20, 20, 20)\n  )\n)\n\n# Set theme\ntheme_set(weekly_theme)\n```\n\n\n6. Plot\n\nShow code```{r}\n#| label: plot\n#| warning: false\n\n### |-  P1 - THE BIG NUMBER ---- \np1 &lt;- ggplot() +\n  # Annotate\n  annotate(\n    \"text\",\n    x = 0.5, y = 0.75,\n    label = \"49\",\n    size = 40,\n    fontface = \"bold\",\n    color = colors$palette$text_headline\n  ) +\n  annotate(\n    \"text\",\n    x = 0.5, y = 0.32,\n    label = \"out of 50 states have\\nRegistered Nurse\\nas the #1 most-posted job\",\n    size = 4.5,\n    color = colors$palette$text_dark,\n    lineheight = 1.2\n  ) +\n  annotate(\n    \"text\",\n    x = 0.5, y = 0.08,\n    label = \"The one exception? One state has Retail Sales Associate in the top spot.\",\n    size = 3.5,\n    color = colors$palette$text_mid,\n    fontface = \"italic\"\n  ) +\n  # Limits\n  xlim(0, 1) +\n  ylim(0, 1) +\n  # Theme\n  theme_void() +\n  theme(\n    plot.background = element_rect(fill = colors$background, color = colors$background),\n    panel.background = element_rect(fill = colors$background, color = colors$background),\n    plot.margin = margin(10, 10, 10, 10)\n  )\n\n### |-  P2 - #2 JOB DISTRIBUTION ----\np2 &lt;- p2_data |&gt;\n  ggplot(aes(x = n_states, y = second_job, fill = second_job)) +\n  # Geoms\n  geom_col(width = 0.7) +\n  geom_text(\n    aes(\n      label = label,\n      fontface = ifelse(is_hero, \"bold\", \"plain\")\n    ),\n    hjust = -0.1,\n    size = 4,\n    color = colors$palette$text_dark\n  ) +\n  # Scales\n  scale_fill_manual(values = job_colors, guide = \"none\") +\n  scale_x_continuous(expand = expansion(mult = c(0, 0.25))) +\n  # Labs\n  labs(\n    title = \"What's Your State's #2 Most-Posted Job?\",\n    subtitle = \"Since RN dominates #1, the real variation is in the second spot\",\n    x = NULL,\n    y = NULL\n  ) +\n  # Theme\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    axis.text.x = element_blank(),\n    plot.margin = margin(10, 10, 10, 10)\n  )\n\n### |-  P3 - THE OPPORTUNITY GAP ---\n\n# Sub-panel A: Number of states\np3a &lt;- p3_data |&gt;\n  ggplot(aes(x = job_short, y = n_states, fill = second_job)) +\n  # Geoms\n  geom_col(width = 0.6) +\n  geom_text(\n    aes(label = paste0(n_states, \" states\")),\n    vjust = -0.5,\n    fontface = \"bold\",\n    size = 3.5,\n    color = colors$palette$text_dark\n  ) +\n  # Scales\n  scale_fill_manual(values = job_colors, guide = \"none\") +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.25))) +\n  # Labs\n  labs(title = \"Where It's #2\") +\n  # Theme\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    axis.title.y = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.ticks.x = element_blank(),\n    plot.margin = margin(10, 10, 10, 10)\n  )\n\n# Sub-panel B: Average wage\np3b &lt;- p3_data |&gt;\n  ggplot(aes(x = job_short, y = avg_wage, fill = second_job)) +\n  # Geoms\n  geom_col(width = 0.6) +\n  geom_text(\n    aes(label = scales::dollar(avg_wage, accuracy = 1, scale = 0.001, suffix = \"k\")),\n    vjust = -0.5,\n    fontface = \"bold\",\n    size = 3.5,\n    color = colors$palette$text_dark\n  ) +\n  # Scales\n  scale_fill_manual(values = job_colors, guide = \"none\") +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.25))) +\n  # Labs\n  labs(title = \"Average Wage\") +\n  # Theme\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    axis.title.y = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.ticks.x = element_blank(),\n    plot.margin = margin(10, 10, 10, 10)\n  )\n\n# Sub-panel C: Total employment\np3c &lt;- p3_data |&gt;\n  ggplot(aes(x = job_short, y = total_emp, fill = second_job)) +\n  # Geoms\n  geom_col(width = 0.6) +\n  geom_text(\n    aes(label = scales::comma(total_emp)),\n    vjust = -0.5,\n    fontface = \"bold\",\n    size = 3.5,\n    color = colors$palette$text_dark\n  ) +\n  # Scales\n  scale_fill_manual(values = job_colors, guide = \"none\") +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.25))) +\n  # Labs\n  labs(title = \"Total Employment\") +\n  # Theme\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    axis.title.y = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.ticks.x = element_blank(),\n    plot.margin = margin(10, 10, 10, 10)\n  )\n\n# Combine P3\np3 &lt;- (p3a | p3b | p3c)\n\n### |-  combined plot ----\ncombined_plot &lt;- (p1 | p2) / p3 +\n  plot_annotation(\n    title = title_text,\n    subtitle = subtitle_text,\n    caption = caption_text,\n    theme = theme(\n      plot.title = element_text(\n        size = rel(2.2),\n        family = fonts$title,\n        face = \"bold\",\n        color = colors$title,\n        lineheight = 1.15,\n        margin = margin(t = 5, b = 10)\n      ),\n      plot.subtitle = element_text(\n        size = rel(0.9),\n        family = fonts$subtitle,\n        color = alpha(colors$subtitle, 0.88),\n        lineheight = 1.5,\n        margin = margin(t = 5, b = 10)\n      ),\n      plot.caption = element_markdown(\n        size = rel(0.65),\n        family = fonts$subtitle,\n        color = colors$caption,\n        hjust = 0,\n        lineheight = 1.4,\n        margin = margin(t = 20, b = 5)\n      ),\n    )\n  )\n```\n\n\n7. Save\n\nShow code```{r}\n#| label: save\n#| warning: false\n\n### |-  plot image ----  \nsave_plot_patchwork(\n  plot = combined_plot, \n  type = \"makeovermonday\", \n  year = current_year,\n  week = current_week,\n  width = 14, \n  height = 10\n  )\n```\n\n\n8. Session Info\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] here_1.0.1      janitor_2.2.0   patchwork_1.3.0 glue_1.8.0     \n [5] scales_1.3.0    showtext_0.9-7  showtextdb_3.0  sysfonts_0.8.9 \n [9] ggtext_0.1.2    lubridate_1.9.3 forcats_1.0.0   stringr_1.5.1  \n[13] dplyr_1.1.4     purrr_1.0.2     readr_2.1.5     tidyr_1.3.1    \n[17] tibble_3.2.1    ggplot2_3.5.1   tidyverse_2.0.0 pacman_0.5.1   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6       xfun_0.49          htmlwidgets_1.6.4  tzdb_0.5.0        \n [5] yulab.utils_0.1.8  vctrs_0.6.5        tools_4.4.0        generics_0.1.3    \n [9] curl_6.0.0         parallel_4.4.0     gifski_1.32.0-1    fansi_1.0.6       \n[13] pkgconfig_2.0.3    ggplotify_0.1.2    lifecycle_1.0.4    compiler_4.4.0    \n[17] farver_2.1.2       munsell_0.5.1      codetools_0.2-20   snakecase_0.11.1  \n[21] htmltools_0.5.8.1  yaml_2.3.10        crayon_1.5.3       pillar_1.9.0      \n[25] camcorder_0.1.0    magick_2.8.5       commonmark_1.9.2   tidyselect_1.2.1  \n[29] digest_0.6.37      stringi_1.8.4      labeling_0.4.3     rsvg_2.6.1        \n[33] rprojroot_2.0.4    fastmap_1.2.0      grid_4.4.0         colorspace_2.1-1  \n[37] cli_3.6.4          magrittr_2.0.3     utf8_1.2.4         withr_3.0.2       \n[41] bit64_4.5.2        timechange_0.3.0   rmarkdown_2.29     bit_4.5.0         \n[45] hms_1.1.3          evaluate_1.0.1     knitr_1.49         markdown_1.13     \n[49] gridGraphics_0.5-1 rlang_1.1.6        gridtext_0.1.5     Rcpp_1.0.13-1     \n[53] xml2_1.3.6         renv_1.0.3         svglite_2.1.3      rstudioapi_0.17.1 \n[57] vroom_1.6.5        jsonlite_1.8.9     R6_2.5.1           fs_1.6.5          \n[61] systemfonts_1.1.0 \n\n\n\n\n\n9. GitHub Repository\n\n\n\n\n\n\nExpand for GitHub Repo\n\n\n\n\n\nThe complete code for this analysis is available in mm_2026_04.qmd.\nFor the full repository, click here.\n\n\n\n10. References\n\n\n\n\n\n\nExpand for References\n\n\n\n\n\nPrimary Data (Makeover Monday):\n\nMakeover Monday 2026 Week 4: Most Posted US Jobs by State\n\nOriginal Article: Job titles in highest-demand, state by state\n\nSource: Lightcast Job Posting Analytics\nCoverage: Top 3 job postings by state (Oct 2024 - Oct 2025)\n\n\n\nEnhancement Data:\n\nEmployment & Wage Data: BLS Occupational Employment and Wage Statistics (OEWS)\n\nRelease: May 2024 State Estimates\nVariables: Employment counts, mean annual wages by occupation Ã— state\nCitation: U.S. Bureau of Labor Statistics. (2025). Occupational Employment and Wage Statistics, May 2024.\n\n\nPopulation Data: Census Bureau Population Estimates\n\nYear: 2023 State Population Estimates\nCitation: U.S. Census Bureau. (2023). Annual Estimates of the Resident Population for the United States, Regions, States, District of Columbia, and Puerto Rico: April 1, 2020 to July 1, 2023 (NST-EST2023-POP).\n\n\n\nSOC Codes Used (BLS OEWS):\n\n29-1141: Registered Nurses\n53-3032: Heavy and Tractor-Trailer Truck Drivers\n41-2031: Retail Salespersons\n15-1252: Software Developers\n43-4051: Customer Service Representatives\n29-2061: Licensed Practical and Licensed Vocational Nurses\n\n\n\n\n11. Custom Functions Documentation\n\n\n\n\n\n\nðŸ“¦ Custom Helper Functions\n\n\n\n\n\nThis analysis uses custom functions from my personal module library for efficiency and consistency across projects.\nFunctions Used:\n\n\nfonts.R: setup_fonts(), get_font_families() - Font management with showtext\n\nsocial_icons.R: create_social_caption() - Generates formatted social media captions\n\nimage_utils.R: save_plot() - Consistent plot saving with naming conventions\n\nbase_theme.R: create_base_theme(), extend_weekly_theme(), get_theme_colors() - Custom ggplot2 themes\n\nWhy custom functions?\nThese utilities standardize theming, fonts, and output across all my data visualizations. The core analysis (data tidying and visualization logic) uses only standard tidyverse packages.\nSource Code:\nView all custom functions â†’ GitHub: R/utils\n\n\n\n\n\n\n\n Back to topCitationBibTeX citation:@online{ponce2026,\n  author = {Ponce, Steven},\n  title = {Americaâ€™s {Most} {In-Demand} {Jobs:} {Beyond} the\n    {Headlines}},\n  date = {2026-01-26},\n  url = {https://stevenponce.netlify.app/data_visualizations/MakeoverMonday/2026/mm_2026_04.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPonce, Steven. 2026. â€œAmericaâ€™s Most In-Demand Jobs: Beyond the\nHeadlines.â€ January 26, 2026. https://stevenponce.netlify.app/data_visualizations/MakeoverMonday/2026/mm_2026_04.html."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-28.html",
    "href": "projects/standalone_visualizations/sa_2026-01-28.html",
    "title": "Governance-First Launch Forecasting: A Decision Support Framework",
    "section": "",
    "text": "ðŸš€ Live app:Oncology Launch Curve Forecaster\nðŸ’» Source code:GitHub repository"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-28.html#framing-the-problem",
    "href": "projects/standalone_visualizations/sa_2026-01-28.html#framing-the-problem",
    "title": "Governance-First Launch Forecasting: A Decision Support Framework",
    "section": "1. Framing the problem",
    "text": "1. Framing the problem\nPre-launch planning in pharmaceutical commercialization involves decisions under substantial uncertainty. Brand teams must commit to launch timing, resource allocation, and forecast ranges while facing unknowns about regulatory approval timing, manufacturing readiness, and market reception.\nThe natural instinct is to seek precision: better models, more data, tighter confidence intervals. But in practice, the harder problem is often structuring the conversation around forecast ranges, revenue-at-risk, and timing shiftsâ€”rather than eliminating uncertainty entirely.\nThis project approaches launch forecasting as a governance and framing problem, rather than a prediction exercise. The objective is not to forecast whether a specific launch will succeed, but to quantify how analog selection and timing assumptions translate into revenue riskâ€”making trade-offs explicit for cross-functional discussion.\nIn practice, this means shifting the question from â€œWhat will happen?â€ to â€œWhat are we implicitly assumingâ€”and what does that assumption cost if itâ€™s wrong?â€"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-28.html#the-core-decision-question",
    "href": "projects/standalone_visualizations/sa_2026-01-28.html#the-core-decision-question",
    "title": "Governance-First Launch Forecasting: A Decision Support Framework",
    "section": "2. The core decision question",
    "text": "2. The core decision question\nThe framework is designed around a single, actionable question:\nWhat is the revenue at risk if launch timing shifts under uncertainty?\nThis question matters because it connects analytical work directly to decisions that leadership teams actually face:\n\nHow much revenue exposure exists in Year 1 if launch slips by one or two quarters?\nWhat forecast commitment range (P25/P50/P75) is defensible given analog variation?\nHow sensitive are these conclusions to which analogs are included?\n\nIn practice, timing assumptions also propagate into manufacturing readiness, commercial resourcing, and financial guidanceâ€”making early uncertainty costly to unwind later.\nRather than producing point forecasts, the framework surfaces ranges and trade-offs that support structured executive discussion."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-28.html#why-governance-first-analog-selection",
    "href": "projects/standalone_visualizations/sa_2026-01-28.html#why-governance-first-analog-selection",
    "title": "Governance-First Launch Forecasting: A Decision Support Framework",
    "section": "3. Why governance-first analog selection",
    "text": "3. Why governance-first analog selection\nAnalog-based forecasting is common in pharmaceutical commercial planning. The challenge is that analog selection is inherently subjectiveâ€”and post-hoc adjustments can undermine credibility.\nThis framework applies a governance-first methodology:\n\n\nDefine inclusion criteria before examining outcomes â€” Therapeutic area, peak revenue threshold, and data availability requirements are specified upfront.\n\nLock the analog list in writing â€” No modifications after seeing revenue performance.\n\nDocument rationale for every inclusion/exclusion â€” Creates an audit trail for reviewers.\n\nTest sensitivity explicitly â€” Option to exclude the top-performing analog tests whether conclusions depend on outliers.\n\nThis approach addresses a common critique of analog analysis: that analysts cherry-pick comparators to support predetermined conclusions. By separating selection criteria from outcome examination, the framework survives skeptical review.\nThis governance-first approach is operationalized in the app through four components: Executive Brief (scenario comparison and trade-off framing), Scenario Builder (criteria configuration and sensitivity testing), Analog Explorer (individual product examination with guardrails), and Methods & Data (assumption documentation and scope boundaries)."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-28.html#what-the-framework-quantifies",
    "href": "projects/standalone_visualizations/sa_2026-01-28.html#what-the-framework-quantifies",
    "title": "Governance-First Launch Forecasting: A Decision Support Framework",
    "section": "4. What the framework quantifies",
    "text": "4. What the framework quantifies\nRevenue-at-Risk Estimation\nThe framework calculates Year 1 revenue at risk under configurable launch delay scenarios:\nRevenue at Risk (Year 1) = delay_quarters Ã— (median Year 1 revenue / 4)\nYear 1 is used because it is the period most sensitive to launch timing assumptions and the least confounded by later competitive or lifecycle effects.\nThis is explicitly labeled as a Year 1 average-quarter approximationâ€”a simplification that provides directional magnitude without implying DCF-level precision.\nScenario Bands from Analog Variation\nPercentile bands (P25/P50/P75) are derived from observed analog performance:\n\n\nP50 (Base Case): Median analog trajectory\n\nP75 (Upper Range): Upper quartile performance\n\nP25 (Lower Range): Lower quartile performance\n\nThese represent observed variation across analogs, not statistical confidence intervals. The distinction matters: they quantify historical heterogeneity, not forecasting uncertainty.\nSelection Statistics\nDynamic statistics update as criteria change:\n\nSolid tumor vs.Â hematology count\nApproval year range\nMedian peak revenue\nNumber of analogs meeting criteria\n\nThis transparency helps users understand whatâ€™s driving the scenario range."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-28.html#key-assumptions-documented",
    "href": "projects/standalone_visualizations/sa_2026-01-28.html#key-assumptions-documented",
    "title": "Governance-First Launch Forecasting: A Decision Support Framework",
    "section": "5. Key assumptions documented",
    "text": "5. Key assumptions documented\nThe framework relies on several simplifying assumptions that users should understand:\nDemand deferral, not destruction\nDelayed demand is assumed to shift forward in time rather than being permanently lost. Competitive dynamics and access erosion are not modeled.\nLabel expansion bias\nSome analogs experienced significant post-launch indication expansions, creating potential upward bias in peak revenue estimates. Products without similar expansion potential may underperform these benchmarks.\nEra effects\nLaunch dynamics differ between earlier (2013â€“2015) and more recent oncology approvals. The analog set includes both eras, which may introduce heterogeneity.\nUS-weighted revenue\nSEC filing data may include global revenue. Geographic mix differences between analogs and forecasted products are not adjusted.\nThese assumptions are documented in the Methods & Data tab and surfaced in the dashboard interface to prevent over-interpretation."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-28.html#what-this-framework-doesand-does-notdo",
    "href": "projects/standalone_visualizations/sa_2026-01-28.html#what-this-framework-doesand-does-notdo",
    "title": "Governance-First Launch Forecasting: A Decision Support Framework",
    "section": "6. What this framework doesâ€”and does notâ€”do",
    "text": "6. What this framework doesâ€”and does notâ€”do\nWhat it does\nâœ… Structures analog-based launch scenario analysis\nâœ… Quantifies revenue ranges from analog variation (P25/P50/P75)\nâœ… Supports structured trade-off conversations under uncertainty\nâœ… Documents assumptions and limitations transparently\nâœ… Provides sensitivity checks to test analytical robustness\nWhat it does not do\nâŒ Predict whether a specific launch will succeed\nâŒ Recommend specific investment or resourcing levels\nâŒ Model competitive response or market access dynamics\nâŒ Estimate NPV or financial returns\nâŒ Replace clinical, regulatory, or strategic judgment\nBy design: NPV and market access modeling are excluded because they require company-specific inputs that would compromise generalizability. Revenue scenarios are treated as foundational inputs to financial modeling, not final outputs."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-28.html#dashboard-structure",
    "href": "projects/standalone_visualizations/sa_2026-01-28.html#dashboard-structure",
    "title": "Governance-First Launch Forecasting: A Decision Support Framework",
    "section": "7. Dashboard structure",
    "text": "7. Dashboard structure\nThe application is organized into four complementary views:\nExecutive Brief\n\nAn executive-facing summary that surfaces:\n\nKey metrics (analog count, peak revenue range, revenue at risk)\nLaunch trajectory scenarios with P25/P50/P75 bands\nTwo explicit decision trade-offs: launch timing and forecast commitment\nSelected analog summary table\n\nThe decision boxes explicitly frame trade-offs in terms stakeholders recognize: â€œSpeed vs.Â readinessâ€ and â€œAlignment vs.Â credibility risk.â€\nScenario Builder\n\nAn interactive configuration view that allows users to:\n\nSelect therapeutic focus (solid tumors, hematology, or both)\nSet minimum peak revenue thresholds\nTest sensitivity by excluding the top-performing analog\nConfigure launch delay scenarios (0â€“4 quarters)\n\nThe Selection Rationale panel updates dynamically, showing live statistics and a governance note reminding users that criteria should be documented before examining outcomes.\nAnalog Explorer\n\nA detailed view for examining individual analog characteristics:\n\nSide-by-side comparison of two selected analogs\nLaunch curve visualization showing trajectory differences\nCharacteristics table (company, indication, approval date, peak revenue)\nLaunch context factors that may have influenced trajectory\n\nThis tab includes guardrails against over-interpretationâ€”users must click â€œView Detailsâ€ to load data, creating a deliberate interaction that discourages casual browsing.\nMethods & Data\n\nA transparency-focused section documenting:\n\nFramework overview and workflow diagram\nData sources (FDA approvals, SEC EDGAR filings, published literature)\nInclusion and exclusion criteria\nKey assumptions with explicit discussion\nâ€œWhat This Framework Does NOT Doâ€ section\nTechnical implementation details"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-28.html#the-analog-set",
    "href": "projects/standalone_visualizations/sa_2026-01-28.html#the-analog-set",
    "title": "Governance-First Launch Forecasting: A Decision Support Framework",
    "section": "8. The analog set",
    "text": "8. The analog set\nThe framework includes 10 established oncology launches with product-level revenue disclosed in SEC filings:\nSolid tumors (6):\nKeytruda, Opdivo, Ibrance, Tagrisso, Lynparza, Tecentriq\nHematology (4):\nImbruvica, Darzalex, Venclexta, Calquence\nThe 6/4 split reflects real-world prevalence rather than forced symmetry. Adding weaker products to achieve balance would introduce more noise than signal.\nApproval years range from 2013â€“2017, providing sufficient follow-up to observe peak revenue while remaining recent enough to reflect modern launch dynamics."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-28.html#technical-lessons-from-the-build",
    "href": "projects/standalone_visualizations/sa_2026-01-28.html#technical-lessons-from-the-build",
    "title": "Governance-First Launch Forecasting: A Decision Support Framework",
    "section": "9. Technical lessons from the build",
    "text": "9. Technical lessons from the build\nThis project surfaced an important technical insight about Shiny development with CSS-based UI frameworks.\nThe Problem\nWhen using shiny.semantic (which relies on Semantic UIâ€™s CSS-based tab switching), outputs donâ€™t render automatically when users navigate to a tab. Shinyâ€™s lazy evaluation assumes it knows when tabs become visibleâ€”but CSS-based tabs donâ€™t notify Shiny of visibility changes.\nThe Solution\nAdding outputOptions(output, \"output_name\", suspendWhenHidden = FALSE) to all outputs forces Shiny to render regardless of perceived visibility. This pattern isnâ€™t documented in standard Shiny guides but is essential for CSS-based tab frameworks.\nThis discoveryâ€”after several hours of debuggingâ€”became the most valuable technical lesson from the project."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-28.html#why-this-framing-matters-for-commercial-analytics",
    "href": "projects/standalone_visualizations/sa_2026-01-28.html#why-this-framing-matters-for-commercial-analytics",
    "title": "Governance-First Launch Forecasting: A Decision Support Framework",
    "section": "10. Why this framing matters for commercial analytics",
    "text": "10. Why this framing matters for commercial analytics\nIn pharmaceutical commercial planning, forecasts are rarely wrong because of poor algorithms. Theyâ€™re wrong because:\n\nAnalog selection was post-hoc rationalized\nAssumptions werenâ€™t documented or tested\nRanges were too narrow to capture actual uncertainty\nTrade-offs werenâ€™t made explicit to decision-makers\n\nThis framework addresses these failure modes directly:\n\n\nGovernance-first selection prevents cherry-picking\n\nDocumented assumptions create audit trails\n\nP25/P50/P75 bands acknowledge inherent uncertainty\n\nExplicit trade-off framing connects analysis to decisions\n\nThe goal is not better predictions, but better-structured conversations about what forecasts can and cannot support."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-28.html#appendix-methodology-build-notes",
    "href": "projects/standalone_visualizations/sa_2026-01-28.html#appendix-methodology-build-notes",
    "title": "Governance-First Launch Forecasting: A Decision Support Framework",
    "section": "Appendix: Methodology & Build Notes",
    "text": "Appendix: Methodology & Build Notes\nData Sources\n\n\nFDA Drug Approvals: Approval dates (T=0), initial indications\n\nSEC EDGAR Filings: Product-level revenue from 10-K and 10-Q reports\n\nPublished Literature: Launch curve patterns and benchmarks from peer-reviewed sources\nTechnical Stack\n\n\nLanguage: R (4.3+)\n\nFramework: Shiny (modular architecture)\n\nUI: shiny.semantic (Appsilon)\n\nVisualization: ggplot2, ggiraph\n\nTables: reactable, reactablefmtr\n\nDeployment: shinyapps.io\nKey Design Choices\n\nRevenue normalized to launch quarter (T=0) for comparability\nPercentiles calculated across analog set (not confidence intervals)\nRevenue scaled to millions USD for readability\nAll data from public sources to ensure reproducibility"
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-28.html#purpose-scope-and-disclaimer",
    "href": "projects/standalone_visualizations/sa_2026-01-28.html#purpose-scope-and-disclaimer",
    "title": "Governance-First Launch Forecasting: A Decision Support Framework",
    "section": "Purpose, Scope, and Disclaimer",
    "text": "Purpose, Scope, and Disclaimer\nThis project is a portfolio case study intended to demonstrate analytical framing, governance, and decision-support design using publicly available data.\nIt is not intended for real-world commercial decision-making and is not affiliated with any pharmaceutical company. Product names are used for analytical illustration only.\nAll data are derived from publicly available sources including SEC filings and FDA databases. No proprietary or confidential information is included.\nThis work does not constitute investment advice, commercial guidance, or strategic recommendations."
  },
  {
    "objectID": "projects/standalone_visualizations/sa_2026-01-28.html#closing-reflection",
    "href": "projects/standalone_visualizations/sa_2026-01-28.html#closing-reflection",
    "title": "Governance-First Launch Forecasting: A Decision Support Framework",
    "section": "Closing Reflection",
    "text": "Closing Reflection\n\n\n\n\n\n\nNote\n\n\n\nThe value of this framework lies not in its predictions, but in its structure. By making analog selection defensible, assumptions transparent, and trade-offs explicit, it provides a foundation for disciplined commercial planning conversationsâ€”conversations that connect forecast ranges to revenue-at-risk and timing decisions to resource commitments.\nIn launch planning, clarity about what we donâ€™t know is often more valuable than false confidence about what we do."
  }
]